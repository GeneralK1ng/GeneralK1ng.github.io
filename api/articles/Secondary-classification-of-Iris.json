{"title":"（实战）鸢尾花数据集的二分类","uid":"6ad60e40b1cfbe85f1c534ea3d1910e1","slug":"Secondary-classification-of-Iris","date":"2023-07-19T10:14:24.000Z","updated":"2023-07-19T11:33:27.102Z","comments":true,"path":"api/articles/Secondary-classification-of-Iris.json","keywords":null,"cover":"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/dataAnalysis.jpg","content":"<p>所以说第一行打不了字是吧，莫名其妙。（不用管这一行，刚刚发现我的编辑器第一行莫名其妙打不了字，所以你看到的这是第二行，很烦）</p>\n<p>昨天我学习了逻辑回归，今天就要实战一下啦！因为光看纸上的知识总感觉有点枯燥，咱们动手试试，把学到的知识化为力量吧！今天我们要玩的游戏是逻辑回归，而游戏场地就是鸢尾花的数据集。</p>\n<h2 id=\"数据集：鸢尾花大冒险\"><a href=\"#数据集：鸢尾花大冒险\" class=\"headerlink\" title=\"数据集：鸢尾花大冒险\"></a>数据集：鸢尾花大冒险</h2><p>咱们先打开Excel，看看我们要玩的鸢尾花数据集是什么样子滴！第一列是索引，我们直接删掉啦！（记得一定要删掉哦！不然程序会迷失方向，不信你试试！不过别问我为什么知道… T T）</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/IrisDataDemo.png\"></p>\n<p>可以发现，第一行是表头数据，分别有<strong>Sepal.Length（萼片长度）</strong>，<strong>Sepal.Width（萼片宽度）</strong>，<strong>Petal.Length（花瓣长度）</strong>，<strong>Petal.Width（花瓣宽度）</strong>，<strong>Species（种类）</strong>，这几个，而Species中分为三个种类，分别是“<strong>setosa</strong>”，“<strong>versicolor</strong>”和“<strong>virginica</strong>”，分别是“小山鸢尾”、“变色鸢尾”和“维吉尼亚鸢尾”。</p>\n<h2 id=\"准备阶段：选取我们的“法宝”\"><a href=\"#准备阶段：选取我们的“法宝”\" class=\"headerlink\" title=\"准备阶段：选取我们的“法宝”\"></a>准备阶段：选取我们的“法宝”</h2><p>首先，咱们得明确自己的任务和目标哦：我们要用逻辑回归算法解决一个二分类问题，把这个法宝应用于鸢尾花数据集。目标是训练逻辑回归模型，并查看它在测试集上的“施法”效果。</p>\n<p>这里咱们可要动用一些神奇的“法宝”呢！数据处理用强大的<code>Pandas</code>，数值计算可凭借老生常谈的<code>numpy</code>库，<code>train_test_split</code>可用来把数据分为训练集和测试集，<code>LogisticRegression</code>则是我们要打造的逻辑回归模型，还有<code>accuracy_score</code>、<code>precision_score</code>和<code>recall_score</code>这三把尺子，它们能帮我们测量评估指标的准确度哦！最后，还有<code>matplotlib.pyplot</code>可将数据可视化，让我们一起瞧瞧吧！</p>\n<p>所以准备工作差不多就这些，先把所需要的模块导入。</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nimport matplotlib.pyplot as plt</code></pre>\n\n<h2 id=\"魔法准备：定义一些有趣的“法术”\"><a href=\"#魔法准备：定义一些有趣的“法术”\" class=\"headerlink\" title=\"魔法准备：定义一些有趣的“法术”\"></a>魔法准备：定义一些有趣的“法术”</h2><p>现在，我们要定义一些有趣的“法术”来玩逻辑回归啦！这些“法术”都是数学公式变身的，让Python来帮我们算算就好啦！</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">def sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\ndef log_likelihood(features, target, weights):\n    scores = np.dot(features, weights)\n    ll = np.sum(target * scores - np.log(1 + np.exp(scores)))\n    return ll\n\ndef logistic_regression(features, target, num_steps, learning_rate):\n    intercept = np.ones((features.shape[0], 1))\n    features = np.hstack((intercept, features))\n    weights = np.zeros(features.shape[1])\n\n    for step in range(num_steps):\n        scores = np.dot(features, weights)\n        predictions = sigmoid(scores)\n\n        output_error_signal = target - predictions\n        gradient = np.dot(features.T, output_error_signal)\n        weights += learning_rate * gradient\n\n        # Print log-likelihood every 100 steps\n        if step % 100 == 0:\n            print(f\"Step {step}, Log-Likelihood: {log_likelihood(features, target, weights)}\")\n\n    return weights</code></pre>\n\n<p>第一个“法术”叫做<code>sigmoid</code>，它是逻辑回归中的魔法函数，负责把输入的数值变成0到1之间的可爱小数哦！</p>\n<p>接下来是<code>log_likelihood</code>，“法术”嘛，它能算出对数似然性，看起来有点高深，其实是帮我们衡量预测结果的好坏程度！</p>\n<p>最后一个“法术”是<code>logistic_regression</code>，这个可厉害了！它用梯度上升算法，一步步地训练逻辑回归模型，就像咱们在山上慢慢攀登一样！它还会在每爬100步的时候，打印出对数似然性，让我们知道自己的成长进度哦！</p>\n<h2 id=\"大冒险准备：数据预处理\"><a href=\"#大冒险准备：数据预处理\" class=\"headerlink\" title=\"大冒险准备：数据预处理\"></a>大冒险准备：数据预处理</h2><p>怎么个处理法，其实好像没什么需要处理的，无非就是读取，存储，几个简单的转换？差不多吧。</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 加载数据集并分成训练集和测试集\ndata_path = 'iris.csv' # 你的路径！\ndata = pd.read_csv(data_path)\n\n# 将'setosa'标记为1，其他两种花标记为0，实现二分类问题\ndata['Species'] = data['Species'].map({'setosa': 1, 'versicolor': 0, 'virginica': 0})\n\n# 提取特征和标签\nfeatures = data.drop('Species', axis=1)\ntarget = data['Species']\n\n# 分割数据集\ntrain_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.2, random_state=42)</code></pre>\n\n<p>首先，我们要加载数据集，它就像我们的宝藏地图一样，指引着我们前进的方向。我们用<code>pd.read_csv()</code>将数据从<code>csv</code>文件中读取出来，并把花的种类标记为<code>1</code>和<code>0</code>，就像宝藏上的标记一样，让我们可以区分哪些是我们要找的，哪些是普通的岩石。瞧，鸢尾花的种类有点像三个魔法宝石，我们要把其中一个宝石标记为<code>1</code>，其他两个标记为<code>0</code>，这样它们就变成了我们要寻找的目标。</p>\n<p>接下来，我们得把宝藏中的特征和目标提取出来。特征就像地图上的路线，目标就像我们要找的宝藏。咱们把特征放进<code>features</code>变量，把目标放进<code>target</code>变量，这样咱们就能对它们进行后续的处理啦。</p>\n<p>鸢尾花大冒险的第一步就是分割数据集，将宝藏地图分成训练集和测试集，这样我们才能在训练中不断成长，最后测试一下自己的探险成果。通过<code>train_test_split</code>，我们将数据集分成了两部分，80%的数据用来训练，20%的数据留作测试，而随机种子<code>random_state=42</code>则确保我们在不同的时候玩同样的游戏。</p>\n<h2 id=\"参数：选个好武器，准备战斗\"><a href=\"#参数：选个好武器，准备战斗\" class=\"headerlink\" title=\"参数：选个好武器，准备战斗\"></a>参数：选个好武器，准备战斗</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 使用训练集来训练逻辑回归模型\nnum_steps = 1000\nlearning_rate = 0.01\nweights = logistic_regression(train_features, train_target, num_steps, learning_rate)</code></pre>\n\n<p>接下来，我们要选择适合鸢尾花大冒险的武器了。先把自己的装备整理一下，我们需要设定一些超级厉害的“法宝”：迭代次数<code>num_steps</code>和学习率<code>learning_rate</code>，这些会决定我们在冒险中的表现。好了，现在我们就准备好了，可以正式进入鸢尾花的世界了！</p>\n<p>“法宝”已经准备齐全，现在我们需要通过<code>logistic_regression</code>函数，调用那些魔法“法术”来进行模型的训练。这个过程就像在修炼魔法一样，每一步都在增强我们的力量。训练过程中，我们会在每爬100步的时候，打印出当前的对数似然性，这样我们就能看到自己的成长历程。</p>\n<p>你也可以在这部分通过调整迭代次数和学习率来观察不同情况下的模型表现。</p>\n<h2 id=\"探索成果，评估表现！\"><a href=\"#探索成果，评估表现！\" class=\"headerlink\" title=\"探索成果，评估表现！\"></a>探索成果，评估表现！</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">test_intercept = np.ones((test_features.shape[0], 1))\ntest_features = np.hstack((test_intercept, test_features))\ntest_predictions = sigmoid(np.dot(test_features, weights))\ntest_predictions = np.round(test_predictions)\n\naccuracy = accuracy_score(test_target, test_predictions)\nprecision = precision_score(test_target, test_predictions)\nrecall = recall_score(test_target, test_predictions)\n\nprint(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\")</code></pre>\n\n<p>这一部分代码使用训练后的模型权重对测试集进行预测，并计算评估指标。首先，将测试集的特征矩阵添加一列全为1的列作为截距，然后通过逻辑函数<code>sigmoid</code>和权重矩阵计算预测结果。为了得到最终的分类结果，将预测概率四舍五入为0或1。</p>\n<p>最后，计算预测结果与测试集真实标签之间的准确率、精确率和召回率，并将结果打印输出。</p>\n<div class=\"custom-quote tip\">\n<span class=\"custom-quote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M20.86 14.13C20 14.7 19.56 15.74 19.77 16.76C20.13 18.55 18.55 20.13 16.76 19.77C15.74 19.57 14.7 20 14.13 20.86C13.12 22.38 10.89 22.38 9.88 20.86C9.3 20 8.26 19.56 7.24 19.77C5.45 20.13 3.87 18.55 4.23 16.76C4.43 15.74 4 14.7 3.14 14.13C1.62 13.12 1.62 10.89 3.14 9.88C4 9.3 4.44 8.26 4.23 7.24C3.87 5.45 5.45 3.87 7.24 4.23C8.26 4.44 9.3 4 9.87 3.14C10.88 1.62 13.11 1.62 14.12 3.14C14.7 4 15.74 4.44 16.76 4.23C18.55 3.87 20.13 5.45 19.77 7.24C19.56 8.26 20 9.3 20.86 9.87C22.38 10.88 22.38 13.12 20.86 14.13Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M12.01 15C12.01 14.5 12.01 14.5 12.01 14.5C12.04 13.75 13 13.46 14.04 12.2C14.41 11.74 14.69 11.41 14.86 10.85C15.15 9.95 14.92 9.18 14.86 9.02C14.8 8.79 14.52 8 13.72 7.46C13.06 7.02 12.42 7 12.14 7C11.9 7 11.36 7 10.78 7.3C10.28 7.56 9.98 7.9 9.83 8.1C9.24 8.82 9.06 9.63 9 10.06\"></path>\n<path stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M11.99 18H12.01\"></path>\n</svg></span>\n<p class=\"custom-quote-title\">TIP</p>\n<p>这里我再来贴一下什么是准确率，精确率和召回率。</p>\n<ol>\n<li><strong>准确率（Accuracy）</strong>： 准确率是最常用的模型性能指标之一，它表示模型正确预测的样本数与总样本数之间的比例。即：(预测正确的样本数) / (总样本数)。准确率越高，表示模型的整体性能越好。</li>\n<li><strong>精确率（Precision）</strong>： 精确率是针对<strong>预测</strong>为正例的样本而言的，它表示在所有预测为正例的样本中，模型正确预测为正例的比例。即：(真正例数) / (真正例数 + 假正例数)。精确率高表示模型对正例的预测较准确。</li>\n<li><strong>召回率（Recall）</strong>： 召回率是针对<strong>实际</strong>为正例的样本而言的，它表示在所有实际为正例的样本中，模型正确预测为正例的比例。即：(真正例数) / (真正例数 + 假负例数)。召回率高表示模型对正例的识别能力较强。</li>\n</ol>\n\n</div>\n<h2 id=\"数据可视化\"><a href=\"#数据可视化\" class=\"headerlink\" title=\"数据可视化\"></a>数据可视化</h2><p>由于鸢尾花数据集有四个特征，我们可以选择任意两个特征来进行可视化处理。</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">feature_names = ['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']\ntarget_names = ['setosa', 'versicolor/virginica']\n\nfig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 15))\n\nfor idx, ax in enumerate(axes.flat):\n    i, j = idx // 2, idx % 2\n    ax.scatter(data[data['Species'] == 1][feature_names[i]], data[data['Species'] == 1][feature_names[j]], label='setosa')\n    ax.scatter(data[data['Species'] == 0][feature_names[i]], data[data['Species'] == 0][feature_names[j]], label='versicolor/virginica')\n    ax.scatter(test_features[test_target == 1][:, i+1], test_features[test_target == 1][:, j+1], marker='o', edgecolors='red', facecolors='none', label='setosa (predicted)')\n    ax.scatter(test_features[test_target == 0][:, i+1], test_features[test_target == 0][:, j+1], marker='x', color='red', label='versicolor/virginica (predicted)')\n    ax.set_xlabel(feature_names[i])\n    ax.set_ylabel(feature_names[j])\n    ax.legend()\n\nplt.tight_layout()\nplt.show()</code></pre>\n\n<p>最后这一部分代码进行了数据可视化处理，使用散点图展示了不同特征组合下的分类结果。这部分代码使用了<code>matplotlib.pyplot</code>库，创建了6个子图，并在每个子图中绘制了鸢尾花数据集中的两个特征。蓝色的点代表’Setosa’类别，橙色的点代表’Versicolor’和’Virginica’类别。预测集的结果用红色的圆圈（’o’）表示’Setosa’类别，用红色的叉（’x’）表示’Versicolor’和’Virginica’类别。</p>\n<p>完整代码如下</p>\n<details class=\"custom-details\">\n<summary>Click to see more</summary>\n<p><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nimport matplotlib.pyplot as plt\n\n# 1. 逻辑回归算法的代码实现\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\ndef log_likelihood(features, target, weights):\n    scores = np.dot(features, weights)\n    ll = np.sum(target * scores - np.log(1 + np.exp(scores)))\n    return ll\n\ndef logistic_regression(features, target, num_steps, learning_rate):\n    intercept = np.ones((features.shape[0], 1))\n    features = np.hstack((intercept, features))\n    weights = np.zeros(features.shape[1])\n\n    for step in range(num_steps):\n        scores = np.dot(features, weights)\n        predictions = sigmoid(scores)\n\n        output_error_signal = target - predictions\n        gradient = np.dot(features.T, output_error_signal)\n        weights += learning_rate * gradient\n\n        # Print log-likelihood every 100 steps\n        if step % 100 == 0:\n            print(f\"Step {step}, Log-Likelihood: {log_likelihood(features, target, weights)}\")\n\n    return weights\n\n# 2. 选择一个适合的二分类数据集\n# 在此示例中，我们将使用鸢尾花数据集\n\n# 3. 加载数据集并分成训练集和测试集\ndata_path = 'iris.csv' # 你的路径！！！\ndata = pd.read_csv(data_path)\n\n# 将'setosa'标记为1，其他两种花标记为0，实现二分类问题\ndata['Species'] = data['Species'].map({'setosa': 1, 'versicolor': 0, 'virginica': 0})\n\n# 提取特征和标签\nfeatures = data.drop('Species', axis=1)\ntarget = data['Species']\n\n# 分割数据集\ntrain_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.2, random_state=465)\n\n# 4. 使用训练集来训练逻辑回归模型\nnum_steps = 1000\nlearning_rate = 0.01\nweights = logistic_regression(train_features, train_target, num_steps, learning_rate)\n\n# 5. 在测试集上评估模型性能\ntest_intercept = np.ones((test_features.shape[0], 1))\ntest_features = np.hstack((test_intercept, test_features))\ntest_predictions = sigmoid(np.dot(test_features, weights))\ntest_predictions = np.round(test_predictions)\n\naccuracy = accuracy_score(test_target, test_predictions)\nprecision = precision_score(test_target, test_predictions)\nrecall = recall_score(test_target, test_predictions)\n\nprint(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\")\n\n# 6. 数据可视化处理（放到同一张图里的子图中）\n# 由于鸢尾花数据集有四个特征，我们可以选择任意两个特征来进行可视化处理。\n\nfeature_names = ['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']\ntarget_names = ['setosa', 'versicolor/virginica']\n\nfig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 15))\n\nfor idx, ax in enumerate(axes.flat):\n    i, j = idx // 2, idx % 2\n    ax.scatter(data[data['Species'] == 1][feature_names[i]], data[data['Species'] == 1][feature_names[j]], label='setosa')\n    ax.scatter(data[data['Species'] == 0][feature_names[i]], data[data['Species'] == 0][feature_names[j]], label='versicolor/virginica')\n    ax.scatter(test_features[test_target == 1][:, i+1], test_features[test_target == 1][:, j+1], marker='o', edgecolors='red', facecolors='none', label='setosa (predicted)')\n    ax.scatter(test_features[test_target == 0][:, i+1], test_features[test_target == 0][:, j+1], marker='x', color='red', label='versicolor/virginica (predicted)')\n    ax.set_xlabel(feature_names[i])\n    ax.set_ylabel(feature_names[j])\n    ax.legend()\n\nplt.tight_layout()\nplt.show()\n\n# 7. 尝试调整学习率、迭代次数等参数，观察对模型性能的影响\n# 你可以尝试不同的学习率和迭代次数，观察模型在测试集上的性能变化。</code></pre>\n\n</p>\n</details>\n<h2 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h2><img src=\"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/Secondary classification of Iris.png\">\n\n<p>于是我们就能得到如上的图片，并且控制台打印如下：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">Step 0, Log-Likelihood: -466.2106144434709\nStep 100, Log-Likelihood: -0.36586843732581664\nStep 200, Log-Likelihood: -0.261779308423121\nStep 300, Log-Likelihood: -0.2055975355203343\nStep 400, Log-Likelihood: -0.17016379364395556\nStep 500, Log-Likelihood: -0.14565669423300498\nStep 600, Log-Likelihood: -0.12763643409226652\nStep 700, Log-Likelihood: -0.11379421631281457\nStep 800, Log-Likelihood: -0.1028071299788049\nStep 900, Log-Likelihood: -0.09386101997678553\nAccuracy: 1.0, Precision: 1.0, Recall: 1.0</code></pre>\n\n<h3 id=\"图片分析\"><a href=\"#图片分析\" class=\"headerlink\" title=\"图片分析\"></a>图片分析</h3><ol>\n<li>图片中的子图：在图片中的每个子图中，横轴和纵轴分别表示两个特征，点的分布代表鸢尾花数据集中的样本分布。蓝色点表示’Setosa’类别，橙色点表示’Versicolor’和’Virginica’类别。红色圆圈（’o’）表示模型预测为’Setosa’类别的样本，红色叉（’x’）表示模型预测为’Versicolor’和’Virginica’类别的样本。</li>\n<li>分析子图的区分度：观察每个子图中的蓝色点和橙色点的分布情况，可以看出这两类样本在这两个特征上的区分度。如果两类样本在某个特征上有明显的分离，说明该特征对分类有较强的区分能力。</li>\n<li>分析预测结果：观察红色圆圈和红色叉的分布情况，它们代表了模型在测试集上的预测结果。如果模型分类准确，预测为’Setosa’类别的样本应该位于蓝色点的附近，预测为’Versicolor’和’Virginica’类别的样本应该位于橙色点的附近。如果红色圆圈和红色叉分布与蓝色点和橙色点重叠较少，说明模型的预测效果较好。</li>\n</ol>\n<h3 id=\"控制台分析\"><a href=\"#控制台分析\" class=\"headerlink\" title=\"控制台分析\"></a>控制台分析</h3><p>从控制台打印的日志可以看出模型在训练过程中的对数似然性（Log-Likelihood）逐步增大，并在迭代次数较少时就收敛到一个较小的负值。最后，模型在测试集上的评估结果显示准确率（Accuracy）、精确率（Precision）和召回率（Recall）均为1.0，即100%。</p>\n<p>对于对数似然性的变化：</p>\n<ul>\n<li>在训练初始阶段（Step 0到Step 100），对数似然性从一个较大的负值逐渐减小，说明模型的拟合效果在改进，损失逐渐减小。</li>\n<li>在训练中期（Step 100到Step 500），对数似然性下降幅度较大，模型在这个阶段学习到了较多的特征权重，开始更好地拟合训练集。</li>\n<li>在训练后期（Step 500到Step 900），对数似然性下降速度减缓，模型接近收敛。这时候模型已经较好地拟合训练集，但仍然可能存在一些小的误差。</li>\n</ul>\n<p>对于评估结果：</p>\n<ul>\n<li>准确率、精确率和召回率均为1.0，表示模型在测试集上的分类结果完美地匹配了真实标签。准确率表示模型正确分类样本的比例，精确率表示模型预测为正类的样本中真正为正类的比例，召回率表示模型正确识别正类样本的比例。这些指标都为1.0表明模型对于’Setosa’类别的预测完全正确，没有产生误分类。</li>\n</ul>\n<p>综合来看，这个结果可能存在一些问题：</p>\n<ol>\n<li><strong>数据集可能过于简单</strong>：鸢尾花数据集相对简单，可能存在较强的线性关系，使得逻辑回归模型能够在这个数据集上表现得很好。</li>\n<li><strong>过拟合</strong>：虽然在测试集上表现良好，但模型可能在训练集上过拟合，过度拟合了训练集的特点，导致在测试集上泛化能力较差。</li>\n</ol>\n<p>为了更好地评估模型性能，你可以进行交叉验证和尝试使用其他复杂度较高的数据集。交叉验证能够更全面地评估模型的泛化能力，复杂度较高的数据集能够更好地反映模型在现实场景中的表现。同时，尝试调整学习率、迭代次数等超参数，观察对模型性能的影响。这样可以更全面地评估模型的性能，并找到合适的模型和参数组合。</p>\n","feature":true,"text":"所以说第一行打不了字是吧，莫名其妙。（不用管这一行，刚刚发现我的编辑器第一行莫名其妙打不了字，所以你看到的这是第二行，很烦） 昨天我学习了逻辑回归，今天就要实战一下啦！因为光看纸上的知识总感觉有点枯燥，咱们动手试试，把学到的知识化为力量吧！今天我们要玩的游戏是逻辑回归，而游戏场地...","link":"","photos":[],"count_time":{"symbolsCount":"11k","symbolsTime":"10 mins."},"categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","count":9,"path":"api/tags/Machine-Learning.json"},{"name":"笔记","slug":"笔记","count":11,"path":"api/tags/笔记.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%9A%E9%B8%A2%E5%B0%BE%E8%8A%B1%E5%A4%A7%E5%86%92%E9%99%A9\"><span class=\"toc-text\">数据集：鸢尾花大冒险</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%87%86%E5%A4%87%E9%98%B6%E6%AE%B5%EF%BC%9A%E9%80%89%E5%8F%96%E6%88%91%E4%BB%AC%E7%9A%84%E2%80%9C%E6%B3%95%E5%AE%9D%E2%80%9D\"><span class=\"toc-text\">准备阶段：选取我们的“法宝”</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%AD%94%E6%B3%95%E5%87%86%E5%A4%87%EF%BC%9A%E5%AE%9A%E4%B9%89%E4%B8%80%E4%BA%9B%E6%9C%89%E8%B6%A3%E7%9A%84%E2%80%9C%E6%B3%95%E6%9C%AF%E2%80%9D\"><span class=\"toc-text\">魔法准备：定义一些有趣的“法术”</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%A4%A7%E5%86%92%E9%99%A9%E5%87%86%E5%A4%87%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86\"><span class=\"toc-text\">大冒险准备：数据预处理</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%8F%82%E6%95%B0%EF%BC%9A%E9%80%89%E4%B8%AA%E5%A5%BD%E6%AD%A6%E5%99%A8%EF%BC%8C%E5%87%86%E5%A4%87%E6%88%98%E6%96%97\"><span class=\"toc-text\">参数：选个好武器，准备战斗</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%8E%A2%E7%B4%A2%E6%88%90%E6%9E%9C%EF%BC%8C%E8%AF%84%E4%BC%B0%E8%A1%A8%E7%8E%B0%EF%BC%81\"><span class=\"toc-text\">探索成果，评估表现！</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96\"><span class=\"toc-text\">数据可视化</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%BB%93%E8%AE%BA\"><span class=\"toc-text\">结论</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%9B%BE%E7%89%87%E5%88%86%E6%9E%90\"><span class=\"toc-text\">图片分析</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%8E%A7%E5%88%B6%E5%8F%B0%E5%88%86%E6%9E%90\"><span class=\"toc-text\">控制台分析</span></a></li></ol></li></ol>","author":{"name":"General_K1ng","slug":"blog-author","avatar":"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/avatar.png","link":"/","description":"一名正在努力学习计算机的菜鸟","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/svg/BILIBILI.svg","link":"https://space.bilibili.com/32927332"},"csdn":{"icon":"/svg/csdn.svg","link":"https://blog.csdn.net/qq_34849354"},"github":{"icon":"/svg/GitHub.svg","link":"https://github.com/GeneralK1ng"},"QQ":{"icon":"/svg/QQ.svg","link":"tencent://AddContact/?fromId=45&fromSubId=1&subcmd=all&uin=2645370205"}}}},"mapped":true,"prev_post":{"title":"一些题外话","uid":"005491f74262b9b4c835e159a3d618ac","slug":"Some-Digression","date":"2023-07-20T06:30:32.000Z","updated":"2023-07-20T07:17:14.766Z","comments":true,"path":"api/articles/Some-Digression.json","keywords":null,"cover":"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/jianyue.png","text":"这章节的在课程的笔记里面就是叫题外话，因为和下一节都比较短，所以我就放到一起来记录。 题外话：感知机学习算法咱们现在稍微偏离一下主题，来简单探讨一种历史上颇具趣味的算法，同时在后面学习理论的时候也会再次回到它。这个算法是从逻辑回归方法修改而来，以强制其输出值为 0 或 1。为了实...","link":"","photos":[],"count_time":{"symbolsCount":"1.8k","symbolsTime":"2 mins."},"categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","count":9,"path":"api/tags/Machine-Learning.json"},{"name":"笔记","slug":"笔记","count":11,"path":"api/tags/笔记.json"}],"author":{"name":"General_K1ng","slug":"blog-author","avatar":"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/avatar.png","link":"/","description":"一名正在努力学习计算机的菜鸟","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/svg/BILIBILI.svg","link":"https://space.bilibili.com/32927332"},"csdn":{"icon":"/svg/csdn.svg","link":"https://blog.csdn.net/qq_34849354"},"github":{"icon":"/svg/GitHub.svg","link":"https://github.com/GeneralK1ng"},"QQ":{"icon":"/svg/QQ.svg","link":"tencent://AddContact/?fromId=45&fromSubId=1&subcmd=all&uin=2645370205"}}}},"feature":true},"next_post":{"title":"分类与逻辑回归","uid":"4c5f4ebe8f68ff24ce30098465671f7c","slug":"Classification-and-logistic-regression","date":"2023-07-18T09:41:28.000Z","updated":"2023-07-18T11:40:45.100Z","comments":true,"path":"api/articles/Classification-and-logistic-regression.json","keywords":null,"cover":"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/jianyue.png","text":"在机器学习的广袤领域中，分类问题犹如一片神秘的森林，吸引着众多探险家的目光。我们可以将自己想象成一位勇敢的森林导游，带领着各种生物来到分类问题的奇妙世界。 什么是分类问题？在这片森林中，我们将聚焦于探讨分类问题。这与我们之前遇到的回归问题有些相似，但又有所不同。在分类问题中，我们...","link":"","photos":[],"count_time":{"symbolsCount":"4.2k","symbolsTime":"4 mins."},"categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","count":9,"path":"api/tags/Machine-Learning.json"},{"name":"笔记","slug":"笔记","count":11,"path":"api/tags/笔记.json"}],"author":{"name":"General_K1ng","slug":"blog-author","avatar":"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/avatar.png","link":"/","description":"一名正在努力学习计算机的菜鸟","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/svg/BILIBILI.svg","link":"https://space.bilibili.com/32927332"},"csdn":{"icon":"/svg/csdn.svg","link":"https://blog.csdn.net/qq_34849354"},"github":{"icon":"/svg/GitHub.svg","link":"https://github.com/GeneralK1ng"},"QQ":{"icon":"/svg/QQ.svg","link":"tencent://AddContact/?fromId=45&fromSubId=1&subcmd=all&uin=2645370205"}}}}}}