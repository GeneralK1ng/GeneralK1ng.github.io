[{"id":"359c9a1a9e0f8b70b5c766d3c5f40981","title":"Java_Exercise(Week 2)","content":"Exercise #2.1 What day is it?编写一个 Java 程序，将日期作为输入，并打印出该日期所在星期的哪一天。\n程序应使用三个整数：y（年）、m（月）和 d（日）。对于 m，1 月用 1，2 月用 2，以此类推。对于输出，周日打印 0，周一打印 1，周二打印 2，以此类推。\n使用以下公式：\n\n\n\n\n测试用例：\nTest case 1:\nInput:\n2018\n12\n24\nOutput: \nIt's day 1 !\n\n解决给出来的一些程序问题，毕竟我们不牵扯算法的问题，公式和算法都已经给你呈现了，我们要做的只是把公式翻译成Java语言就行了，只要看好输入输出的测试用例，然后注意一下公式的表达，基本上不会出什么问题。\n代码如下：\n\nClick to see more\nimport java.util.Scanner; //牵扯到输入，所以必须导入Scanner包\n\npublic class DateToDay {\n    public static void main(String[] args) { //main方法入口\n        Scanner sc = new Scanner(System.in); // 创建Scanner的对象\n        int y = sc.nextInt(); \n        int m = sc.nextInt();\n        int d = sc.nextInt(); //调用方法分别记录输入的y,m,d的值\n\n        int a = y - (14 - m) / 12; \n        int b = a + a/4 - a/100 + a/400;\n        int c = m + 12 * ((14 - m) /12) - 2; //分别将录入的值用a,b,c来记录，便于公式的表达\n\n        int day = (d + b + (31 * c) / 12) % 7; //带入公式\n\n        System.out.println(\"It's day \" + day + \" !\"); //控制台输出，注意输出时的空格\n    }\n}\n\n\n\nExercise #2.2 CMYK to RGB有几种不同的格式用于表示颜色。您可能知道 RGB 格式，它在 0 到 255 的整数范围内指定红色 (R)、绿色 (G) 和蓝色 (B) 的级别。还有一种格式叫 CMYK 格式，它规定了青色 (C)、洋红色 (M)、黄色 (Y) 和黑色 (K) 在 0.0 到 1.0 的实数范围内的级别。\n\n编写一个 Java 程序，使用以下公式将 CMYK 格式转换为 RGB 格式：白 = 1 - 黑红色 = 255 × 白色 × (1 - 青色)绿 = 255 × 白 × (1 - 洋红)蓝 = 255 × 白 × (1 - 黄)\n您的程序必须输入青色、洋红色、黄色和黑色这四个数字；计算相应的 RGB 值，每个值都四舍五入为最接近的整数；并按下面的测试用例打印 RGB 值：\nTest case 1:\nInput:  \n0.0\n0.0\n1.0\n0.0\nOutput: \nred = 255\ngreen = 255\nblue = 0\n\nTest case 2:\nInput:\n0.0\n1.0\n0.75\n0.50\nOutput:\nred = 128\ngreen = 0\nblue = 32\n\n\n\n这道题比上一道提升了一点难度，但是难度不大，还是重点在于搞清楚变量之间的关系，并且有一些小坑注意避免，所以这道题的代码分开写便于理解。\n\nClick to see more\n首先我们先分析题目吧，说白了，让你按照公式把几个值进行转换，然后打印输出，公式都给你了，那就直接照着公式打吧：\n首先我们先要键盘录入，然后再来接受键盘录入的值，分别是青色，洋红色，黄色和黑色。\nScanner sc = new Scanner(System.in); //创建Scanner的对象\ndouble cyan = sc.nextDouble();\ndouble magenta = sc.nextDouble();\ndouble yellow = sc.nextDouble();\ndouble black = sc.nextDouble(); //用double来接受录入的值\n\n然后我们再开始按照公式进行转换\ndouble white = 1 - black;\ndouble red = 255 * white * (1 - cyan);\ndouble green = 255 * white * (1 - magenta);\ndouble blue = 255 * white * (1 - yellow);\n\n照着公式打应该是不会打错的，比较容易出错的一步就是要打印输出，我们先写一下吧\nSystem.out.println(\"red = \" +  red);\nSystem.out.println(\"green = \" + green);\nSystem.out.println(\"blue = \" + blue);\n\n看上去好像没问题啊，那我们先拿第一个测试用例试一下\n输出如下：\nred = 255.0\ngreen = 255.0\nblue = 0.0\n\n看上去好像没问题对不对？但是其实是错的，其实看一下预期发现应该是整数类型而不是double，那这不简单嘛，那前两天刚学了基本数据类型的强转，那我们来强转一下一定行，hh\nSystem.out.println(\"red = \" +  (int)red);\nSystem.out.println(\"green = \" + (int)green);\nSystem.out.println(\"blue = \" + (int)blue);\n\n这样一定行了吧，第一个测试用例确实通过了，但是第二个呢？\n输出如下：\nred = 127\ngreen = 0\nblue = 31\n\n发现了吗，blue的要求应该是32，而这里却输出了31，为什么？因为基本数据类型的强转当中，double转int是向下取整，而测试用例需要我们向上取整，这下发现了吧，我们应该使用的是Math.round()方法。\n完整的代码应该是这样：\nimport java.util.Scanner;\n\npublic class CMYKtoRGB {\n    public static void main(String[] args) {\n        Scanner sc = new Scanner(System.in);\n\n        double cyan = sc.nextDouble();\n        double magenta = sc.nextDouble();\n        double yellow = sc.nextDouble();\n        double black = sc.nextDouble();\n\n        double white = 1 - black;\n        double red = 255 * white * (1 - cyan);\n        double green = 255 * white * (1 - magenta);\n        double blue = 255 * white * (1 - yellow);\n\n        System.out.println(\"red = \" +  Math.round(red));\n        System.out.println(\"green = \" +  Math.round(green));\n        System.out.println(\"blue = \" +  Math.round(blue));\n\n\n    }\n}\n\n所以一定要看清测试用例，和明白问题关键在哪，学会自己分析问题。\n\n\nExercise #2.3 Great Circle Distance大圆距离是球面上两点和（x2,y2）之间最短路径的长度。\n计算公式如下。\n\n编写一个 Java 程序，输入四个复数 x1、y1、x2、y2，它们是地球表面两点的经度和纬度（以度为单位）；使用地球的平均半径 r = 6,371.0 千米；并打印出两点之间的大圆距离 dist（单位：千米）。\n请注意，输入的数字是以度为单位的，但 Java 的三角函数使用的是弧度。使用 Math.toRadians() 将度转换为弧度。\n测试用例如下：\nTest case 1:\nInput:\n80.0\n25.0\n155.0\n102.5\nOutput: \n7509.440708014122 kilometres\n\nTest case 2:\nInput:\n10.55\n39.33\n21.47\n-7.88\nOutput:\n5169.256612492542 kilometres\n\n这个题看着很吓人，但是其实还是最开始那句话，不要被题吓到，算法和公式不是我们需要考虑的问题，我们并不需要知道怎么才能用经纬度算出两点之间的距离，根本不需要数学和物理知识，你只需要如何把公式翻译成代码就好，程序员最最重要的一点就是要明白需求，而不是想别的。\n首先看到题目，肯定我们需要有键盘录入，其次接收的变量类型应该是double，再然后就是一个非常长的公式，仔细的打出来就好。\n\nClick to see more\n首先我们还是要先创建变量来接收键盘录入的值，分别有四个x1、y1、x2、y2，必须用double。\nScanner sc = new Scanner(System.in);\n\ndouble x1 = sc.nextDouble();\ndouble y1 = sc.nextDouble();\ndouble x2 = sc.nextDouble();\ndouble y2 = sc.nextDouble();\n\n然后必须要注意题目里面已经给你提醒了，我们Java程序用的是弧度制，我们的输入都是角度，必须用 Math.toRadians() 来进行转换，为了我的代码更加的简洁，优雅（如何写优雅的代码可以看上一章）我们可以这样写：\ndouble x1 = Math.toRadians(sc.nextDouble());\ndouble y1 = Math.toRadians(sc.nextDouble());\ndouble x2 = Math.toRadians(sc.nextDouble());\ndouble y2 = Math.toRadians(sc.nextDouble());\n\n我们把键盘录入的值直接传递给 Math.toRadians() 这个函数，然后这个函数返回的值直接赋值给我们的这四个变量，简洁，优雅。\n接着我们再定义一个变量r用来表示地球的半径\ndouble r = 6371.0\n\n然后就是枯燥又考验细心的公式环节，这个公式很长很长，注意不要输错了，括号要保持清楚，所以我建议是在每个运算符之间要进行空格，便于查看和debug。\ndouble dist = 2 * r * Math.asin(Math.sqrt(Math.sin((x2 - x1)/2) * Math.sin((x2 - x1)/2) + Math.cos(x1) * Math.cos(x2) * Math.sin((y2 - y1)/2) * Math.sin((y2 - y1)/2)));\n\n然后我们输出即可，完整代码如下：\nimport java.util.Scanner; //导包\n\npublic class GreatCircleDistance {\n    public static void main(String[] args) {\n        Scanner sc = new Scanner(System.in); //新建对象\n\n        double x1 = Math.toRadians(sc.nextDouble());\n        double y1 = Math.toRadians(sc.nextDouble());\n        double x2 = Math.toRadians(sc.nextDouble());\n        double y2 = Math.toRadians(sc.nextDouble());//用变量接收转换为弧度的键盘录入的值\n\n        double r = 6371.0;//定义地球半径\n\n        double dist = 2 * r * Math.asin(Math.sqrt(Math.sin((x2 - x1)/2) * Math.sin((x2 - x1)/2) + Math.cos(x1) * Math.cos(x2) * Math.sin((y2 - y1)/2) * Math.sin((y2 - y1)/2))); //痛苦的公式\n\n        System.out.println(dist + \" kilometres\");//输出\n    }\n}\n\n不是很难。\n\n\nCW1 #2.1 Area of a Pentagon给定 r = 五角形中心到顶点的长度（实数），编写一个 Java 程序，计算五边形的面积。\n\n五边形面积的计算公式是其中，s 是边长，计算公式为测试用例：\nTest case 1:\nInput:\n2.5\nOutput: \nArea = 14.86025806711178\n\nTest case 2:\nInput:\n1.0\nOutput:\nArea = 2.377641290737884\n\n相比前面的这个感觉其实根本没什么难度，还是强调那句话，公式都有了，翻译就好。\n代码如下：\n\nClick to see more\nimport java.util.Scanner; //导包\n\npublic class AreaOfAPentagon {\n    public static void main(String[] args) { //主入口\n        Scanner sc = new Scanner(System.in); //新建对象\n\n        double r = sc.nextDouble(); //接收键盘录入\n        double s = 2 * r * Math.sin(Math.PI / 5); //带入公式\n\n        double area = (5 * s * s) / (4 * Math.tan(Math.PI / 5)); //带入公式\n\n        System.out.println(\"Area = \" + area); //输出\n    }\n}\n\n\n\n这次的作业感觉就是lab的一次强化练习吧。\n","slug":"Java-Exercise-Week2","date":"2023-09-22T08:43:31.000Z","categories_index":"","tags_index":"笔记,Java初学","author_index":"General_K1ng"},{"id":"4b98df5a945ea20ec148c80f048ac74c","title":"Java_Learning(Week2)","content":"变量是什么？变量是计算机编程中的一个基本概念，用于存储和表示数据。变量是程序中用来保存数据的一种标识符，它可以是数字、文本、对象或任何其他数据类型的值。通过给变量赋值，程序可以在运行过程中存储、操作和使用数据。\n数据类型在Java中，变量可以分为以下几种主要类型：\n\n原始数据类型（Primitive Data Types）： 用于存储单一的数值，例如整数、浮点数、字符和布尔值。Java的原始数据类型包括int、double、char、boolean等。\n引用数据类型（Reference Data Types）： 用于存储对象的引用。这些变量不直接存储对象的数据，而是存储对象在内存中的地址。Java的引用数据类型包括类（Class）、接口（Interface）、数组（Array）等。\n\n原始数据类型（Primitive Data Types）：\nbyte（字节）：\n大小：8位（1字节）\n范围：-128 到 127\n用途：通常用于节省内存，存储小整数值。\n\n\nshort（短整数）：\n大小：16位（2字节）\n范围：-32,768 到 32,767\n用途：存储中等范围的整数。\n\n\nint（整数）：\n大小：32位（4字节）\n范围：-2^31 到 2^31-1\n用途：存储整数值，是最常用的整数数据类型。\n\n\nlong（长整数）：\n大小：64位（8字节）\n范围：-2^63 到 2^63-1\n用途：用于存储大整数值，通常用于需要大范围整数的情况。\n\n\nfloat（浮点数）：\n大小：32位（4字节）\n用途：存储小数值，具有单精度，通常用于科学计算和工程计算中。\n\n\ndouble（双精度浮点数）：\n大小：64位（8字节）\n用途：存储小数值，具有双精度，通常用于大多数浮点数计算。\n\n\nchar（字符）：\n大小：16位（2字节）\n范围：0 到 65,535\n用途：存储单个字符，例如字母、数字或符号。\n\n\nboolean（布尔值）：\n大小：取决于实现\n只有两个值：true 和 false\n用途：表示真假值，通常用于条件判断。\n\n\n\n引用数据类型（Reference Data Types）：引用数据类型是指对象类型，它们不直接存储数据，而是存储对对象的引用。常见的引用数据类型包括类（Class）、接口（Interface）、数组（Array）等。这些类型的变量存储的是对象的引用地址，而不是对象的实际数据。\n变量的声明与初始化为什么要声明变量？为什么要声明变量呢？声明变量是为了告诉编译器变量的名称、类型和内存分配。在Java中，声明变量有以下重要原因：\n\n类型检查： 声明变量可以让编译器检查代码中的类型错误。如果你尝试将不兼容的数据类型赋给一个已声明的变量，编译器会直接报错。\n内存分配： 声明变量让编译器知道需要为该变量分配多少内存空间。这是因为不同数据类型需要不同大小的内存来存储。\n代码可读性： 变量声明可以提高代码的可读性。通过看变量名和类型，其他开发人员可以更容易地理解代码的用途和意图。\n作用域控制： 变量的声明还确定了变量的作用域，即在哪些部分的代码中可以访问该变量。作用域规则有助于防止变量被误用或滥用。\n\n在Java中，变量的声明通常包括变量名和类型，例如：\nint age; // 声明一个整数变量\ndouble salary; // 声明一个双精度浮点数变量\nString name; // 声明一个字符串变量\n\n在声明后，可以使用赋值语句将值分配给变量，这一步称为变量的初始化，例如：\nage = 30; // 将值30赋给age变量\nsalary = 50000.0; // 将值50000.0赋给salary变量\nname = \"Jin\"; // 将字符串\"Jin\"赋给name变量\n\n什么是变量的初始化？变量的初始化是指在声明变量的同时给它一个初始值。在Java中，可以选择性地在声明时初始化变量，也可以在稍后的代码中初始化。如果不初始化变量，它们将具有默认值，这取决于变量的数据类型。例如，int类型的变量默认初始化为0，boolean类型的变量默认初始化为false，Object类型的变量默认初始化为null。\n声明变量的要求\n变量名称规则： 变量的名称必须遵循一定的命名规则。变量名称可以包含字母、数字、下划线（_）和美元符号（$），但必须以字母、下划线或美元符号开头，不能以数字开头。变量名称区分大小写，即myVariable和myvariable是不同的变量名。\n关键字冲突： 变量名称不能与Java的关键字（保留字）相同。例如，不能使用关键字int作为变量名。\n合法标识符： 变量名称必须是合法的标识符。这意味着变量名称不能包含空格、特殊字符（如@、#、%等），也不能是Java中已经定义的类名、方法名等标识符。\n类型声明： 变量的声明必须包括其数据类型。数据类型确定了变量可以存储的数据种类和范围。例如，int、double、String等都是合法的数据类型。\n唯一性： 在同一个作用域内，变量名必须是唯一的。不能在同一作用域内声明两个同名的变量。\n声明语法： 变量的声明语法为：数据类型 变量名;。例如，int age;声明了一个整数类型的变量名为age。\n\n什么是包装类？课件当中还提到了一个难以理解的概念，就是包装类（Wrapper Class），如果目前无法理解其实无所谓，在后续的泛型部分应该会详细讲，这里我就提一下。\n在Java中，每种原始数据类型都有对应的包装类（Wrapper Class），用于将原始数据类型封装成对象。这些包装类提供了一些额外的功能，例如在集合类中存储原始数据类型的值，以及执行一些与对象相关的操作。以下是原始数据类型和其对应的包装类：\n\n\n\n\n\n\n\n\n\n对象的概念很重要，但是要理解也非常的抽象，需要长时间的感觉，所以我会在后面的笔记中渗透一些面向对象的内容，理解什么是对象，什么是面向对象。\n\n\n\n原始数据类型\n对应的包装类\n\n\n\nbyte\nByte\n\n\nshort\nShort\n\n\nint\nInteger\n\n\nlong\nLong\n\n\nfloat\nFloat\n\n\ndouble\nDouble\n\n\nchar\nCharacter\n\n\nboolean\nBoolean\n\n\n包装类的用处这一段我去找的资料，看个乐就行，反正现在看不懂非常正常。\n\n将原始数据类型转换为对象： 原始数据类型是基本的数据类型，不能直接用于面向对象编程（OOP）。包装类允许将原始数据类型封装成对象，从而可以在对象上执行各种操作。\n在集合中存储原始数据类型： Java集合（如ArrayList、HashMap等）只能存储对象，而不能存储原始数据类型。包装类使得可以将原始数据类型的值存储在集合中，因为它们都是对象。\n提供额外的功能和方法： 包装类提供了许多有用的方法，这些方法可以用于执行各种操作，如转换为字符串、比较、数学运算等。这些方法使得在处理数据时更加灵活和方便。\n处理空值（null）： 包装类可以存储null值，这在某些情况下非常有用，例如表示缺失数据或处理可能为null的情况。\n支持泛型（Generics）： 在泛型代码中，只能使用对象类型，而不是原始数据类型。包装类允许您在泛型类中使用原始数据类型的值。\n与其他API的兼容性： 某些Java API和库只接受对象作为参数，这时您需要使用包装类将原始数据类型封装成对象以便与这些API进行交互。\nJava反射： 反射是一种机制，可以在运行时检查和操作类的属性和方法。包装类使得可以通过反射机制来访问原始数据类型的信息和值。\n\n再强调一遍，看不懂无所谓的！\n如果让我用大白话来说，包装类无非是为了让Java当中的一些操作更加灵活和方便。\n类型转换在Java中，数据类型转换是将一个数据类型的值转换为另一个数据类型的过程。数据类型转换通常涉及到原始数据类型之间的转换以及对象之间的转换。Java中的数据类型转换可以分为两种类型：隐式转换（Implicit Conversion）和显式转换（Explicit Conversion）。\n隐式转换（Implicit Conversion）：隐式转换是自动进行的类型转换，不需要显式指定，通常发生在以下情况：\n\n小类型到大类型： 当将一个小范围的数据类型转换为一个大范围的数据类型时，会发生隐式转换。例如，将一个int赋值给long，或将一个float赋值给double。\n整数到浮点数： 当将整数类型转换为浮点数类型时，会发生隐式转换。例如，将int赋值给float。\n字面量常量转换： 在赋值常量字面量时，会进行隐式转换。例如，将整数字面量42赋值给long类型的变量。\n表达式中的类型提升： 在表达式中，如果包含多个操作数，它们的数据类型会自动提升到更大的数据类型，以便执行操作。这种提升也是隐式转换的一部分。\n\n隐式转换是安全的，因为它不会导致数据丢失。例如，将int转换为long不会导致数据精度损失。\n显式转换（Explicit Conversion）：显式转换需要通过强制类型转换操作符（cast）来明确指定。它通常用于以下情况：\n大类型到小类型： 当将一个大范围的数据类型转换为一个小范围的数据类型时，需要进行显式转换。这可能导致数据精度损失，因此需要程序员明确表示他们知道潜在的风险。例如，将double强制转换为int。\ndouble d = 3.14;\nint i = (int) d; // 显式转换，将double转换为int，会损失小数部分\n\n对象之间的转换： 当需要将一个对象从一种类转换为另一种类时，需要进行显式转换。这需要使用强制类型转换操作符，并确保类型之间存在继承关系或实现关系。\n// 显式将父类引用转换为子类引用\nParentClass parent = new ChildClass();\nChildClass child = (ChildClass) parent; // 显式转换\n\n字符到整数的转换： 当需要将字符类型（char）的字符表示为其对应的Unicode码点时，需要进行显式转换。\nchar c = 'A';\nint unicode = (int) c; // 显式转换，将字符'A'转换为Unicode码点65\n\n总结一下就是，显式转换别乱用，比较容易出错的，隐式转换JVM都帮你完成了，你只需要操点心就行。\n什么是转义符？看了看我们的课件，第一周的Lab和后面的一些练习当中就出现了转义符的相关知识，那就来了解一下好了。\n在计算机编程中，转义符是一种特殊字符，通常用来表示一些特殊的字符或控制字符序列。转义符以反斜杠符号（\\）开头，后跟一个或多个字符，用于表示不容易直接输入或显示的字符。转义符的主要目的是允许你在字符串或字符常量中插入特殊字符，或者执行某些控制操作。\n以下是一些常见的转义符及其用途：\n\n\\n： 表示换行符，用于在文本中创建新的一行。\n\\t： 表示制表符，用于在文本中创建水平制表符（通常用于缩进文本）。\n\\r： 表示回车符，用于将光标移到行的开头。\n\\b： 表示退格符，用于删除光标前的字符。\n\\f： 表示换页符，通常在控制打印机输出时使用。\n\\： 表示反斜杠自身，用于在字符串中插入反斜杠字符。\n‘： 表示单引号字符，用于在字符常量中插入单引号。\n“： 表示双引号字符，用于在字符串中插入双引号。\n\\uXXXX： 表示Unicode转义序列，其中XXXX是一个四位十六进制数，用于表示特定的Unicode字符。例如，\\u0041表示字符’A’。\n\n使用转义符可以在字符串中插入特殊字符，从而实现格式化文本、创建多行文本、处理特殊字符等目的。例如，要创建一个包含换行的多行字符串，可以使用\\n转义符，如下所示：\nString multiLineString = \"This is the first line.\\nThis is the second line.\";\nSystem.out.println(multiLineString);\n\n或者你要是想要在打印输出的时候输出双引号本身，你就可以在需要输出的双引号前加上\\。\npublic static void main(String[] args) {\n\t\tSystem.out.println(\"Hello world!\");\n        System.out.println(\"\\\"Hello world!\\\"\");\n    }\n\n最后就会输出\nHello world!\n\"Hello world!\"\n\n所以其实没啥重要的知识，忘了自己上网查就好。\n良好的编程习惯！这一部分非常的重要，好的习惯养成就是在最开始学习编程的时候养成的，不然后续很多的坏习惯可能会导致团队协作，项目开发，版本维护等等等问题，所以这一部分还是挺重要的。\n我们的最终的目的是可以编写优雅的代码，什么样子的代码可以称得上优雅？\n\n有意义的变量名： 变量名应该能清晰地表达变量的用途和含义。避免使用单个字母或无意义的缩写。例如，使用totalAmount而不是amt，使用customerName而不是cn。尤其是很多国人，千万不要用拼音来，其实拼音还好，最怕的是用拼音缩写，真的逆天，记住一定要让别人和你自己都能看懂，为什么说你自己呢？因为在编程当中有一句话：“刚写完的代码只有我和上帝看得懂，一周后，只有上帝看得懂。。。”如果养成了良好习惯，就能极大程度的避免这一点，并且后期工作一般是很多人来维护同一个项目，如果你的变量名很抽象，很容易导致团队合作的脱节。\n注释： 使用注释来解释代码的意图和关键部分，但不要过度注释。注释应该是清晰、简洁、易于理解的。及时更新注释以反映代码的变化。我平时最讨厌两种人，一种是让我加注释的，另一种是不让我加注释的XD。\n缩进和格式化： 使用一致的缩进和代码格式化规范，以增加代码的可读性。使用空格或制表符进行缩进，选择一种风格并保持一致。一定要缩进，一定要换行！不然问别人问题别人都不想给你看。\n函数和方法： 函数和方法应该短小而专注于单一任务。遵循单一职责原则（SRP）。使用有意义的函数名，并确保函数的命名与其功能一致。记住，一个函数或者方法只干一件事，实现功能的时候一定是越细化越好，现在可能看不出来，但是一旦到了大型项目，这样的好处就体现出来了，可以快速定位bug，快速针对功能进行更新，修改，删除。\n避免魔法数值： 避免在代码中直接使用未经解释的魔法数值。使用常量或枚举类型来表示这些数值，并为其命名以提高代码的可维护性。魔法数值就是直接把一个数字写到代码里面，这会非常的致命。\n异常处理： 始终处理可能引发异常的情况。不要忽略异常或简单地将其抛出。使用try-catch块或throws声明来处理异常。等我们学到异常之后就能理解了，现在可以先不用管。\n代码复用： 遵循”不要重复自己”（DRY）原则，将常用的代码块提取到函数、方法或类中以便复用。\n代码测试： 编写单元测试来验证代码的正确性。自动化测试可以帮助及早发现和修复问题。每次写完一个部分，或者一个小功能时候养成一个习惯针对这一部分写几个测试用例来验证一下，可以有效降低bug率。\n版本控制： 使用版本控制系统（如Git）来跟踪代码的历史记录和更改。提交代码前进行代码审查。\n命名约定： 遵循命名约定，例如Java中的驼峰命名法（camelCase），以及类名以大写字母开头等。\n文档化： 编写文档来描述项目、模块、函数和方法的用法和API。这有助于其他开发人员理解和使用你的代码。\n性能考虑： 在编写代码时考虑性能问题，但不要过度优化。只有在有明确性能问题时才进行优化。采访过一位大佬，代码的易读性&gt;代码的性能。\n安全性： 注意代码的安全性，避免常见的安全漏洞，如SQL注入、跨站脚本（XSS）等。\n错误处理： 考虑错误处理策略，包括日志记录和向用户提供有用的错误信息。\n持续学习： 不断学习新的编程技术和最佳实践，保持对编程世界的好奇心和进取心。\n\n","slug":"Java-Learning-week2","date":"2023-09-18T13:14:43.000Z","categories_index":"","tags_index":"笔记,Java初学","author_index":"General_K1ng"},{"id":"b6ddc4ee88d4afe7e2e1051d594b4d83","title":"Java_Learning(Week 1)","content":"整理CPT111这门课程（Java Programming）的一些笔记，从最简单的开始，不是简单的翻译，但是还是会以学校进程和教材为主。\n选择一个趁手的IDE在我们选择IDE前，容我先简单介绍一下什么是IDE，为什么我们需要IDE。\n什么是IDE？IDE是集成开发环境（Integrated Development Environment）的缩写。是一种软件应用程序，旨在帮助程序员编写、调试和管理他们的代码项目。IDE为开发者提供了一套工具和功能，使他们更轻松地进行软件开发工作。以下是IDE的一些主要特点和功能：\n\n代码编辑器：IDE包含一个文本编辑器，用于编写源代码。这个编辑器通常会提供语法高亮显示、自动完成、代码格式化等功能，以帮助程序员编写更高效和规范的代码。\n编译器和解释器：IDE集成了编译器（对于编译型语言）或解释器（对于解释型语言），可以将源代码转换为可执行的程序或直接执行代码。这使得程序员可以更轻松地检查代码的语法错误和逻辑错误。\n调试器：IDE通常包含一个强大的调试器，用于帮助程序员识别和修复代码中的错误。调试器允许程序员逐步执行代码、查看变量的值，并在运行时检测问题。\n项目管理工具：IDE允许程序员创建和管理代码项目。这包括创建、打开、保存和组织文件和文件夹，以及管理依赖项和库。\n版本控制集成：许多IDE集成了版本控制工具，如Git，以便程序员能够更轻松地跟踪和管理代码的版本历史。\n自动化构建工具：IDE通常包含自动构建工具，可以自动构建和部署代码项目，减少了手动操作的需求。\n代码分析工具：IDE可以提供代码分析和性能分析工具，帮助程序员识别潜在的性能瓶颈和代码质量问题。\n集成开发环境：IDE将上述所有功能整合在一个统一的界面中，使程序员能够在一个环境中进行所有开发活动，提高了工作效率。\n\n我们为什么需要IDE？总结两个字，方便！方便就完事了，理论上你完全可以用电脑自带的笔记本进行代码的书写，但是我相信没有人会这么干，趁手的IDE可以大幅度提升你的开发效率和开发质量，并且可以帮助你更好的后期维护和debug(虽然这往往和IDE没有多大关系)。\n安装IDEAIntelliJ IDEA（通常称为IDEA）是一款由JetBrains开发的强大集成开发环境（IDE），主要用于Java、Kotlin和其他编程语言的开发。它具有许多优点，如智能代码编辑、强大的代码导航、集成的构建工具、版本控制、调试器和丰富的插件生态系统等。下面是安装IntelliJ IDEA的详细步骤：\n安装IntelliJ IDEA：\n\n下载IntelliJ IDEA： 前往JetBrains官方网站（ https://www.jetbrains.com/idea/download/ ），  选择适用于您操作系统的版本（Windows、macOS、Linux）并下载Community Edition（免费版本）或Ultimate Edition（付费版本）。初学者完全使用社区版本完全就够用了，虽然我们学校提供了教育免费版，如果不嫌麻烦的话也可以。\n安装JDK： IntelliJ IDEA需要Java Development Kit (JDK) 才能运行。虽然目前我知道好像IDEA可以自己给你装JDK，并且有很完备的版本管理，非常方便。\n安装IntelliJ IDEA：\n在Windows上，运行下载的安装程序（.exe文件）并按照提示进行安装。\n在macOS上，将下载的IntelliJ IDEA文件拖到“应用程序”文件夹中。\n在Linux上，解压下载的文件并运行idea.sh脚本。\n\n\n启动IntelliJ IDEA： 打开安装好的IntelliJ IDEA应用程序。\n激活或注册：\n如果你选择Ultimate Edition，并且有有效的许可证，可以直接输入许可证信息激活。\n如果你选择Community Edition，它是免费的，无需激活。\n\n\n配置首选项： 在首次运行IDEA时，您可以根据您的偏好配置IDEA的外观、主题、插件等设置。\n\n一些基本的设置自己上网搜索，比如字体，主题之类的，这里不作详细介绍。\n为什么不用学校推荐的NetBeans?我觉得难用，就是这么简单，难用，而且后续很多的企业开发当中基本上公司配备的Java用的IDE都是IDEA，你也不想特立独行吧？（\n打出你的第一句Hello Word！为什么要打出Hello World？别问，问就是传统。\n创建新项目\n打开IntelliJ IDEA。\n在欢迎屏幕上，选择 “Create New Project”（创建新项目）。\n\n\n\n配置项目\n在 “Project name”（项目名称）字段中输入您的项目名称，例如 “CPT111”。\n在 “Project location”（项目位置）字段中选择您要保存项目的文件夹位置。\n选择JDK，没有JDK就用IDEA给你装一个，免去了复杂的环境配置。\n点击 “Finish”（完成）。\n\n创建后的界面如下：\n\n运行其实这个默认的Main方法就是最普通的HelloWorld了，对着这个代码直接右键运行就好。\n\n简单解释一下代码与非常简单的Python不同，Java的 Hello World 令人有些费解，但是不急，逐行分析一下\npublic class Main {\n    public static void main(String[] args) {\n\n        System.out.println(\"Hello world!\");\n    }\n}\n\n\npublic：这是一个访问修饰符，表示这个类是公共的，可以从其他类中访问。在Java中，类通常会被声明为public、private或protected，以控制其可见性。\nclass：这个关键词用于定义一个类。在Java中，所有的代码都必须位于类中，这是面向对象编程的基本概念。\nHelloWorld：这是类的名称，通常类名的第一个字母大写。类名必须与文件名相匹配，并且在Java中，每个程序都必须包含至少一个类，其中一个类必须包含一个main方法，作为程序的入口点。\n{ 和 }：这些大括号用于定义类的开始和结束，以及方法的开始和结束。在Java中，大括号用于组织代码块。\npublic static void main(String[] args)：这是一个特殊的方法，叫做main方法。它是Java程序的入口点，当程序运行时，会从main方法开始执行。让我们来解释main方法的各个部分：\npublic：同样是访问修饰符，表示main方法是公共的，可以从其他类中访问。\nstatic：这是一个关键词，表示main方法是静态的，可以在不创建类的实例的情况下调用。\nvoid：这是返回类型，表示main方法不返回任何值。\nmain：这是方法的名称，Java程序会从这里开始执行。\n(String[] args)：这是方法的参数列表。在这里，main方法接受一个字符串数组作为参数，通常用来接收命令行参数。\n\n\nSystem.out.println(\"Hello, World!\");：这是main方法中的一行代码，用于在控制台上打印文本消息。让我们分解这行代码：\nSystem：这是一个类，代表了Java的系统资源和标准输入/输出。\nout：这是System类的一个静态成员，代表标准输出流。\nprintln：这是一个方法，用于将文本输出到标准输出流，并在最后自动添加一个换行符。\n\"Hello, World!\"：这是要打印的文本消息，包含在双引号中。\n\n\n\n如果这上面的你都不能理解，也别急，你只要知道System.out.println(\"Hello world!\")这一句是输出就好，也就是打印。\n","slug":"Java-Learning","date":"2023-09-18T08:56:41.000Z","categories_index":"","tags_index":"笔记,Java初学","author_index":"General_K1ng"},{"id":"f742bd6c1e232d7ef58dbc0bfbd5e353","title":"核方法","content":"核方法（Kernel Methods）“Kernel methods”（核方法）是机器学习领域中一类重要的算法和技术，它们主要用于处理非线性问题和高维数据。核方法在分类、回归和聚类等任务中具有广泛的应用，并在支持向量机（Support Vector Machines，SVM）等算法中发挥着关键作用。\n线性可分 vs. 线性不可分在介绍核方法之前，让我们先了解一下线性可分和线性不可分的概念：\n\n线性可分：在一个二分类问题中，如果可以通过一条直线（在二维空间中）或一个超平面（在高维空间中）将两类样本完美地分开，那么我们称该问题是线性可分的。\n线性不可分：如果两类样本在特征空间中不能被一条直线或一个超平面完美地分开，那么我们称该问题是线性不可分的。\n\n在传统的机器学习中，对于线性可分的问题，我们可以使用线性分类器（如感知机、逻辑回归、线性SVM等）来解决，它们在处理线性问题上表现良好。但对于线性不可分的问题，传统的线性分类器就会遇到困难，因为它们无法在原始的特征空间中找到合适的线性边界。\n核方法的核心思想是通过一个数学技巧，将原始的特征空间映射到一个更高维度的特征空间，使得在新的高维空间中，数据在某种意义上变得线性可分。这个数学技巧就是所谓的“核函数”。\n核函数是一种特殊的函数，它可以计算在高维特征空间中两个样本之间的相似度。通过核函数，我们可以在不显式计算高维特征空间中的数据点的情况下，直接在原始的低维特征空间中进行计算，从而大大节省了计算资源。\n一旦我们得到了在高维特征空间中的相似度，我们可以使用线性分类器（如线性SVM）来找到一个超平面，将样本分开。在原始的低维特征空间中，这个超平面对应于一个非线性边界，从而实现了对线性不可分问题的有效处理。\n常用的核函数包括线性核、多项式核、高斯核（径向基核函数），它们分别对应着不同的映射函数。通过选择适当的核函数，我们可以将核方法应用于不同类型的数据，并取得良好的分类性能。\n特征图（Feature Maps）在机器学习和核方法的上下文中，**”特征地图”（Feature Map）**是一个重要的概念，它与核函数密切相关。\n在介绍特征地图之前，我们先回顾一下核方法的基本思想：核方法通过使用核函数将原始的低维特征空间映射到一个高维特征空间，使得数据在高维空间中可能是线性可分的，然后在高维空间中使用线性分类器来处理原始的非线性问题。\n特征地图是与核函数对应的映射函数。具体地说，核函数  可以计算原始特征空间中两个样本  和  在高维特征空间中的内积（或称为相似度），即 ，其中  是特征地图函数。\n换句话说，给定一个核函数 ，我们可以找到一个特征地图函数 ，使得 。这样，我们就可以通过核函数的计算结果来隐式地得到样本在高维特征空间中的内积，而无需直接计算映射后的高维特征。\n举例来说，如果我们使用高斯核函数（径向基核函数），其形式为 ，那么相应的特征地图函数就是 。在这里，样本在高维特征空间中的内积  可以通过计算核函数  得到，而无需直接计算  和 。\n特征地图的引入使得核方法具有高效处理高维特征空间的能力，因为我们无需显式地计算映射后的高维特征，而只需计算核函数的结果。这在处理复杂的非线性问题时非常有用，因为在高维空间中，数据可能更容易线性可分，从而提高了分类和回归等任务的性能。\n举例回顾我们关于线性回归的讨论，我们考虑了从房屋的居住面积（用表示）预测房屋价格（用表示）的问题，并且将一个的线性函数拟合到训练数据。但是，如果价格可以更准确地表示为的非线性函数呢？在这种情况下，我们需要比线性模型更具表现力的模型族。\n我们开始考虑拟合三次函数 。实际上，我们可以将这个三次函数视为另一组特征变量的线性函数（如下所定义）。具体地说，令函数  定义为：这个函数将输入  映射成一个包含四个新的数字的向量。我们可以看到，这些数字分别是  和 。所以，当我们把房屋面积  输入到函数  中，我们得到一个新的向量，比如对于某个具体的房屋面积 ，我们会得到 。\n现在让我们来理解为什么这组数字又把房屋面积问题转换成了线性问题。原始问题是要预测房屋价格 ，它与房屋面积  之间的关系可能是一个复杂的三次函数。但是，当我们使用特殊的函数  将房屋面积  映射成新的特征向量  时，我们得到了一个新的问题。\n新问题是：如何用参数向量  中的四个数字  来表示房屋价格与新特征向量  之间的关系？换句话说，我们想找到一个线性模型来拟合这组新的特征。\n这个新的问题是线性的，因为我们的目标是找到四个数字 ，使得房屋价格  可以通过  来近似表示。这里的  表示参数向量  的转置， 是特征向量。所以这就变成了一个线性模型：我们只需要找到合适的  来使得  与房屋价格  尽可能接近即可。\n让 表示包含  的向量。那么我们可以将  的三次函数重写为：其中  是新的特征变量。因此， 的三次函数可以视为基于  的线性函数。为了区分这两组变量，在核方法的背景下，我们将“原始”输入值称为问题的输入属性（在本例中是 ，即房屋面积）。当原始输入映射到一组新的量  时，我们将称这些新的量为特征变量。（不幸的是，不同的作者在不同的上下文中使用不同的术语来描述这两个概念。）我们称  为特征图，它将属性映射为特征。\n通过这样的方式，我们把原始的非线性问题转化成了一个线性问题，使得我们可以用线性模型来处理这个新的特征空间。线性问题比非线性问题更容易解决，我们可以使用已知的数学方法来找到最佳的 ，从而得到一个在新特征空间中表现良好的模型。\n这就是特征地图的精妙之处：通过将原始特征映射到一个新的高维特征空间，我们可以使用线性模型来处理复杂的非线性关系，从而提高了模型的表现能力。核方法通过隐式计算高维特征空间中的内积，进一步简化了计算过程，使得在高维空间中处理问题变得高效。\n带有特征的最小均方（LMS with features）什么是带有特征的最小均方？“LMS” 是 “最小均方误差”（Least Mean Squares）的缩写。它是一种经典的优化算法，通常用于机器学习中的参数估计和模型训练。在这个算法中，我们尝试通过最小化均方误差来调整模型的参数，从而使得模型在训练数据上更好地拟合。\n“LMS with features” 指的是在 LMS 算法中使用特征来进行参数估计和模型拟合的版本。特征是用来表示数据的属性或变量，在机器学习中，我们通常会用特征来描述样本的特点，从而帮助模型理解和预测数据。\n在 “LMS with features” 中，我们假设模型的输出（或目标值）是由一组特征和模型的参数进行线性组合得到的。例如，如果我们用  表示样本的特征， 表示模型的参数，那么模型的输出可以表示为 。而 “LMS with features” 的目标就是通过最小化预测值与真实值之间的均方误差，来找到最优的参数 ，从而使得模型在训练数据上拟合得更好。\n“LMS with features” 算法通常是迭代的，它会根据预测结果和真实结果之间的误差来更新模型的参数。在每一次迭代中，模型会根据当前参数预测输出，并计算预测值与真实值之间的差距。然后，根据这个差距，算法会通过一定的学习率来调整参数的值，使得预测结果逐渐趋近于真实结果。\n这种算法被广泛用于线性回归和神经网络等机器学习模型的训练过程中。通过使用特征来表示数据，LMS 可以根据数据的特点来调整模型的参数，从而更好地适应不同的问题和数据集。\n推导我们将推导出用于拟合模型 的梯度下降算法。首先回忆一下，对于普通的最小二乘问题，我们要拟合 ，批量梯度下降的更新公式为（参见第一节课笔记以获取其推导）：在这里，每个变量的含义如下：\n\n 是我们要优化的参数向量，它用来拟合模型 。\n 是第  个训练样本的特征向量。\n 是第  个训练样本的真实标签或目标值。\n 是模型的预测值，即 。\n\n接下来，我们引入一个特征映射 ，它将属性 （在  中）映射到特征 （在  中）。这样，我们的目标就是拟合函数 ，其中  是  中的向量，而不是 。\n为了在特征映射下进行参数更新，我们将算法中所有出现的  替换为 ，得到新的参数更新公式：在这个公式中，每个变量的含义如下：\n\n 是我们要优化的参数向量，它用来拟合模型 。\n 是第  个训练样本在特征映射下的特征向量。\n 是第  个训练样本的真实标签或目标值。\n 是模型的预测值。\n\n这个新的更新公式可以用于梯度下降算法中的每一步迭代，以更新参数 ，从而逐渐使模型在训练数据上拟合得更好。特别地，如果我们使用随机梯度下降算法，即每次只用一个样本进行更新，更新规则变为：这样我们就得到了用于拟合模型  的梯度下降算法。这个算法在机器学习中非常常用，特别是在支持向量机（SVM）等模型中，它们使用了核方法和特征映射来处理非线性问题。\n举例当我们想预测房价时，最初使用了简单的线性模型 ，其中  是房屋的居住面积， 是房价， 和  是需要学习的参数。但有时候，房价可能不仅仅与面积成线性关系，可能是一种曲线或弯曲的关系，比如更大的房屋不仅仅是线性地增长更贵，可能有更多的因素在影响房价。所以我们需要更灵活的模型来适应这种复杂的关系。\n这时候，我们可以考虑使用一个三次函数来预测房价，就像  这样的函数。但是，我们仍然希望能够使用梯度下降这样的优化算法来找到最优的参数 。\n现在问题是，我们之前的梯度下降算法是针对线性模型设计的，而现在我们的模型是三次函数。这时，我们可以通过一个特殊的函数 ，将原来的房屋面积  映射成一个新的向量 ，我们把这个向量当做新的特征来处理。这样，我们的模型变成了 ，这就是一个线性模型！\n通过这个巧妙的映射，我们把原本的非线性问题转换成了线性问题。现在我们可以使用梯度下降算法来学习参数 ，使得预测的房价  尽可能接近真实的房价 。\n更新参数的公式为：在这里， 是我们需要学习的参数向量， 是一个房屋的面积特征， 是这个房屋的真实价格。 是学习率，它控制我们在每次更新中改变参数的步长。\n通过反复迭代这个更新过程，我们的模型会逐渐学到最优的参数 ，从而能够更好地拟合房价数据。这就是梯度下降算法的一个简单应用，通过特征映射的方式，我们可以在复杂的问题中使用线性模型来得到更好的预测结果。\n","slug":"Kernel-methods","date":"2023-07-29T07:55:10.000Z","categories_index":"","tags_index":"Machine Learning,笔记","author_index":"General_K1ng"},{"id":"8dcfbd65ba007c0c6564bd13d62b9cd1","title":"文本分类的事件模型","content":"文本分类的多项式事件模型在文本分类中，我们有一个专门的模型叫做多项式事件模型，它在处理文本分类问题时表现较好。这个模型与我们之前介绍的朴素贝叶斯有些相似，但也有一些不同之处。\n问题描述我们要解决的问题是对电子邮件进行分类，判断其是垃圾邮件还是正常邮件。对于一封电子邮件，我们可以将其表示为由单词组成的向量 ，其中  是第  个单词在词汇表中的标识， 是邮件中的单词总数。\n伯努利事件模型 vs. 多项式事件模型在文本分类的特定情境中，朴素贝叶斯的形式使用了所谓的伯努利事件模型（有时称为多变量伯努利事件模型）。在这个模型中，我们假设生成一封电子邮件的方式是：首先根据类先验概率  随机确定下一封邮件是垃圾邮件还是正常邮件。然后，发送电子邮件的人遍历字典，独立地根据概率  决定是否在邮件中包含每个单词 。因此，一封邮件的概率由  给出。\n这里介绍了另一种模型，称为多项式事件模型（Multinomial event model）。为了描述这个模型，我们将使用不同的符号和特征来表示电子邮件。我们用  表示邮件中第  个单词的标识。因此， 现在是一个取值范围为  的整数，其中  是我们词汇表（字典）的大小。一封由  个单词组成的电子邮件现在用长度为  的向量  来表示；请注意，不同文档的  可以不同。例如，如果一封电子邮件以 “A NeurIPS…” 开头，则 （“a”是字典中的第一个单词），（如果“neurips”是字典中的第35000个单词）。\n多项式事件模型的生成过程在多项式事件模型中，生成一封邮件的过程是这样的：\n\n根据类别先验概率  随机确定邮件是垃圾邮件还是正常邮件。\n通过从多项式分布  生成第一个单词 。\n然后，第二个单词  独立于 ，但仍从相同的多项式分布中生成。\n依此类推，直到生成所有  个单词的邮件。\n\n详细来说，首先根据  决定是否为垃圾邮件或非垃圾邮件，与之前相同。然后，邮件的发送者通过从某个多项式分布（）生成  来撰写邮件。接下来，第二个单词  独立于  但是从相同的多项式分布中选择，对于 、 等等，都是相同的过程，直到生成邮件的所有  个单词。因此，整体的邮件概率由  给出。请注意，这个公式看起来类似于之前在伯努利事件模型下给出的邮件概率公式，但公式中的术语现在具有非常不同的含义。特别地， 现在是一个多项式分布，而不是伯努利分布。\n我们新模型的参数与之前一样：、（对于任意 ）和。请注意，我们假设对于所有  的值，是相同的（即生成一个单词的分布不依赖于其在邮件中的位置 ）。\n参数估计我们的目标是通过训练集  来估计模型的参数。对于多项式事件模型，参数包括先验概率  和条件概率 。\n为了估计这些参数，我们最大化似然函数 。其中， 是类别先验概率， 和  分别是给定类别的条件概率。使用拉普拉斯平滑来获得更好的性能，参数估计公式如下：\n类别先验概率：垃圾邮件样本数总样本数\n条件概率：在垃圾邮件中出现的第个单词的样本数垃圾邮件中的单词总数在正常邮件中出现的第个单词的样本数正常邮件中的单词总数\n如果我们有一个训练集 ，其中  （这里， 是第  个训练样本中的单词数），数据的似然函数可以表示为：通过最大化这个似然函数，我们可以得到参数的最大似然估计：如果我们在估计和时应用拉普拉斯平滑（在实践中需要以获得良好的性能），我们将在分子中加1，在分母中加上，从而得到：\n朴素贝叶斯分类器尽管朴素贝叶斯分类器不一定是最优的分类算法，但由于其简单性和易于实现，通常在文本分类问题中表现出令人惊讶的良好效果。因此，它经常作为首选尝试的算法之一。\n通过以上的多项式事件模型和参数估计，我们可以构建一个朴素贝叶斯分类器，用于文本分类任务。希望这样的改写能够让您更好地理解文本分类问题及其相关模型。如果还有其他问题或需要进一步解释，请随时问我！\n","slug":"Event-models-for-text-classification","date":"2023-07-29T06:54:26.000Z","categories_index":"","tags_index":"Machine Learning,笔记","author_index":"General_K1ng"},{"id":"8b18e271b14b3d6ddbc293dffc4eb5b3","title":"拉普拉斯平滑","content":"解决稀疏数据问题：拉普拉斯平滑当我们用机器学习构建垃圾邮件过滤器时，朴素贝叶斯算法是一个强大的工具。然而，在实践中应用该算法时，我们可能会遇到一个小问题，那就是稀疏数据问题。\n稀疏数据问题是什么？稀疏数据问题出现在我们有大量特征，但某些特征在训练集中很少出现，甚至有些特征在某类邮件中根本没有出现。这就像探险家在茫茫大草原上追踪狼群，但是草原上的脚印却非常零散，有些地方甚至一点踪迹都没有。\n解决方案：拉普拉斯平滑为了解决这个问题，我们引入了拉普拉斯平滑（Laplace Smoothing）。这就像是在草原上找到了一种神奇的踪迹增强剂，让我们能够更好地跟踪狼群一样！\n在朴素贝叶斯算法中，我们需要估计特征在某个类别下的条件概率。在稀疏数据情况下，有些特征在训练集中可能没有出现，导致概率估计为零。为了避免这种情况，我们采用拉普拉斯平滑来平滑概率估计。\n改进朴素贝叶斯算法尽管朴素贝叶斯算法在许多问题上表现不错，但在某些特定情况下，特别是在文本分类任务中，它可能面临一些问题。让我们简要讨论当前形式下算法存在的问题，并探讨如何通过一种简单的改进来提高其性能。\n问题：稀疏数据假设我们在进行垃圾邮件/电子邮件分类问题，并且要使用朴素贝叶斯算法来进行分类。在假设情景中，你完成了CS229课程并在项目中取得优秀成绩，决定在20xx年5月20日前将你的工作提交给NeurIPS学术会议进行发表。由于你在邮件中讨论了该学术会议，你开始收到带有“neurips”一词的消息。但这是你的第一篇NeurIPS论文，直到此时为止，你之前没有收到过包含“neurips”一词的邮件；尤其是“neurips”一词从未出现在你的垃圾邮件/非垃圾邮件训练集中。假设“neurips”是词典中的第35000个单词，那么你的朴素贝叶斯垃圾邮件过滤器因此选择了参数φ_{35000|y}的最大似然估计为：这意味着因为在垃圾邮件或非垃圾邮件的训练示例中从未见过“neurips”，它认为在任何一类邮件中看到该单词的概率都是零。因此，当尝试判断一个包含“neurips”的消息是否为垃圾邮件时，它计算了类别的后验概率，并得到：这是因为每个术语“”都包含一个的项，这个项被乘到其中。因此，我们的算法得到了的结果，并且无法进行预测。\n更广泛地说，因为在有限的训练集中没有见过某个事件，将其概率估计为零是一个统计上不好的做法。考虑对取值在的多项式随机变量的均值进行估计的问题。我们可以用来参数化我们的多项式分布。给定一组独立的观测值，最大似然估计为：\n解决方案：拉普拉斯平滑如上所述，如果我们使用这些最大似然估计，一些的值可能为零，这是个问题。为了避免这种情况，我们可以采用拉普拉斯平滑，用以下估计代替：在这里，是特征可能的取值个数，是训练样本总数。\n在这里，我们在分子上加了，在分母上加了。请注意，仍然成立（请自行验证！），这是一个希望得到的性质，因为是我们知道必须总和为的概率的估计值。而且，对于所有的值，不等于，解决了概率被估计为零的问题。在某些（可以说相当强的）条件下，可以证明拉普拉斯平滑实际上给出了的最优估计器。\n拉普拉斯平滑的优点是对所有特征都给予了一个非零的概率估计，避免了概率为零的问题。这样，即使某个特征在训练集中没有出现，它仍然有一个较小但非零的概率估计，不会影响到后续的概率计算。\n考虑回到我们的朴素贝叶斯分类器，并应用拉普拉斯平滑，我们可以得到以下参数的估计值：请注意，对于是否应用拉普拉斯平滑通常并不重要，因为我们通常会有相当数量的垃圾邮件和非垃圾邮件，所以将是的一个合理估计值，并且通常会远离0。\n通过拉普拉斯平滑，我们能够更好地解决稀疏数据问题，并使得朴素贝叶斯算法在文本分类等任务中表现得更加优秀。\n","slug":"Laplace-smoothing","date":"2023-07-29T06:21:21.000Z","categories_index":"","tags_index":"Machine Learning,笔记","author_index":"General_K1ng"},{"id":"060cf84ea8728915ecf4c659557a0907","title":"朴素贝叶斯","content":"机器学习中的文本分类在GDA中，特征向量是连续的实值向量。现在我们来讨论另一种学习算法，其中是离散值。\n在机器学习中，我们经常遇到特征是离散值的情况，这里我们来讨论这种情况。举个例子，我们打算用机器学习构建一个电子邮件垃圾邮件过滤器。这个过滤器的任务是判断一封电子邮件是否是垃圾邮件，然后自动将其过滤到专门的垃圾邮件文件夹里。这个问题属于文本分类的范畴，而文本分类又是一个更大问题集的一部分。\n特征表示方式我们假设我们有一个训练集（一组被标记为垃圾邮件或非垃圾邮件的电子邮件）。我们将通过指定用于表示邮件的特征  来构建我们的垃圾邮件过滤器。\n我们将通过一个特征向量来表示一封电子邮件，其长度等于字典中的单词数。具体地，如果一封电子邮件包含字典中的第  个单词，则我们将设置 ；否则，我们设置 。例如，向量表示的一封电子邮件可能如下所示：该特征向量用于表示包含单词“a”和“buy”，但不包含“aardvark”，“aardwolf”或“zygmurgy”的电子邮件。所编码到特征向量的单词集合称为词汇表，因此特征向量 x 的维度等于词汇表的大小。例如，如果词汇表包含1000个单词，那么特征向量  的维度将是1000。在这种表示下，我们可以通过特征向量来表示每封电子邮件中包含哪些特定的单词。\n\n\n\n\n\n\n\n\n\n在实际应用中，我们通常不会查阅完整的英语字典来获取所有可能的单词列表。而是根据训练集来确定特征向量中的单词。通常只将在训练集中至少出现一次的单词加入特征向量。这样可以减少建模所需的单词数量，降低计算和空间需求。此外，一些高频的“内容无关”单词（如 “the”, “of”, *”and”*）也会被排除，因为它们对判断电子邮件是否是垃圾邮件没有太大帮助。这些高频单词被称为停用词（stop words）。\n朴素贝叶斯分类器现在我们需要构建一个生成模型来对条件概率  建模。但如果我们的词汇表有50000个单词，那么特征向量 ，也就是一个由0和1组成的50000维向量。如果我们想用多项式分布来显式建模 ，那么可能的结果有个，参数数量将非常庞大。\n为了简化建模，我们做出了一个非常强的假设，称为朴素贝叶斯（Naive Bayes）假设。假设在给定  的条件下，所有的  是条件独立的。这样，我们得到了朴素贝叶斯分类器。举个例子，如果  表示垃圾邮件；”buy” 对应单词编号2087，而”price” 对应单词编号39831。那么我们假设在已知 （某封电子邮件是垃圾邮件）的情况下，是否知道 （是否包含”buy”）对于判断 （是否包含”price”）是无关的。更形式化地，我们可以写成 。（注意，这不是说  和  是独立的，而是说在给定  的条件下， 和  是条件独立的。）\n我们现在有：第一个等式是概率的一般性质，而第二个等式就是由朴素贝叶斯假设得到的结果。尽管朴素贝叶斯假设非常强，但由此产生的算法在很多问题上表现良好。\n参数化和最大似然估计在朴素贝叶斯算法中，我们使用一些参数来表示模型。这些参数是 ， 和 。它们的解释非常简单： 表示在垃圾邮件（）中，包含单词  的比例。\n通过给定的训练集 ，我们可以写出数据的联合似然：为了估计参数 ， 和 ，我们使用最大似然估计。也就是找到使得联合似然函数最大化的参数值。\n具体地，我们可以通过如下公式来计算参数的最大似然估计值：在上面的方程中，符号“∧”表示“与”。这些参数有一个非常自然的解释。例如，只是垃圾邮件（）中包含单词的比例。\n预测新样本的类别在拟合好这些参数后，我们可以用来预测新样本的类别。假设我们有一个新样本的特征表示 ，我们希望判断它是垃圾邮件还是非垃圾邮件（还是）。\n我们可以简单地计算后验概率来进行预测：然后，我们选择具有较高后验概率的类别作为预测结果。\n处理更多离散值的情况最后，我们指出，虽然我们主要针对特征是二元值的问题开发了朴素贝叶斯算法，但对可以在，，，中取值的情况，其推广是简单的。在这种情况下，我们只需将建模为多项式而不是伯努利分布。实际上，即使某些原始输入属性（例如我们之前的例子中的房屋生活面积）是连续值的，将其离散化（即将其转换为一组小的离散值）并应用朴素贝叶斯也是相当常见的。例如，如果我们使用某个特征来表示生活面积，我们可以将连续值离散化如下：\n\n\n\nLiving area (sq. feet)\n&lt; 400\n400-800\n800-1200\n1200-1600\n&gt;1600\n\n\n\n\n1\n2\n3\n4\n5\n\n\n因此，对于一所生活面积为890平方英尺的房屋，我们将相应特征的值设置为3。然后，我们可以应用朴素贝叶斯算法，用多项式分布来建模，就像之前所描述的那样。当原始的连续值属性不适合用多元正态分布建模时，将特征进行离散化并使用朴素贝叶斯（而不是GDA）通常会得到更好的分类器。\n","slug":"Naive-bayes","date":"2023-07-24T07:28:32.000Z","categories_index":"","tags_index":"Machine Learning,笔记","author_index":"General_K1ng"},{"id":"68643f4a3340f18395afd7c596807d57","title":"高斯判别分析","content":"高斯判别分析（GDA）让我们来讨论生成学习算法中的一个重要模型——高斯判别分析（Gaussian Discriminant Analysis，简称 GDA）。在这个模型中，我们假设数据的条件概率  符合多元正态分布。在深入探讨 GDA 模型之前，我们先简要介绍一下多元正态分布的性质。\n多元正态分布在  维空间中的多元正态分布，也被称为多元高斯分布，由均值向量  和协方差矩阵  参数化，其中  是对称且半正定的。我们用  来表示这个分布，其概率密度函数如下所示：在上面的方程中，“”表示矩阵的行列式。\n对于服从  分布的随机变量 ，其均值是 ，这并不令人意外：对于一个向量值随机变量 ，协方差定义为 ，这推广了实值随机变量的方差概念。协方差也可以定义为 。（你应该能够自行证明这两个定义是等价的。）如果 ，那么：以下是一些高斯分布密度函数的示例：\n\n\n最左边的图显示的是均值为零（即2x1的零向量）且协方差矩阵（2x2的单位矩阵）的高斯分布。这个分布也被称为标准正态分布。\n中间的图显示的是均值为零且的高斯分布。\n最右边的图显示的是均值为零且的高斯分布。我们可以观察到，随着变得更大，高斯分布变得更加“扩展”，而随着变得更小，分布则变得更“压缩”。\n\n让我们看更多的例子：\n\n上面的图显示了均值为0的高斯分布，并分别显示了它们的协方差矩阵：左侧的图显示了熟悉的标准正态分布，我们可以看到随着协方差矩阵中的非对角元素增加，密度趋向于线（由给出）。当我们查看同样三个密度的等高线图时，这一点更加清晰：\n\n以下是通过变化生成的另一组示例：\n\n上面使用的图分别是:从左边和中间的图中，我们可以看到通过减小协方差矩阵的非对角元素，密度再次变得“压缩”，但是方向相反。最后，当我们更一般地改变参数时，等高线将形成椭圆（右边的图显示了一个例子）。\n作为我们最后的一组例子，我们固定，通过改变，我们可以将密度的均值移动到不同的位置。\n\n上面的数字是使用生成的，分别是\n高斯判别分析模型当我们面对一个分类问题，其中输入特征是连续值随机变量时，我们可以使用高斯判别分析（Gaussian Discriminant Analysis，GDA）模型，它使用多元正态分布来建模。该模型为：写出分布，这是：在这里，我们的模型参数是、、和。（请注意，尽管有两个不同的均值向量和，但通常使用一个协方差矩阵来应用该模型。）数据的对数似然是由以下公式给出：通过对参数最大化，我们可以找到参数的最大似然估计：从图示上看，该算法的过程如下所示：\n\n在图中显示了训练集，以及对每个类别中的数据进行拟合的两个高斯分布的等高线。注意，这两个高斯分布的等高线具有相同的形状和方向，因为它们共享协方差矩阵，但它们具有不同的均值和。图中还显示了给出决策边界的直线，该边界使得。在边界的一侧，我们将预测是最可能的结果，而在另一侧，我们将预测。\n讨论：GDA和逻辑回归GDA模型与逻辑回归之间有着有趣的关系。事实上，如果我们将  看作是  的函数，我们会发现它可以写成以下形式：\n在这里， 是 、、 和  的一些合适函数。这恰好是逻辑回归——一个判别算法——用来建模  的形式。\n\n\n\n\n\n\n\n\n\n这里使用了重新定义右侧的  的约定，通过添加额外的坐标 ，将它们变成  维向量\n那么我们什么时候更喜欢一种模型而不是另一种模型呢？一般来说，当在同一数据集上训练时，GDA和逻辑回归会给出不同的决策边界。那么哪个模型更好呢？\n我们刚刚证明了如果  是多元高斯分布（具有共享的 ），那么  必定遵循一个逻辑函数。然而，反过来并不成立；即  是一个逻辑函数并不意味着  是多元高斯分布。这表明GDA对数据做出了比逻辑回归更强的建模假设。事实上，当这些建模假设正确时，GDA将对数据拟合得更好，是一个更优的模型。特别地，当  确实是高斯分布（具有共享的 ）时，GDA是渐近有效的。简单来说，这意味着在非常大的训练集（大 n）的极限情况下，没有比GDA更好的算法（例如在准确估计  方面）。特别地，可以证明在这种情况下，GDA将优于逻辑回归；而更一般地说，即使对于较小的训练集大小，我们通常也会预期GDA更优。\n相比之下，逻辑回归通过做出明显较弱的假设，更加健壮且对错误的建模假设不太敏感。有许多不同的假设集会导致  采取逻辑函数的形式。例如，如果 ，并且 ，那么  将是逻辑函数。在这样的泊松分布数据上，逻辑回归也会表现良好。但是，如果我们在这样的数据上使用GDA，并将高斯分布拟合到这样的非高斯分布数据上，结果将变得不那么可预测，GDA可能（或者可能不会）表现良好。\n总结起来：GDA做出了更强的建模假设，在建模假设正确或近似正确的情况下更具数据效率（即需要较少的训练数据来学习得更好）。逻辑回归做出了较弱的假设，对于与建模假设的偏差更具有鲁棒性。具体而言，当数据确实是非高斯分布时，在大规模数据集的极限情况下，逻辑回归几乎总是比GDA表现更好。因此，在实践中，逻辑回归比GDA更常用。（我们接下来讨论的朴素贝叶斯算法也涉及有关判别模型与生成模型的类似考虑，但朴素贝叶斯算法仍被认为是一种非常优秀且广受欢迎的分类算法。）\n","slug":"Gaussian-discriminant-analysis","date":"2023-07-22T06:04:23.000Z","categories_index":"","tags_index":"Machine Learning,笔记","author_index":"General_K1ng"},{"id":"6e9ecff97c79fc9b7ee5419e3db98187","title":"生成式学习算法","content":"生成式学习算法：从动物外貌特征到分类预测到目前为止，我们已经讨论了一些学习算法，这些算法主要关注于建模条件分布 ，也就是在给定输入  的情况下输出  的概率分布。例如，逻辑回归使用  来建模 ，其中  是 sigmoid 函数。在这次笔记中，我们将探讨一种不同类型的学习算法。\n判别式学习算法在考虑一个分类问题时，我们希望根据动物的一些特征来学习如何区分大象 (y = 1) 和狗 (y = 0)。判别式学习算法，例如逻辑回归或感知机算法，试图找到一条直线，即决策边界，来将大象和狗分开。然后，为了对新的动物进行分类，算法会检查它在决策边界的哪一侧，并根据结果进行预测。\n生成式学习算法：全新的方法现在，我们来探讨一种全新的学习方法。首先，我们可以构建一个描述大象外貌特征的模型。然后，我们可以构建一个独立的描述狗外貌特征的模型。最后，当我们需要对一个新的动物进行分类时，我们可以将其与大象模型进行匹配，并将其与狗模型进行匹配，从而确定新动物更像我们在训练集中见过的大象还是更像狗。\n生成式学习算法 vs. 判别式学习算法刚才我们提到的直接学习  的算法（例如逻辑回归）或者直接学习从输入空间  到标签 {0, 1} 的映射（例如感知机算法），都属于判别式学习算法。而在这里，我们将讨论一类试图对条件概率 （以及类先验 ）进行建模的算法，这些算法被称为生成式学习算法。例如，对于一个表示示例是狗（0）还是大象（1）的问题， 建模了狗的特征分布，而  建模了大象的特征分布。\n从条件概率到后验概率在建模了  （称为类先验）和条件概率  之后，我们的算法可以使用贝叶斯规则来推导给定  的后验概率 ：这里，分母  由  给出（您应该能够从概率的标准性质验证这一点），因此也可以用我们已经学到的  和  的数量来表示。实际上，如果我们正在计算  以进行预测，那么我们实际上不需要计算分母，因为分母  只是用于归一化 ，以确保其概率总和为1。但由于我们只关心预测的类别，而不是具体的概率值，我们可以忽略归一化项，直接计算分子部分来得到预测的类别。\n","slug":"Generative-learning-algorithms","date":"2023-07-22T05:45:25.000Z","categories_index":"","tags_index":"Machine Learning,笔记","author_index":"General_K1ng"},{"id":"944f20daa7bfde2d1440fd8c10bf6bf0","title":"（实战）鸢尾花数据集的三分类","content":"上一章的难度相比各位估计应该也是云里雾里吧，那么这一章就来实战一下如何运用softmax回归来进行多分类吧！刚好顺便来弥补一下之前我们在对鸢尾花进行分类的时候只运用了二分类的遗憾，今天，我们就直接开始，三分类！\nSoftmax回归概念回顾首先我们先回顾一下什么是Softmax回归，它是一种用于多分类问题的分类算法，也称为多类别逻辑回归或多项逻辑回归。Softmax回归广泛用于机器学习和深度学习中，尤其在图像识别、自然语言处理和语音识别等任务上。\n简单来说，softmax回归将输入的样本通过线性变换和一个softmax函数映射为类别的概率分布。它主要包含两个步骤：\n\n线性变换：对于给定的输入样本，首先通过一个线性变换计算每个类别的得分。这个得分可以看作是输入样本属于每个类别的权重。\nSoftmax函数：然后，将得分通过softmax函数转换为概率分布。Softmax函数可以将原始得分转换为非负且和为1的概率值，这样可以表示每个类别的概率。\n\n假设我们有n个类别，对于第i个类别，它的得分为。那么Softmax函数的计算如下：其中，是指数函数，是求和函数。\n最终，输入样本属于第i个类别的概率为。可以选择概率最高的类别作为预测结果。\n在训练过程中，通常使用交叉熵损失函数来衡量预测结果和真实标签之间的差异，并通过梯度下降等优化算法来更新模型的参数，使得预测结果更接近真实情况。\n好像还是有些难懂，那再用人话来说一遍吧。\n人话版本1. 什么是分类问题？\n首先，什么是分类问题。在机器学习中，分类问题是指将事物分为不同的类别。比如，我们可以将动物分为猫、狗和鸟三个类别，或者将邮件分为垃圾邮件和非垃圾邮件两个类别。\n2. 什么是Softmax回归？\n它是一种机器学习算法，用于解决分类问题。假设我们有很多特征，比如动物的体重、体长和年龄，我们想要根据这些特征把动物分成不同的类别，比如猫、狗和鸟。Softmax回归可以帮助我们做这件事。\n3. 如何工作？\nSoftmax回归的工作方式有两个关键步骤：\n步骤一：计算得分\n对于给定的一个动物，我们会用一些数学计算得到它属于每个类别的得分。这个得分可以理解为，每个类别有多大的可能性与这个动物匹配。\n步骤二：转换为概率\n有了得分后，我们需要将它们转换成概率。概率是一个介于0到1之间的数值，表示某个动物属于某个类别的可能性有多大。Softmax回归使用一个特殊的函数，称为softmax函数，来做这个转换。它会把得分转换成概率，确保所有类别的概率加起来等于1。\n4. 如何做预测？\n在训练阶段，我们会用一堆已知类别的动物数据来让机器学习算法学习。它会通过调整一些参数来找到最佳的方式来预测动物的类别。\n然后，在预测阶段，当我们有一个新的动物数据时，我们会用训练好的模型，通过同样的计算和转换过程，得到动物属于每个类别的概率。最后，我们会选择概率最高的类别作为预测结果，就像猫、狗和鸟中选择概率最高的那个类别。\n怎么计算得分假设我们有一个分类问题，有个类别需要进行分类。对于给定的输入样本，我们会为每个类别分配一个得分（也称为logit），表示输入样本属于该类别的可能性大小。\n对于第个类别，得分的计算是通过将输入样本的特征与相应的权重进行线性组合得到的。假设输入样本有个特征（即特征向量的长度为），则该类别的得分可以表示为：其中， 是与每个特征相关联的权重， 是输入样本的特征值， 是偏置项（也称为截距项）。\n对于输入样本，我们需要为每个类别计算一个得分。\n怎么转换成概率得到每个类别的得分后，我们需要将它们转换为概率，以便进行分类。\n我们使用softmax函数来执行这个转换。对于第个类别的得分，它在Softmax函数中的概率表示为：其中，是指数函数，它会将得分转换为非负数。是求和函数，对所有类别的得分进行求和。\n通过这个计算，我们可以获得每个类别的概率。这些概率的和总是等于1，因为softmax函数的特性保证了这一点。\n最后，在预测阶段，我们选择具有最高概率的类别作为预测结果。例如，如果softmax函数给出了猫的概率为0.8，狗的概率为0.15，鸟的概率为0.05，那么我们将预测这个输入样本属于”猫”类别。\n实战开始选取模块与库那么还是老样子，选择我们应该用那些库，其实跟上次的都差不多。\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n首先，我们导入了所需的库，包括 pandas 用于数据处理，numpy 用于数值计算，matplotlib.pyplot 用于绘图，以及一些用于机器学习的模块如 train_test_split 用于数据集划分，StandardScaler 用于特征缩放，accuracy_score、confusion_matrix 和 classification_report 用于评估分类模型的性能。\n读取文件# 读取数据\ndata = pd.read_csv('iris.csv') # 你的文件路径！\n\n然后，我们使用 pandas 读取了一个名为 “iris.csv” 的数据集，该数据集包含了鸢尾花（Iris）的一些测量数据以及其所属的物种标签。\n跟上次一样的数据预处理过程，不过这一次我们还需要干一个事情就是将Species列转换成数值，使用One-hot编码。那么什么是One-hot编码呢？\nOne-hot编码在softmax回归中，我们需要将类别标签转换成一种称为One-hot编码的形式。One-hot编码是一种向量表示方法，将一个类别表示为一个向量，其中只有一个元素是1，其他元素都是0。例如，山鸢尾类别可以表示为[1, 0, 0]，变色鸢尾类别可以表示为[0, 1, 0]，维吉尼亚鸢尾类别可以表示为[0, 0, 1]。\n# 将Species列转换成数值，使用One-hot编码\ndata = pd.get_dummies(data, columns=['Species'])\n\n我们将数据集中的 “Species” 列进行了转换，并使用 One-hot 编码将其转换成了数值形式，这是因为机器学习算法通常只接受数值输入。\n数据预处理其实这一步真的跟之前二分类那一次都差不多了，无非是分离标签，分离特征，划分训练集和预测集，最后再把特征缩放一下。\n# 将特征和标签进行分离\nX = data.drop(['Species_setosa', 'Species_versicolor', 'Species_virginica'], axis=1).values\ny = data[['Species_setosa', 'Species_versicolor', 'Species_virginica']].values\n\n我们将数据集中的特征和标签进行了分离。在这个数据集中，特征是花的测量数据，而标签是表示鸢尾花所属物种的 One-hot 编码形式。\n# 将数据集划分为训练集和测试集\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n我们使用 train_test_split 函数将数据集划分为训练集和测试集。训练集用于模型的训练，测试集用于评估模型的性能。这里将数据集划分成 80% 的训练集和 20% 的测试集，并且使用 random_state 参数设置了随机种子，以确保每次划分的结果都是相同的，便于我们复现结果。\n# 特征缩放\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n接着，我们对特征进行了缩放处理，这是为了确保不同特征的数值范围一致，从而避免某些特征对模型训练的影响过大。这里使用了 StandardScaler 类进行标准化处理，将特征缩放到均值为 0、方差为 1 的标准正态分布。\nSoftmax函数就是我们上面所说的那个，我在这里再放一下：我们翻译成代码就是\n# 定义Softmax函数\ndef softmax(scores):\n    exp_scores = np.exp(scores - np.max(scores, axis=1, keepdims=True))\n    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n\n定义 Softmax 函数，这是一个常用的激活函数，用于将模型输出转换为类别概率。它将原始的线性输出（也称为 “scores“）转换为一个概率分布，确保所有概率值在 0 到 1 之间，并且它们的和等于 1。这里的实现避免了数值不稳定性问题，通过减去每个样本的最大分数，可以使指数运算更稳定。\n损失函数：交叉熵这里我们需要再定义一个函数，我们称之为交叉熵函数，为了训练模型，我们需要定义一个损失函数来衡量预测结果和真实标签之间的差异。在softmax回归中，我们使用交叉熵损失函数来衡量预测概率和真实标签之间的距离。我们的目标是最小化交叉熵损失函数，使得模型的预测尽可能接近真实情况。\n# 定义交叉熵损失函数\ndef cross_entropy_loss(y_true, y_pred):\n    num_samples = y_true.shape[0]\n    log_likelihood = -np.log(y_pred[range(num_samples), np.argmax(y_true, axis=1)])\n    loss = np.sum(log_likelihood) / num_samples\n    return loss\n\n交叉熵是常用的分类问题损失函数，它通过计算模型输出概率与真实标签之间的差异来评估模型性能。这里的实现使用了 NumPy 数组运算，避免了显式的循环操作，提高了计算效率。\n训练函数这一步，我们需要使用我们的老朋友梯度下降算法来优化模型参数（权重和偏置）。梯度下降算法会根据损失函数的梯度方向，逐步更新模型的参数，以使损失函数逐渐减小。\n通过迭代训练过程，我们的模型将学习如何将输入样本映射到合适的类别，并且我们可以使用训练好的模型进行预测。\n# 定义训练函数\ndef train_softmax_regression(X, y, learning_rate, epochs):\n    num_samples, num_features = X.shape\n    num_classes = y.shape[1]\n\n    # 初始化权重和偏置\n    W = np.random.randn(num_features, num_classes)\n    b = np.zeros((1, num_classes))\n\n    # 记录每个epoch的损失\n    losses = []\n\n    for epoch in range(epochs):\n        # 前向传播\n        scores = np.dot(X, W) + b\n        probabilities = softmax(scores)\n\n        # 计算损失\n        loss = cross_entropy_loss(y, probabilities)\n        losses.append(loss)\n\n        # 反向传播\n        error = probabilities - y\n        dW = np.dot(X.T, error) / num_samples\n        db = np.sum(error, axis=0, keepdims=True) / num_samples\n\n        # 参数更新\n        W -= learning_rate * dW\n        b -= learning_rate * db\n\n    return W, b, losses\n\n我们定义了训练函数 train_softmax_regression。该函数使用批量梯度下降法来训练 Softmax 回归模型。在训练过程中，我们根据损失函数的梯度更新模型的权重和偏置，不断优化模型以使其更好地拟合训练数据。同时，我们还记录了每个 epoch 的损失值，以便后续的可视化和分析。\n开始调用设置学习率和迭代次数这一步跟之前也非常像，无非是梯度下降嘛\n# 设置学习率和迭代次数\nlearning_rate = 0.01\nepochs = 1000\n\n# 调用训练函数，训练Softmax回归模型\nW, b, losses = train_softmax_regression(X_train_scaled, y_train, learning_rate, epochs)\n\n在这里，我们设置了学习率和迭代次数，并调用训练函数 train_softmax_regression 对模型进行训练。通过不断地迭代优化权重和偏置，模型将逐渐适应训练数据。\n模型预测# 使用训练好的模型进行预测\nscores_test = np.dot(X_test_scaled, W) + b\nprobabilities_test = softmax(scores_test)\ny_pred = np.argmax(probabilities_test, axis=1)\n\n现在，我们使用训练好的模型对测试集进行预测。首先，我们计算测试集的模型输出分数（即未经过 Softmax 函数处理的值），然后将其转换为概率分布，最后根据概率值选择最可能的类别作为预测结果。\n模型评估设置这里我们需要写一些代码，方便我们后期对模型进行评估\n准确率# 计算准确率\naccuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred)\nprint(\"准确率：\", accuracy)\n\n接下来，我们计算模型的准确率，即模型在测试集上的分类正确率。这里使用了 accuracy_score 函数，它将预测结果与真实标签进行比较，并输出分类的准确率。\n分类报告与混淆矩阵# 输出分类报告和混淆矩阵\nprint(\"\\n分类报告：\")\nprint(classification_report(np.argmax(y_test, axis=1), y_pred))\n\nprint(\"\\n混淆矩阵：\")\nprint(confusion_matrix(np.argmax(y_test, axis=1), y_pred))\n\n最后，我们输出分类报告和混淆矩阵，用于详细评估模型在各个类别上的分类性能。分类报告提供了精确率、召回率和 F1 分数等指标，而混淆矩阵展示了模型预测结果与真实标签之间的对应关系。\n\n\n\n\n\n\n\n\n\n混淆矩阵是分类器在测试集上的分类结果的矩阵表示。矩阵的行表示真实类别，列表示预测类别。对角线上的元素表示正确分类的样本数，非对角线上的元素表示错误分类的样本数。\n可视化处理这一步我们就需要进行可视化处理，因为程序写一大堆，不如图像来的直观，便捷。\n损失函数# 可视化损失值随着迭代次数的变化\nplt.plot(range(epochs), losses)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training Loss')\nplt.show()\n\n我们使用 matplotlib 库绘制了损失值随着迭代次数的变化曲线图，用于可视化模型训练的过程和损失值的收敛情况。这个图可以帮助我们判断模型是否在训练中得到了有效的优化。\n结果散点图我们需要绘制分类结果的散点图和预测结果的散点图。散点图将数据集中的样本点可视化为不同颜色和符号的点，以显示不同类别的分布和模型的分类结果。\n# 准备绘制子图的布局\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\naxes = axes.ravel()\n\n首先，我们创建了一个 2x2 的子图布局，即总共有 4 个子图。plt.subplots(2, 2) 返回一个包含 2 行 2 列的 Figure 对象和一个 Axes 对象数组。然后，通过 axes.ravel() 将该数组转换为一维数组，以便更方便地对每个子图进行操作。\n# 绘制每个子图\nfor i in range(3):\n    # 绘制分类结果的散点图\n    axes[i].scatter(X_train[y_train[:, 0] == 1, i], X_train[y_train[:, 0] == 1, i + 1], label='Class 1 (Train)', marker='o', c='blue')\n    axes[i].scatter(X_train[y_train[:, 1] == 1, i], X_train[y_train[:, 1] == 1, i + 1], label='Class 2 (Train)', marker='s', c='green')\n    axes[i].scatter(X_train[y_train[:, 2] == 1, i], X_train[y_train[:, 2] == 1, i + 1], label='Class 3 (Train)', marker='^', c='red')\n\n    # 绘制预测结果的散点图，使用不同的颜色和符号\n    axes[i].scatter(X_test[y_pred == 0, i], X_test[y_pred == 0, i + 1], label='Class 1 (Test)', marker='x', c='blue', alpha=0.5)\n    axes[i].scatter(X_test[y_pred == 1, i], X_test[y_pred == 1, i + 1], label='Class 2 (Test)', marker='x', c='green', alpha=0.5)\n    axes[i].scatter(X_test[y_pred == 2, i], X_test[y_pred == 2, i + 1], label='Class 3 (Test)', marker='x', c='red', alpha=0.5)\n\n    axes[i].set_xlabel(data.columns[i])\n    axes[i].set_ylabel(data.columns[i + 1])\n    axes[i].legend()\n\n\n接着，我们使用循环遍历每个子图，并在每个子图中绘制两个类别的散点图：一个是分类结果的散点图，另一个是预测结果的散点图。我们使用 scatter 函数绘制散点图，其中包含了训练集和测试集中不同类别的样本点。\n对于分类结果的散点图，我们分别使用不同的颜色和符号来表示每个类别。蓝色圆点表示 “Class 1”，绿色正方形表示 “Class 2”，红色三角形表示 “Class 3”。我们从训练集 X_train 和标签 y_train 中选择相应的样本点，根据标签的 One-hot 编码来确定样本的类别。\n对于预测结果的散点图，我们使用虚线的 X 符号来表示。同样，我们根据预测结果 y_pred 来选择测试集 X_test 中的样本点，并根据预测的类别来确定样本所属的类别。\n在每个子图中，我们设置了 x 轴和 y 轴的标签，分别为数据集的不同特征列，用以标识每个散点图中数据点的位置。同时，我们添加了图例来说明不同类别的符号和颜色含义。\n\n# 设置整体图的标题和坐标轴\nplt.suptitle('Classification and Prediction Results')\nplt.tight_layout()\nplt.show()\n\n最后，我们为整体图设置了标题 “Classification and Prediction Results”，使用 suptitle 函数来实现。同时，我们通过 tight_layout() 函数调整子图之间的布局，使得图像更美观。最后，使用 plt.show() 来显示绘制的图像。\n完整代码如下\n\nClick to see more\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n\n# 读取数据\ndata = pd.read_csv('iris.csv') # 记得改自己文件的路径\n\n# 将Species列转换成数值，使用One-hot编码\ndata = pd.get_dummies(data, columns=['Species'])\n\n# 将特征和标签进行分离\nX = data.drop(['Species_setosa', 'Species_versicolor', 'Species_virginica'], axis=1).values\ny = data[['Species_setosa', 'Species_versicolor', 'Species_virginica']].values\n\n# 将数据集划分为训练集和测试集\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 特征缩放\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\ndef softmax(scores):\n    exp_scores = np.exp(scores - np.max(scores, axis=1, keepdims=True))\n    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n\ndef cross_entropy_loss(y_true, y_pred):\n    num_samples = y_true.shape[0]\n    log_likelihood = -np.log(y_pred[range(num_samples), np.argmax(y_true, axis=1)])\n    loss = np.sum(log_likelihood) / num_samples\n    return loss\n\ndef train_softmax_regression(X, y, learning_rate, epochs):\n    num_samples, num_features = X.shape\n    num_classes = y.shape[1]\n\n    # 初始化权重和偏置\n    W = np.random.randn(num_features, num_classes)\n    b = np.zeros((1, num_classes))\n\n    # 记录每个epoch的损失\n    losses = []\n\n    for epoch in range(epochs):\n        # 前向传播\n        scores = np.dot(X, W) + b\n        probabilities = softmax(scores)\n\n        # 计算损失\n        loss = cross_entropy_loss(y, probabilities)\n        losses.append(loss)\n\n        # 反向传播\n        error = probabilities - y\n        dW = np.dot(X.T, error) / num_samples\n        db = np.sum(error, axis=0, keepdims=True) / num_samples\n\n        # 参数更新\n        W -= learning_rate * dW\n        b -= learning_rate * db\n\n    return W, b, losses\n\nlearning_rate = 0.01\nepochs = 1000\n\nW, b, losses = train_softmax_regression(X_train_scaled, y_train, learning_rate, epochs)\n\n# 预测\nscores_test = np.dot(X_test_scaled, W) + b\nprobabilities_test = softmax(scores_test)\ny_pred = np.argmax(probabilities_test, axis=1)\n\n# 准确率\naccuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred)\nprint(\"准确率：\", accuracy)\n\n# 分类报告和混淆矩阵\nprint(\"\\n分类报告：\")\nprint(classification_report(np.argmax(y_test, axis=1), y_pred))\n\nprint(\"\\n混淆矩阵：\")\nprint(confusion_matrix(np.argmax(y_test, axis=1), y_pred))\n\n# 可视化损失\nplt.plot(range(epochs), losses)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training Loss')\nplt.show()\n\n# 准备绘制子图的布局\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\naxes = axes.ravel()\n# 绘制每个子图\nfor i in range(3):\n    # 绘制分类结果的散点图\n    axes[i].scatter(X_train[y_train[:, 0] == 1, i], X_train[y_train[:, 0] == 1, i + 1], label='Class 1 (Train)', marker='o', c='blue')\n    axes[i].scatter(X_train[y_train[:, 1] == 1, i], X_train[y_train[:, 1] == 1, i + 1], label='Class 2 (Train)', marker='s', c='green')\n    axes[i].scatter(X_train[y_train[:, 2] == 1, i], X_train[y_train[:, 2] == 1, i + 1], label='Class 3 (Train)', marker='^', c='red')\n\n    # 绘制预测结果的散点图，使用不同的颜色和符号\n    axes[i].scatter(X_test[y_pred == 0, i], X_test[y_pred == 0, i + 1], label='Class 1 (Test)', marker='x', c='blue', alpha=0.5)\n    axes[i].scatter(X_test[y_pred == 1, i], X_test[y_pred == 1, i + 1], label='Class 2 (Test)', marker='x', c='green', alpha=0.5)\n    axes[i].scatter(X_test[y_pred == 2, i], X_test[y_pred == 2, i + 1], label='Class 3 (Test)', marker='x', c='red', alpha=0.5)\n\n    axes[i].set_xlabel(data.columns[i])\n    axes[i].set_ylabel(data.columns[i + 1])\n    axes[i].legend()\n\n# 设置整体图的标题和坐标轴\nplt.suptitle('Classification and Prediction Results')\nplt.tight_layout()\nplt.show()\n\n\n\n结果评估图像评估先来看我们第一张损失函数图像\n\n可以看得出，随着我们迭代次数的增加，模型的损失在不断的减小，符合我们的预期，可以说是一个很好的模型。那么我们接着往下看。\n\n这张图当中可以看得出来，训练集的数据已经用不同颜色和形状分布在各个地方，我们也能发现我们的预测集的x也合理的分布在他们所在的区域。\n当然最开始我是只画了一张图像的，就是第一张，我只对比了Sepal.Width和Sepal.Length两个维度下，三个品种之间的关系，你可以发现绿色和红色纠缠在一起，并不能很好的区分。是因为我们只画两个维度，但是实际模型考虑了四个维度，限于二维图像的表示限度，所以我就多画了几个图，尽可能多的考虑每个维度之间不同的结果，其实就可以发现分类其实是成功了的。\n当然我也画了三维图像，那个更加明显，不过，给各位留作思考吧！\n嘿嘿以后再说吧，其实目前我们已经可以很明显的看出来三者是可以区分的。\n控制台评估我们也生成了一份报告，如果图像并不能很好的分析的话，我们可以看实际的数据报告是什么样的。\n准确率： 0.9333333333333333\n\n分类报告：\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        10\n           1       0.89      0.89      0.89         9\n           2       0.91      0.91      0.91        11\n\n    accuracy                           0.93        30\n   macro avg       0.93      0.93      0.93        30\nweighted avg       0.93      0.93      0.93        30\n\n\n混淆矩阵：\n[[10  0  0]\n [ 0  8  1]\n [ 0  1 10]]\n\n\n准确率： 准确率是分类器预测正确的样本数占总样本数的比例。在这个例子中，准确率为0.9333333333333333，即约为93.33%。\n\n分类报告： 分类报告提供了关于每个类别的精确率（precision）、召回率（recall）和F1-score的信息。精确率是分类器预测为某一类别的样本中真实属于该类别的比例，召回率是真实属于某一类别的样本中被分类器预测为该类别的比例，F1-score是精确率和召回率的调和平均值。macro avg表示各类别的平均值，weighted avg表示按样本数加权的平均值。\n在这个例子中，对于类别0，精确率和召回率都为1.00，F1-score也为1.00；对于类别1，精确率和召回率都为0.89，F1-score为0.89；对于类别2，精确率和召回率都为0.91，F1-score为0.91。整体的macro avg和weighted avg的准确率、召回率和F1-score都在0.93左右。\n\n混淆矩阵： 混淆矩阵是分类器在测试集上的分类结果的矩阵表示。矩阵的行表示真实类别，列表示预测类别。对角线上的元素表示正确分类的样本数，非对角线上的元素表示错误分类的样本数。\n在这个例子中，对于类别0，有10个样本被正确分类；对于类别1，有8个样本被正确分类，1个样本被错误分类为类别2；对于类别2，有10个样本被正确分类，1个样本被错误分类为类别1。可以看到，大部分样本被正确分类，但仍有一些样本被错误分类。\n\n\n综合来看，这个分类器在测试集上的表现还是不错的，准确率达到了约93.33%。各类别的精确率、召回率和F1-score也都较为接近，说明模型对于不同类别的预测表现都较为稳定。但仍然有少数样本被错误分类，可能需要进一步优化模型，调整参数或特征，以进一步提高分类器的性能。\n其实大家可以多跑几次，会发现每次都会有些小差距，但是准确率一般都在91%~97%附近，还是蛮不错的模型了噢！\n任务留个小任务吧。\n思考：在多维度数据下，有什么方法可以更好的数据可视化？在这次分类中我们就可以发现一张二维图像可能很难看出三者之间的分类情况，何况我画了三张，对比了每两个维度三者之间的关系才可以勉强分析，那么有什么好方法呢？\n","slug":"irisSoftmax","date":"2023-07-21T10:46:33.000Z","categories_index":"","tags_index":"Machine Learning,笔记","author_index":"General_K1ng"},{"id":"6d0e0a76d24875617f81e74389647d3a","title":"构建GLM","content":"这节我们就要开始构造GLM了。\n假设您想建立一个模型，根据一些特征x（比如商店促销活动、最近的广告、天气、星期几等）来估计在任何给定的小时内到达您的商店（或您的网站上的页面浏览次数）的顾客数量y。我们知道泊松分布通常是用于描述访问者数量的好模型。有了这个信息，我们该如何为我们的问题构建一个模型呢？幸运的是，泊松分布是指数分布族的一种，因此我们可以应用广义线性模型（GLM）。在本节中，我们将描述一种构建GLM模型来解决这类问题的方法。\n问题背景首先，让我们考虑一个分类或回归问题，我们希望根据特征 x 预测随机变量 y 的值。为了推导适用于这个问题的GLM，我们做出以下三个假设：\n\n假设一： 在给定 x 和参数 θ 的情况下，y | x; θ 的分布服从某个指数族分布，其参数为 η。\n假设二： 在给定 x 的情况下，我们的目标是预测 T(y) 的期望值，即 *E[y | x]*。在我们的大多数示例中，我们有 T(y) = y，这意味着我们希望我们学习的假设 h 所输出的预测 h(x) 满足 *h(x) = E[y | x]*。（需要注意的是，这个假设对于逻辑回归和线性回归中的  的选择是成立的。例如，在逻辑回归中，我们有 。）\n假设三： 自然参数 η 和输入 x 之间是线性相关的：。（或者，如果 η 是向量值的，则 。）\n\n值得注意的是，第三个假设可能看起来较不充分，并且更应该被视为设计GLM的“选择”，而不是严格的假设。这三个假设/设计选择使我们能够推导出一类非常优雅的学习算法，即GLMs，具有许多理想的特性，如易于学习。此外，由此产生的模型通常非常有效，适用于对 y 的不同类型分布进行建模；例如，我们很快将展示逻辑回归和普通最小二乘法都可以作为GLMs的特定实例推导出来。\n普通最小二乘法（Ordinary Least Squares）为了证明普通最小二乘法是GLM模型族的一个特例，我们首先考虑目标变量 y（在GLM术语中也称为响应变量）为连续型的情况。我们将 y 给定 x 的条件分布建模为高斯分布 ，，其中 μ 可能依赖于 x。这样，我们就选择了上面提到的指数族分布中的分布作为高斯分布。\n正如之前提到的，将高斯分布表示为指数族分布时，我们有 。所以我们有：\n1. 首先，根据假设2，我们有:这表示我们的目标是预测 y 的条件期望值。\n2. 其次，由于我们选择的指数族分布是高斯分布，所以根据高斯分布的性质，其期望值 μ 就等于 η，即:3. 接下来，根据假设3，我们有:这表示 η 和输入 x 之间是线性相关的。\n将这些信息结合起来，我们得到：这就证明了普通最小二乘法是GLM模型族的一个特例。在普通最小二乘法中，我们的目标是最小化预测值与真实值之间的平方差，从而得到拟合效果最优的线性模型。普通最小二乘法是线性回归问题中最常见和经典的解决方法。在下一节，我们将继续探讨GLM模型族的其他实例，例如逻辑回归。\n逻辑回归（Logistic regression）接下来，我们将探讨逻辑回归。在这种情况下，我们对二元分类感兴趣，因此 y 只能取 0 或 1。考虑到 y 是二值的，选择伯努利分布族来建模给定 x 条件下 y 的条件分布是很自然的。将伯努利分布表示为指数族分布时，我们得到 。此外，注意到如果 ，则 。按照与普通最小二乘法相似的推导，我们得到：\n1. 首先，根据假设2，我们有：这表示我们的目标是预测 y 的条件期望值。\n2. 其次，由于我们选择的指数族分布是伯努利分布，所以根据伯努利分布的性质，其期望值 φ 就等于  函数的规范响应函数，即：3. 接下来，根据假设3，我们有：这表示 η 和输入 x 之间是线性相关的。\n将这些信息结合起来，我们得到：这就给出了逻辑回归的假设函数形式 。如果您曾经好奇我们是如何得到逻辑函数  的形式的，现在这就是答案：一旦我们假设 y 在给定 x 的条件下服从伯努利分布，逻辑函数的形式就是GLMs和指数族分布所定义的结果。\n此外，为了引入一些更多的术语，将分布的均值表示为自然参数的函数的函数 g（）称为规范响应函数。它的逆函数  被称为规范链接函数。因此，对于高斯族，规范响应函数是恒等函数；而对于伯努利分布，规范响应函数是逻辑函数。\n\n\n\n\n\n\n\n\n\n很多文献使用g来表示链接函数，而来表示响应函数；但是，我们在这里使用的符号，继承自早期的机器学习文献，将更符合本课程其他部分使用的符号。\nSoftmax回归（Softmax regression）让我们再来看一个GLM的例子，即Softmax回归。这个模型适用于多类别分类问题，其中响应变量 y 可以取 k 个值中的任意一个，即 y ∈ {1, 2, . . . , k}。例如，我们不再只将电子邮件分类为垃圾邮件或非垃圾邮件（二元分类问题），而是希望将其分类为三类，比如垃圾邮件、个人邮件和工作邮件。虽然响应变量仍然是离散的，但现在可以取多于两个值。因此，我们将其建模为多项式分布。\n参数化多项式分布为了参数化包含 k 个可能结果的多项式分布，我们可以使用 k 个参数  来指定每个结果的概率。但是，这些参数是冗余的，即不独立的（因为知道任意 k-1 个  将唯一确定最后一个，因为它们必须满足 ）。因此，我们只使用 k-1 个参数  来参数化多项式分布，其中 ，而 。为了方便起见，我们还可以让 ，但是我们应该记住这不是一个参数，并且完全由  确定。\n表示为指数族分布为了将多项式分布表示为指数族分布，我们定义  如下：，，，，，与之前的例子不同，这里我们不再有 ；而且， 现在是一个 k - 1 维向量，而不是一个实数。我们用  来表示向量  的第 i 个元素。\n指示函数我们再引入一个非常有用的符号。指示函数 1{·} 在其参数为真时取值为 1，在其参数为假时取值为 0（1{True} = 1，1{False} = 0）。例如，1{2 = 3} = 0，1{3 = 5 - 2} = 1。因此，我们还可以将  与  之间的关系表示为 (。（在继续阅读之前，请确保你理解了这是为什么！）此外，我们有 。\n多项式分布是指数族的成员现在，我们准备展示多项式分布是指数族的成员。我们有以下推导：\n\n其中：\n\n\n这样，我们完成了将多项式分布表述为指数族分布的过程。\n链接函数和响应函数我们得到了链接函数的定义（对于 i = 1, . . . , k）为：为方便起见，我们还定义了 。为了求反函数并得到响应函数，我们有：这意味着 ，将其代回公式得到响应函数为：这个从 η 到 φ 的函数被称为Softmax函数，它是一个非常有用的函数，常用于多类别分类问题中，用于将线性输出转换为类别概率。\n完成 Softmax 回归为了完成我们的模型，我们使用之前给出的第三个假设，即  与  呈线性关系。因此，我们有 （对于 ），其中 是我们模型的参数。为了方便起见，我们还可以定义 ，这样 ，如之前所述。因此，我们的模型假设给定  时  的条件分布为：这个适用于 y ∈ {1, . . . , k} 的分类问题的模型被称为 softmax 回归。它是逻辑回归的一种推广。\n模型输出我们的假设将输出：换句话说，我们的假设输出对于每个值 i = 1, . . . , k 的估计概率 。（尽管上面定义的  只有 k − 1 维，很显然  可以通过计算  获得。）\n参数拟合最后，我们讨论参数拟合。与我们之前推导普通最小二乘法和逻辑回归时类似，如果我们有一个包含 n 个示例的训练集 {}，并希望学习该模型的参数 ，我们首先将写出对数似然函数：得到上面第二行的式子，我们使用了之前给出的  的定义。现在，我们可以通过最大化  关于  来获得参数的最大似然估计，使用梯度上升或牛顿法等方法进行优化。\n\n\n\n\n\n\n\n\n\n这个部分主要讲解了Softmax回归模型的建立过程和数学推导。如果不懂，没有关系。\n深入了解数学推导对于机器学习的初学者并非必须，但它有助于加深对机器学习算法和模型的理解。对于初学者，重点应该放在理解基本概念和算法的直觉上，而不是过于深入的数学推导。\n理解数学推导可以帮助你更好地理解算法是如何工作的、为什么选择特定的方法以及它们的局限性。这对于在实际问题中选择合适的模型、调整超参数以及解决算法的性能问题非常有帮助。此外，深入了解数学推导还可以帮助你更好地理解机器学习文献和研究论文，从而保持对新进展的敏感性。\n然而，对于初学者来说，过度关注数学细节可能会让学习过程变得繁琐，甚至让人望而却步。如果你对数学不是特别熟悉，你可以先掌握机器学习的基本概念、常用算法和实践技巧。一旦你对机器学习有了较好的理解，再逐步深入学习数学推导也是一种不错的学习路径。\n最重要的是保持学习的兴趣和动力。你可以根据自己的兴趣和学习目标来决定学习深入数学推导的程度。有时候，实际动手实践和解决实际问题可能比过多纠结于数学推导更加有意义。不断实践和尝试在真实数据上应用机器学习算法将有助于你更快地掌握这门领域。\n","slug":"ConstructingGLMs","date":"2023-07-20T08:10:30.000Z","categories_index":"","tags_index":"Machine Learning,笔记","author_index":"General_K1ng"},{"id":"9397670a03548da92beb1eda8943120b","title":"指数族","content":"为了逐步理解广义线性模型（GLM），我们从定义指数族分布开始！指数族分布是一类神奇的分布，它具有以下形式：其中：\n\ny 是随机变量的取值；\nη 是参数向量（也称为典范参数）；\nT(y) 是充分统计量（sufficient statistic）的向量（对于我们考虑的分布，通常有T(y) = y）；\na(η) 是对数分区函数（log partition function）；\nb(y) 是规范化因子（normalizing factor）。\n\n不要被公式吓到，让我们看看它们的可爱之处！\n 就像一枚魔法徽章，它确保分布  在所有 y 上的和或积等于 1，这样我们就能有一个完美的概率分布。\n这个指数族分布包含许多我们耳熟能详的朋友，比如正态分布、伯努利分布、泊松分布等。而在广义线性模型中，我们将利用指数族分布的特性来构建适用于回归和分类问题的模型。\n探索不同的分布族在 GLM 世界中，固定 T、a 和 b 的选择定义了一个由 η 参数化的分布族（或集合）。当我们改变 η 时，我们会得到这个族中的不同分布。每个族族中的成员都有自己的个性和特点，让我们带着好奇心探索一番！\n伯努利分布和高斯分布是指数族分布的宠儿！让我们看看伯努利分布和高斯分布是指数族分布的两个魔法示例。\n伯努利分布：它是二分类问题中的常客！伯努利分布的均值为 ，写作 Bernoulli()。它规定了  上的分布，使得  和 。随着  的变化，我们会得到具有不同均值的伯努利分布。我们将展示通过改变  获得的这类伯努利分布恰好是指数家族分布。\n我们将Bernoulli分布写成：因此，自然参数由给出。有趣的是，如果我们通过将表示为的函数来反演这个定义，我们会得到。这就是熟悉的sigmoid函数！这在我们将逻辑回归推导为GLM时再次出现。\n将伯努利分布表达成指数家族分布为了将伯努利分布完整地表述为指数家族分布，我们还有以下参数：这表明伯努利分布可以使用适当的T、a和b的选择来写成以上公式的形式。\n高斯分布（正态分布）让我们来研究一下高斯分布。咦，还记得我们推导线性回归时提到的那个方差  吗？其实它对最终的  和  是没有影响的，所以我们可以大胆地选择  的任意值，而不改变任何结果。为了简化接下来的推导，我们就设定  吧！\n\n\n\n\n\n\n\n\n\n嗯，其实如果我们保留  作为一个变量，高斯分布也可以归入指数分布族。在这种情况下， 是一个依赖于  和  的二维向量。然而，在广义线性模型（GLM）中，我们可以通过考虑指数分布族的更一般定义来处理  参数：。这里的  被称为离散参数，对于高斯分布，。但是，为了简便起见，我们在这里只考虑了我们之前假定的情况。\n\n好的，现在让我们来看看高斯分布的奇妙之处：接下来，让我们来看看高斯分布在指数族中的参数表示：指数分布族中还有许多其他分布：多项式分布（稍后我们会看到），泊松分布（用于建模计数数据；也请参阅问题集）；伽马分布和指数分布（用于建模连续、非负的随机变量，比如时间间隔）；贝塔分布和狄利克雷分布（用于概率分布）等等。\n在下一节中，我们将向你展示一个通用的“方法”，用于构建模型，其中 （在给定  和  的情况下）来自上述任意分布之一。\n","slug":"The-exponential-family","date":"2023-07-20T07:17:04.000Z","categories_index":"","tags_index":"Machine Learning,笔记","author_index":"General_K1ng"},{"id":"005491f74262b9b4c835e159a3d618ac","title":"一些题外话","content":"这章节的在课程的笔记里面就是叫题外话，因为和下一节都比较短，所以我就放到一起来记录。\n题外话：感知机学习算法咱们现在稍微偏离一下主题，来简单探讨一种历史上颇具趣味的算法，同时在后面学习理论的时候也会再次回到它。这个算法是从逻辑回归方法修改而来，以强制其输出值为 0 或 1。为了实现这个目标，我们自然而然地改变了函数 g 的定义，将其设定为阈值函数：如果我们继续使用之前定义的 ，但使用这个修改过的 g 函数定义，并采用更新规则：那么我们得到了感知机学习算法。\n感知机学习算法是机器学习中的一个简单算法，用于解决二分类问题。它的灵感来源于神经科学中的感知神经元概念，由 Frank Rosenblatt 于 1957 年提出。\n算法的目标是找到一个超平面，将数据分为两个类别。假设输入样本是一个  维特征向量 ，超平面的表达式为 ，其中  是需要学习的参数向量。对于任意输入 ，如果 ，则预测为正类；如果 ，则预测为负类。\n算法的更新规则如下：\n\n初始化  为一个随机向量或零向量。\n\n对于每个训练样本 ，其中  是标签（1 或 -1）：\na. 计算预测值：。\nb. 如果  和  异号，则更新 ：，其中  是学习率。\n\n\n算法将持续迭代以上步骤，直到所有样本被正确分类或达到预定的迭代次数。需要注意的是，感知机算法只能解决线性可分问题，如果数据线性不可分，则无法收敛。\n在 1960 年代，这个”感知机”被认为是描述大脑中个体神经元工作的一个简略模型。虽然感知机在外观上可能与之前讨论过的其他算法相似，但它实际上与逻辑回归和最小二乘线性回归有很大的不同；特别是，为感知机的预测赋予有意义的概率解释，或将其推导为最大似然估计算法都是非常困难的。不过，它作为学习理论的一个出发点，将为我们的分析提供有趣的帮助。\n另一种最大化的算法现在我们回到使用sigmoid函数作为  的逻辑回归，并讨论一种不同的最大化  的算法。\n让我们首先考虑用牛顿法来寻找函数的零点。假设我们有一个函数 ，我们希望找到一个值 ，使得 。这里， 是一个实数。牛顿法的更新公式如下：这个方法有一个直观的解释，我们可以将其看作是通过一个与当前猜测  处的  相切的线性函数来近似函数 ，然后求解该线性函数为零的位置，并将下一个猜测  设为该位置。\n下面是牛顿法的示意图：\n\n在最左边的图中，我们看到函数  的曲线以及直线 。我们试图找到 ，使得 ；在该例子中， 的值约为 1.3。假设我们将算法的初始值设为 。牛顿法接着拟合了一个与  处的  相切的直线，并求解该直线的零点。（中间的图）这给出了下一个猜测的 ，约为 2.8。最右边的图显示了再进行一次迭代的结果，将  更新为约 1.8。经过几次迭代后，我们迅速接近 。\n牛顿法提供了一种找到  的方法。那么，如果我们想要用它来最大化某个  函数呢？ 函数的极大值对应于其一阶导数  等于零的点。因此，我们可以令 ，然后使用相同的算法来最大化 ，得到更新规则：（思考一下：如果我们想要用牛顿法来最小化而不是最大化一个函数，这将如何改变？）\n最后，在逻辑回归的设置中， 是一个向量，因此我们需要将牛顿法推广到这种多维情况（也称为牛顿-拉夫逊方法）。推广到多维的公式如下：其中， 通常表示  对于  的偏导数的向量； 是一个  的矩阵（实际上是 ，假设我们包括截距项），称为Hessian 矩阵，其元素由以下公式给出：通常情况下，牛顿法 比（批量）梯度下降收敛得更快，并且需要较少的迭代次数来接近最小值。然而，一次牛顿法的迭代可能比一次梯度下降的迭代更昂贵，因为它需要找到和求逆一个  的 Hessian 矩阵；但只要  不是太大，整体上牛顿法通常更加高效。当牛顿法应用于最大化逻辑回归的对数似然函数  时，得到的方法也称为 Fisher scoring 方法。\n广义线性模型下一章节我们就要学习到广义线性模型，到目前为止，我们已经看到了一个回归示例和一个分类示例。在回归示例中，我们有，而在分类示例中，，其中和是和的合适定义函数。在下一节当中，我们将展示这两种方法都是更广泛的模型家族——广义线性模型（Generalized Linear Models，GLMs）的特例。我们还将展示如何导出和应用GLM家族中的其他模型来解决其他分类和回归问题。\n","slug":"Some-Digression","date":"2023-07-20T06:30:32.000Z","categories_index":"","tags_index":"Machine Learning,笔记","author_index":"General_K1ng"},{"id":"6ad60e40b1cfbe85f1c534ea3d1910e1","title":"（实战）鸢尾花数据集的二分类","content":"所以说第一行打不了字是吧，莫名其妙。（不用管这一行，刚刚发现我的编辑器第一行莫名其妙打不了字，所以你看到的这是第二行，很烦）\n昨天我学习了逻辑回归，今天就要实战一下啦！因为光看纸上的知识总感觉有点枯燥，咱们动手试试，把学到的知识化为力量吧！今天我们要玩的游戏是逻辑回归，而游戏场地就是鸢尾花的数据集。\n数据集：鸢尾花大冒险咱们先打开Excel，看看我们要玩的鸢尾花数据集是什么样子滴！第一列是索引，我们直接删掉啦！（记得一定要删掉哦！不然程序会迷失方向，不信你试试！不过别问我为什么知道… T T）\n\n可以发现，第一行是表头数据，分别有Sepal.Length（萼片长度），Sepal.Width（萼片宽度），Petal.Length（花瓣长度），Petal.Width（花瓣宽度），Species（种类），这几个，而Species中分为三个种类，分别是“setosa”，“versicolor”和“virginica”，分别是“小山鸢尾”、“变色鸢尾”和“维吉尼亚鸢尾”。\n准备阶段：选取我们的“法宝”首先，咱们得明确自己的任务和目标哦：我们要用逻辑回归算法解决一个二分类问题，把这个法宝应用于鸢尾花数据集。目标是训练逻辑回归模型，并查看它在测试集上的“施法”效果。\n这里咱们可要动用一些神奇的“法宝”呢！数据处理用强大的Pandas，数值计算可凭借老生常谈的numpy库，train_test_split可用来把数据分为训练集和测试集，LogisticRegression则是我们要打造的逻辑回归模型，还有accuracy_score、precision_score和recall_score这三把尺子，它们能帮我们测量评估指标的准确度哦！最后，还有matplotlib.pyplot可将数据可视化，让我们一起瞧瞧吧！\n所以准备工作差不多就这些，先把所需要的模块导入。\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nimport matplotlib.pyplot as plt\n\n魔法准备：定义一些有趣的“法术”现在，我们要定义一些有趣的“法术”来玩逻辑回归啦！这些“法术”都是数学公式变身的，让Python来帮我们算算就好啦！\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\ndef log_likelihood(features, target, weights):\n    scores = np.dot(features, weights)\n    ll = np.sum(target * scores - np.log(1 + np.exp(scores)))\n    return ll\n\ndef logistic_regression(features, target, num_steps, learning_rate):\n    intercept = np.ones((features.shape[0], 1))\n    features = np.hstack((intercept, features))\n    weights = np.zeros(features.shape[1])\n\n    for step in range(num_steps):\n        scores = np.dot(features, weights)\n        predictions = sigmoid(scores)\n\n        output_error_signal = target - predictions\n        gradient = np.dot(features.T, output_error_signal)\n        weights += learning_rate * gradient\n\n        # Print log-likelihood every 100 steps\n        if step % 100 == 0:\n            print(f\"Step {step}, Log-Likelihood: {log_likelihood(features, target, weights)}\")\n\n    return weights\n\n第一个“法术”叫做sigmoid，它是逻辑回归中的魔法函数，负责把输入的数值变成0到1之间的可爱小数哦！\n接下来是log_likelihood，“法术”嘛，它能算出对数似然性，看起来有点高深，其实是帮我们衡量预测结果的好坏程度！\n最后一个“法术”是logistic_regression，这个可厉害了！它用梯度上升算法，一步步地训练逻辑回归模型，就像咱们在山上慢慢攀登一样！它还会在每爬100步的时候，打印出对数似然性，让我们知道自己的成长进度哦！\n大冒险准备：数据预处理怎么个处理法，其实好像没什么需要处理的，无非就是读取，存储，几个简单的转换？差不多吧。\n# 加载数据集并分成训练集和测试集\ndata_path = 'iris.csv' # 你的路径！\ndata = pd.read_csv(data_path)\n\n# 将'setosa'标记为1，其他两种花标记为0，实现二分类问题\ndata['Species'] = data['Species'].map({'setosa': 1, 'versicolor': 0, 'virginica': 0})\n\n# 提取特征和标签\nfeatures = data.drop('Species', axis=1)\ntarget = data['Species']\n\n# 分割数据集\ntrain_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.2, random_state=42)\n\n首先，我们要加载数据集，它就像我们的宝藏地图一样，指引着我们前进的方向。我们用pd.read_csv()将数据从csv文件中读取出来，并把花的种类标记为1和0，就像宝藏上的标记一样，让我们可以区分哪些是我们要找的，哪些是普通的岩石。瞧，鸢尾花的种类有点像三个魔法宝石，我们要把其中一个宝石标记为1，其他两个标记为0，这样它们就变成了我们要寻找的目标。\n接下来，我们得把宝藏中的特征和目标提取出来。特征就像地图上的路线，目标就像我们要找的宝藏。咱们把特征放进features变量，把目标放进target变量，这样咱们就能对它们进行后续的处理啦。\n鸢尾花大冒险的第一步就是分割数据集，将宝藏地图分成训练集和测试集，这样我们才能在训练中不断成长，最后测试一下自己的探险成果。通过train_test_split，我们将数据集分成了两部分，80%的数据用来训练，20%的数据留作测试，而随机种子random_state=42则确保我们在不同的时候玩同样的游戏。\n参数：选个好武器，准备战斗# 使用训练集来训练逻辑回归模型\nnum_steps = 1000\nlearning_rate = 0.01\nweights = logistic_regression(train_features, train_target, num_steps, learning_rate)\n\n接下来，我们要选择适合鸢尾花大冒险的武器了。先把自己的装备整理一下，我们需要设定一些超级厉害的“法宝”：迭代次数num_steps和学习率learning_rate，这些会决定我们在冒险中的表现。好了，现在我们就准备好了，可以正式进入鸢尾花的世界了！\n“法宝”已经准备齐全，现在我们需要通过logistic_regression函数，调用那些魔法“法术”来进行模型的训练。这个过程就像在修炼魔法一样，每一步都在增强我们的力量。训练过程中，我们会在每爬100步的时候，打印出当前的对数似然性，这样我们就能看到自己的成长历程。\n你也可以在这部分通过调整迭代次数和学习率来观察不同情况下的模型表现。\n探索成果，评估表现！test_intercept = np.ones((test_features.shape[0], 1))\ntest_features = np.hstack((test_intercept, test_features))\ntest_predictions = sigmoid(np.dot(test_features, weights))\ntest_predictions = np.round(test_predictions)\n\naccuracy = accuracy_score(test_target, test_predictions)\nprecision = precision_score(test_target, test_predictions)\nrecall = recall_score(test_target, test_predictions)\n\nprint(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\")\n\n这一部分代码使用训练后的模型权重对测试集进行预测，并计算评估指标。首先，将测试集的特征矩阵添加一列全为1的列作为截距，然后通过逻辑函数sigmoid和权重矩阵计算预测结果。为了得到最终的分类结果，将预测概率四舍五入为0或1。\n最后，计算预测结果与测试集真实标签之间的准确率、精确率和召回率，并将结果打印输出。\n\n\n\n\n\n\nTIP\n这里我再来贴一下什么是准确率，精确率和召回率。\n\n准确率（Accuracy）： 准确率是最常用的模型性能指标之一，它表示模型正确预测的样本数与总样本数之间的比例。即：(预测正确的样本数) / (总样本数)。准确率越高，表示模型的整体性能越好。\n精确率（Precision）： 精确率是针对预测为正例的样本而言的，它表示在所有预测为正例的样本中，模型正确预测为正例的比例。即：(真正例数) / (真正例数 + 假正例数)。精确率高表示模型对正例的预测较准确。\n召回率（Recall）： 召回率是针对实际为正例的样本而言的，它表示在所有实际为正例的样本中，模型正确预测为正例的比例。即：(真正例数) / (真正例数 + 假负例数)。召回率高表示模型对正例的识别能力较强。\n\n\n\n数据可视化由于鸢尾花数据集有四个特征，我们可以选择任意两个特征来进行可视化处理。\nfeature_names = ['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']\ntarget_names = ['setosa', 'versicolor/virginica']\n\nfig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 15))\n\nfor idx, ax in enumerate(axes.flat):\n    i, j = idx // 2, idx % 2\n    ax.scatter(data[data['Species'] == 1][feature_names[i]], data[data['Species'] == 1][feature_names[j]], label='setosa')\n    ax.scatter(data[data['Species'] == 0][feature_names[i]], data[data['Species'] == 0][feature_names[j]], label='versicolor/virginica')\n    ax.scatter(test_features[test_target == 1][:, i+1], test_features[test_target == 1][:, j+1], marker='o', edgecolors='red', facecolors='none', label='setosa (predicted)')\n    ax.scatter(test_features[test_target == 0][:, i+1], test_features[test_target == 0][:, j+1], marker='x', color='red', label='versicolor/virginica (predicted)')\n    ax.set_xlabel(feature_names[i])\n    ax.set_ylabel(feature_names[j])\n    ax.legend()\n\nplt.tight_layout()\nplt.show()\n\n最后这一部分代码进行了数据可视化处理，使用散点图展示了不同特征组合下的分类结果。这部分代码使用了matplotlib.pyplot库，创建了6个子图，并在每个子图中绘制了鸢尾花数据集中的两个特征。蓝色的点代表’Setosa’类别，橙色的点代表’Versicolor’和’Virginica’类别。预测集的结果用红色的圆圈（’o’）表示’Setosa’类别，用红色的叉（’x’）表示’Versicolor’和’Virginica’类别。\n完整代码如下\n\nClick to see more\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nimport matplotlib.pyplot as plt\n\n# 1. 逻辑回归算法的代码实现\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\ndef log_likelihood(features, target, weights):\n    scores = np.dot(features, weights)\n    ll = np.sum(target * scores - np.log(1 + np.exp(scores)))\n    return ll\n\ndef logistic_regression(features, target, num_steps, learning_rate):\n    intercept = np.ones((features.shape[0], 1))\n    features = np.hstack((intercept, features))\n    weights = np.zeros(features.shape[1])\n\n    for step in range(num_steps):\n        scores = np.dot(features, weights)\n        predictions = sigmoid(scores)\n\n        output_error_signal = target - predictions\n        gradient = np.dot(features.T, output_error_signal)\n        weights += learning_rate * gradient\n\n        # Print log-likelihood every 100 steps\n        if step % 100 == 0:\n            print(f\"Step {step}, Log-Likelihood: {log_likelihood(features, target, weights)}\")\n\n    return weights\n\n# 2. 选择一个适合的二分类数据集\n# 在此示例中，我们将使用鸢尾花数据集\n\n# 3. 加载数据集并分成训练集和测试集\ndata_path = 'iris.csv' # 你的路径！！！\ndata = pd.read_csv(data_path)\n\n# 将'setosa'标记为1，其他两种花标记为0，实现二分类问题\ndata['Species'] = data['Species'].map({'setosa': 1, 'versicolor': 0, 'virginica': 0})\n\n# 提取特征和标签\nfeatures = data.drop('Species', axis=1)\ntarget = data['Species']\n\n# 分割数据集\ntrain_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.2, random_state=465)\n\n# 4. 使用训练集来训练逻辑回归模型\nnum_steps = 1000\nlearning_rate = 0.01\nweights = logistic_regression(train_features, train_target, num_steps, learning_rate)\n\n# 5. 在测试集上评估模型性能\ntest_intercept = np.ones((test_features.shape[0], 1))\ntest_features = np.hstack((test_intercept, test_features))\ntest_predictions = sigmoid(np.dot(test_features, weights))\ntest_predictions = np.round(test_predictions)\n\naccuracy = accuracy_score(test_target, test_predictions)\nprecision = precision_score(test_target, test_predictions)\nrecall = recall_score(test_target, test_predictions)\n\nprint(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\")\n\n# 6. 数据可视化处理（放到同一张图里的子图中）\n# 由于鸢尾花数据集有四个特征，我们可以选择任意两个特征来进行可视化处理。\n\nfeature_names = ['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']\ntarget_names = ['setosa', 'versicolor/virginica']\n\nfig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 15))\n\nfor idx, ax in enumerate(axes.flat):\n    i, j = idx // 2, idx % 2\n    ax.scatter(data[data['Species'] == 1][feature_names[i]], data[data['Species'] == 1][feature_names[j]], label='setosa')\n    ax.scatter(data[data['Species'] == 0][feature_names[i]], data[data['Species'] == 0][feature_names[j]], label='versicolor/virginica')\n    ax.scatter(test_features[test_target == 1][:, i+1], test_features[test_target == 1][:, j+1], marker='o', edgecolors='red', facecolors='none', label='setosa (predicted)')\n    ax.scatter(test_features[test_target == 0][:, i+1], test_features[test_target == 0][:, j+1], marker='x', color='red', label='versicolor/virginica (predicted)')\n    ax.set_xlabel(feature_names[i])\n    ax.set_ylabel(feature_names[j])\n    ax.legend()\n\nplt.tight_layout()\nplt.show()\n\n# 7. 尝试调整学习率、迭代次数等参数，观察对模型性能的影响\n# 你可以尝试不同的学习率和迭代次数，观察模型在测试集上的性能变化。\n\n\n\n结论\n\n于是我们就能得到如上的图片，并且控制台打印如下：\nStep 0, Log-Likelihood: -466.2106144434709\nStep 100, Log-Likelihood: -0.36586843732581664\nStep 200, Log-Likelihood: -0.261779308423121\nStep 300, Log-Likelihood: -0.2055975355203343\nStep 400, Log-Likelihood: -0.17016379364395556\nStep 500, Log-Likelihood: -0.14565669423300498\nStep 600, Log-Likelihood: -0.12763643409226652\nStep 700, Log-Likelihood: -0.11379421631281457\nStep 800, Log-Likelihood: -0.1028071299788049\nStep 900, Log-Likelihood: -0.09386101997678553\nAccuracy: 1.0, Precision: 1.0, Recall: 1.0\n\n图片分析\n图片中的子图：在图片中的每个子图中，横轴和纵轴分别表示两个特征，点的分布代表鸢尾花数据集中的样本分布。蓝色点表示’Setosa’类别，橙色点表示’Versicolor’和’Virginica’类别。红色圆圈（’o’）表示模型预测为’Setosa’类别的样本，红色叉（’x’）表示模型预测为’Versicolor’和’Virginica’类别的样本。\n分析子图的区分度：观察每个子图中的蓝色点和橙色点的分布情况，可以看出这两类样本在这两个特征上的区分度。如果两类样本在某个特征上有明显的分离，说明该特征对分类有较强的区分能力。\n分析预测结果：观察红色圆圈和红色叉的分布情况，它们代表了模型在测试集上的预测结果。如果模型分类准确，预测为’Setosa’类别的样本应该位于蓝色点的附近，预测为’Versicolor’和’Virginica’类别的样本应该位于橙色点的附近。如果红色圆圈和红色叉分布与蓝色点和橙色点重叠较少，说明模型的预测效果较好。\n\n控制台分析从控制台打印的日志可以看出模型在训练过程中的对数似然性（Log-Likelihood）逐步增大，并在迭代次数较少时就收敛到一个较小的负值。最后，模型在测试集上的评估结果显示准确率（Accuracy）、精确率（Precision）和召回率（Recall）均为1.0，即100%。\n对于对数似然性的变化：\n\n在训练初始阶段（Step 0到Step 100），对数似然性从一个较大的负值逐渐减小，说明模型的拟合效果在改进，损失逐渐减小。\n在训练中期（Step 100到Step 500），对数似然性下降幅度较大，模型在这个阶段学习到了较多的特征权重，开始更好地拟合训练集。\n在训练后期（Step 500到Step 900），对数似然性下降速度减缓，模型接近收敛。这时候模型已经较好地拟合训练集，但仍然可能存在一些小的误差。\n\n对于评估结果：\n\n准确率、精确率和召回率均为1.0，表示模型在测试集上的分类结果完美地匹配了真实标签。准确率表示模型正确分类样本的比例，精确率表示模型预测为正类的样本中真正为正类的比例，召回率表示模型正确识别正类样本的比例。这些指标都为1.0表明模型对于’Setosa’类别的预测完全正确，没有产生误分类。\n\n综合来看，这个结果可能存在一些问题：\n\n数据集可能过于简单：鸢尾花数据集相对简单，可能存在较强的线性关系，使得逻辑回归模型能够在这个数据集上表现得很好。\n过拟合：虽然在测试集上表现良好，但模型可能在训练集上过拟合，过度拟合了训练集的特点，导致在测试集上泛化能力较差。\n\n为了更好地评估模型性能，你可以进行交叉验证和尝试使用其他复杂度较高的数据集。交叉验证能够更全面地评估模型的泛化能力，复杂度较高的数据集能够更好地反映模型在现实场景中的表现。同时，尝试调整学习率、迭代次数等超参数，观察对模型性能的影响。这样可以更全面地评估模型的性能，并找到合适的模型和参数组合。\n","slug":"Secondary-classification-of-Iris","date":"2023-07-19T10:14:24.000Z","categories_index":"","tags_index":"Machine Learning,笔记","author_index":"General_K1ng"},{"id":"4c5f4ebe8f68ff24ce30098465671f7c","title":"分类与逻辑回归","content":"在机器学习的广袤领域中，分类问题犹如一片神秘的森林，吸引着众多探险家的目光。我们可以将自己想象成一位勇敢的森林导游，带领着各种生物来到分类问题的奇妙世界。\n什么是分类问题？在这片森林中，我们将聚焦于探讨分类问题。这与我们之前遇到的回归问题有些相似，但又有所不同。在分类问题中，我们要预测的目标值只有少数几种离散取值。我们现在先专注于二分类问题，也就是只能是0或者1。就像在森林中，我们要将每个生物划分为两类，比如“可爱的小动物”和“奇怪的怪兽”。0通常被称为负类，而1被称为正类，有时也用符号“-”和“+”来表示。在训练样本中，对于每个输入，我们都有相应的标签，也被称为标签。\n分类问题是机器学习中最常见的任务之一，我们的目标是构建一个模型，能够将新的未知数据准确地分类到正确的类别中。\n这个森林中的探险涉及以下关键要素：\n\n特征（Features）：每个生物都有一组特征，描述了它们的某些属性。这些特征可以是数字、文字、图像等形式，用于描述样本的特点。\n类别（Classes）：我们的目标是将每个生物分到预先定义的类别中。这些类别可以是二元的（例如，可爱的/奇怪的、是/否）或多元的（例如，红色/蓝色/绿色、动物种类）。\n训练数据（Training Data）：我们拥有一批标记好的样本，这些样本是已知类别的数据。我们将用这些数据来训练我们的模型，让它能够学习如何进行正确的分类。\n分类器（Classifier）：作为森林导游，我们需要一个特殊的工具，帮助我们将新生物正确地分类。这个工具就是分类器，它会根据生物的特征来做出分类决策，并将其划分到最有可能的类别中。一些常见的分类器包括逻辑回归、决策树、支持向量机等。\n\n我们可以使用分类问题的技术来构建垃圾邮件过滤器、图像识别器、情感分析器等各种实用的应用。\n了解了分类问题的本质和关键要素，我们就可以自信地踏入这片神奇的森林。接下来，让我们深入研究森林中一种重要的工具——逻辑回归，帮助我们更好地了解并解决分类问题。在这次奇妙的探险中，我们将发现更多的惊喜和乐趣！:deciduous_tree:\n逻辑回归：智慧护卫的二分类大师在机器学习的世界中，逻辑回归是一位智慧而灵活的护卫，专门擅长解决二分类问题。想象一下，他是我们探险中的得力助手，帮助我们在数据的海洋中，区分出两个不同的类别。无论是判断邮件是否为垃圾邮件，预测疾病是否会发生，还是决定客户是否会购买某个产品，逻辑回归都能忠实地指引我们找到正确答案。\n逻辑回归与线性回归的区别在分类问题中，我们通常会遇到一个挑战：目标值只能取0或者1，而线性回归的模型可能会给出超过这个范围的预测结果。为了解决这个问题，逻辑回归改变了我们的模型假设，引入了一个新的假设函数。这个函数使用了一个特殊的函数，也称为逻辑函数或Sigmoid函数，来确保预测结果总是在0和1之间。\n逻辑函数（Sigmoid函数）我们可以忽略是离散值的事实，使用我们之前的线性回归算法来尝试预测给定的。然而，很容易构造出在这种方法表现非常糟糕的例子。直观地讲，当我们知道时，的取值大于1或小于0是没有意义的。\n为了解决这个问题，让我们改变我们假设的形式。我们将选择：当这被称为逻辑函数或Sigmoid函数。以下是的绘图：\n\n\n我们可以看到，当趋近于正无穷时，趋近于1，而当趋近于负无穷时，趋近于0。这样的性质让我们的预测结果总是在合理的范围内，非常适合处理分类问题。此外，，因此也包括，始终保持在0和1之间。与之前一样，我们保持了的约定，使得。\n逻辑回归的拟合在逻辑回归中，我们需要拟合参数。与线性回归一样，我们使用了最大似然估计的方法来拟合参数。这意味着我们为分类模型赋予一组概率假设，然后通过最大似然估计来找到最合适的参数，使得我们的模型能够尽可能地拟合训练数据。 :detective:\n逻辑回归的参数拟合与最大似然估计在逻辑回归中，我们已经选择了逻辑函数作为我们的激活函数，它有助于将预测结果限制在0和1之间。同时，逻辑函数的导数具有一个非常有用的性质，这对我们进行参数拟合非常重要。\n我们将其写为：\n似然性与最大似然估计为了拟合逻辑回归模型的参数，我们需要定义一个衡量拟合程度的度量，这就是似然性（Likelihood）。对于逻辑回归而言，我们可以通过最大似然估计来找到最合适的参数。\n假设我们有个训练样本，每个样本的特征为，对应的标签为，其中。我们假设这些样本是独立生成的，即每个样本的生成与其他样本无关。然后，我们就可以写出参数的似然性。\n让我们假设：请注意，这可以更紧凑地写成假设这个训练示例是独立生成的，我们可以写出参数的似然性：\n为了计算方便，我们通常取似然性的对数，得到对数似然性（Log-Likelihood）：我们的目标是最大化对数似然性，即找到能够使得训练样本出现概率最大的参数。\n梯度上升算法我们如何最大化似然性？类似于我们在线性回归的推导中所做的，我们可以使用梯度上升算法。类似于线性回归中的梯度下降算法，梯度上升算法通过迭代更新参数来逐步寻找似然性的最大值。\n在向量表示法中，我们的更新将由 给出。（请注意更新公式中的正号而不是负号，因为现在我们要最大化函数而不是最小化。）\n\n\n\n\n\n\n\n\n\n这个更新公式表示在梯度上升算法中如何更新参数。在梯度上升算法中，我们希望最大化对数似然性，因为这是参数在训练数据上的似然性。梯度表示对数似然性关于参数的梯度向量，它告诉我们在当前参数的取值下，如何调整参数的方向，才能更好地拟合训练数据。\n具体来说，是学习率，表示每次更新参数的步长。在每一次迭代中，我们将当前的参数与学习率乘以梯度相加，得到新的参数。这样，我们逐步地沿着梯度的方向更新参数，直到达到一个满意的似然性最大值或者收敛。\n让我们从只有一个训练示例开始，我们可以计算对数似然性关于参数的偏导数，得到梯度：然后，我们使用以下更新规则来更新参数：其中，是学习率，用于控制每次更新的步长。\n可能有人看不懂，就用更易懂的表达来详细讲一下：\n\nClick to see more\n假设我们只有一个训练示例，其中是输入特征，是对应的标签。我们希望通过更新参数来使得我们的模型能够更好地拟合这个示例。\n首先，我们计算对数似然性关于参数的偏导数。这里需要用到逻辑函数的导数公式。\n推导过程如下：\n\n首先，我们计算对数似然性关于的偏导数：其中，表示通过逻辑函数将映射到0和1之间的预测结果。\n\n我们可以将上述偏导数的计算过程进行解释：\n\n首先，表示实际标签与预测值之间的差异。当预测值与实际标签一致时，差异为0，表示预测准确；当预测值与实际标签不一致时，差异为非零值，表示预测错误。\n其次，是预测错误的差异的方向，表示我们需要调整参数的方向，使得预测更加准确。\n最后，表示输入特征的第个分量，表示该特征对参数的影响程度。\n\n\n根据这个偏导数的计算结果，我们可以得到随机梯度上升法则的更新公式：其中，是学习率，用于控制每次参数更新的步长。这个公式告诉我们，在每一次更新中，我们将根据预测结果与实际标签的差异，乘以输入特征的对应分量，再乘以学习率，来更新参数。\n通过这样的参数更新过程，我们逐步调整参数的取值，使得我们的模型能够更好地拟合训练示例。这样，我们就可以使用逻辑回归来解决分类问题，并取得优秀的结果。\n\n\n\n\n如果将其与LMS更新规则进行比较，我们会发现它们看起来完全一样；但这并不是同一个算法，因为现在被定义为的非线性函数。尽管如此，令人惊讶的是，对于一个相当不同的算法和学习问题，我们最终得到了相同的更新规则。这是巧合吗，还是背后有更深层次的原因？我们将在讨论广义线性模型（GLM）时回答这个问题。\n任务任务，确实，只看不练可能什么都学不会，那么问题就来了，依旧是我让GPT生成的。\n作业任务一：逻辑回归代码实现与应用任务描述：学生需要使用Python或其他编程语言实现逻辑回归算法，并应用该算法来解决一个二分类问题。\n任务步骤：\n\n编写逻辑回归算法的代码实现，包括计算逻辑函数、计算对数似然性、梯度上升算法等关键部分。\n选择一个适合的二分类数据集，可以使用公开数据集或者自己构造一个数据集。\n将数据集分成训练集和测试集。\n使用训练集来训练你实现的逻辑回归模型。\n在测试集上评估你的模型性能，计算准确率、精确率、召回率等指标。\n最好进行数据可视化处理，让结果更直观。\n可选：尝试调整学习率、迭代次数等参数，观察对模型性能的影响。\n\n\n\n\n\n\n\nTIP\n\n准确率（Accuracy）： 准确率是最常用的模型性能指标之一，它表示模型正确预测的样本数与总样本数之间的比例。即：(预测正确的样本数) / (总样本数)。准确率越高，表示模型的整体性能越好。\n精确率（Precision）： 精确率是针对预测为正例的样本而言的，它表示在所有预测为正例的样本中，模型正确预测为正例的比例。即：(真正例数) / (真正例数 + 假正例数)。精确率高表示模型对正例的预测较准确。\n召回率（Recall）： 召回率是针对实际为正例的样本而言的，它表示在所有实际为正例的样本中，模型正确预测为正例的比例。即：(真正例数) / (真正例数 + 假负例数)。召回率高表示模型对正例的识别能力较强。\n\n\n\n我们这里可以使用一些著名的数据集，比如鸢尾花数据集\n作业任务二：逻辑回归性能优化任务描述：学生需要探索不同方法来优化逻辑回归算法的性能，并比较它们的效果。\n任务步骤：\n\n研究逻辑回归算法的原理和应用场景，了解逻辑回归的优缺点。\n选择一个适合的二分类数据集，可以使用公开数据集或者自己构造一个数据集。\n将数据集分成训练集和测试集。\n使用标准的逻辑回归算法来训练模型，并在测试集上评估模型性能，计算准确率、精确率、召回率等指标。\n尝试以下优化方法，并比较它们对模型性能的影响：\n特征缩放：尝试对特征进行缩放，例如使用标准化或归一化处理。\n多项式特征：尝试使用多项式特征来增加模型的复杂度。\n正则化：尝试使用L1或L2正则化来减少过拟合问题。\n不同的损失函数：尝试使用其他损失函数，如交叉熵损失函数。\n学习率调整：尝试使用不同的学习率，并观察其对模型训练的影响。\n\n\n分析不同优化方法对模型性能的影响，讨论哪些方法对提高模型性能效果更明显。\n\n","slug":"Classification-and-logistic-regression","date":"2023-07-18T09:41:28.000Z","categories_index":"","tags_index":"Machine Learning,笔记","author_index":"General_K1ng"},{"id":"90b9df300d80d6a498525ab2ef94faa4","title":"烟雨满楼山断续，人闲倚遍阑干曲","content":"窗外，暴雨纷纷，乌云低垂，苏州的梅雨季节如约而至。在这座古城的图书馆中，我坐在十几米高的落地窗前，眺望着那阴暗的天空，仿佛被乌云所包围，宛如置身于一个神秘而迷人的世界。\n耳机中传来舒缓怅寥的音乐，音符如烟，缓缓弥漫在空气中，将我渐渐带入一种无拘无束的心境。这样的境地，让我想起了一首曲子，曲调轻盈曼妙，与窗外的烟雨相得益彰。我静静倚在阑干之上，感受着外界的风雨，也感受着内心的起伏。\n雨滴轻拍着窗户，似乎在诉说着它们的故事。有时，它们轻柔细密，如琴弦上的音符，弹奏着悠扬的旋律；有时，它们密集而坚决，如大自然的鼓点，奏响着壮丽的交响。窗外的景象，让我不禁想起人生的变幻无常，有时充满温柔与宁静，有时又充满挑战与考验。\n思绪在雨中飘散，回忆与幻想交织在一起。曾经的美好时光如烟雾般逝去，我开始怀念那些曾经在雨中共度的时光。那时的我们，笑声回荡在雨中，雨水洒落在身上，却带不走我们的快乐与真诚。而今，人们似乎忙碌得已经忘记了停下脚步欣赏雨中的美好，忘记了雨后的清新与宁静。\n窗外的世界与内心的世界交错在一起，仿佛现实与幻想融为一体。滚滚闷雷与闪电，如同内心的冲动和矛盾。我感受到了自然的力量，也感受到了自己内心的深处。这样的时刻，仿佛让我与自己对话，让我重新审视人生的意义和价值。\n如画般的烟雨世界里，人生的意义何在？曾经的欢笑与忧伤，如同雨滴一般洒落在岁月的长河中，渐行渐远。我们追逐着时光的脚步，却不曾停下来，静心感受雨滴的触碰，细数人生的珍贵瞬间。\n社会喧嚣纷杂，人们忙于奔波，追逐物质的诱惑和名利的虚幻。而在这个纷扰的世界里，倚在窗前，感受着烟雨的滋润，心灵也逐渐清澈起来。沉浸在自然的怀抱中，如同一片飘游的落叶，在风雨中悠然自得。\n窗外的雨丝细密，宛如命运的细微变化，我们往往忽略了其中蕴含的深意。雨点在空中交织，汇聚成一片迷蒙的幕帘，将现实与梦幻交错。在这濛濛雨幕之中，我感到一种超越物质束缚的力量。人生不应仅仅是功利与得失，而是要追寻内心的平静与自由。\n或许，我们需要重新审视雨后的清新与宁静。风雨过后，自然焕发出崭新的生机，洗净尘埃，洒满希望。我们也应该学会洗去尘世的浮华，重拾内心的宁静。无论是风雨中的人生起伏，还是世俗纷扰中的烦恼，我们都应该保持一颗平和的心态，让内心如烟雨一般潋滟。\n窗前，我静观着烟雨中的景象，思绪渐渐清晰。雨滴拍打着窗户，如同敲打着内心的门扉，唤醒沉寂已久的思考。我明白，人生的意义并非只有在追逐外在的名利与成就中才能找到，而是要在心灵的寄托和内心的自由中感悟。\n窗外的烟雨依旧满山，而我在烟雨中寻找着自己。在这座古城的图书馆里，我凝视着窗外，瞻仰着世间的变幻。或许，我们需要时刻保持对内心的关照，让心灵在烟雨中沐浴，感受到生命的真谛。人生如烟雨，瞬间绽放，转瞬消散。而唯有在内心的澄明中，才能拥有永恒的宁静与自由。\n这烟雨满楼山断续，人闲倚遍阑干曲。我愿倚在窗前，继续聆听雨点的轻拍，感受大自然的魅力。我愿将思绪凝成文字，传达内心的触动与感悟。因为在这烟雨之中，我找到了生命的力量，找到了心灵的栖息地。\n他说：\n“人生如烟雨，一朝繁华，一念清欢。”\n","slug":"烟雨满楼山断续","date":"2023-07-17T09:23:37.000Z","categories_index":"","tags_index":"随笔","author_index":"General_K1ng"},{"id":"465c62620dad1684532695600a6cd19f","title":"局部加权线性回归*","content":"引言回顾最小二乘法的概率解释，我们曾深入研究过如何通过最小化误差的平方和，寻找最佳的模型参数。这个方法的确非常强大，但有时候我们需要更加灵活和精确的工具来解决特定的问题。\n于是，引入局部加权线性回归（Locally Weighted Linear Regression）。这个方法可以被视为我们探险旅程中的一把望远镜，帮助我们看到更加微妙的模式和趋势。它以一种非常独特的方式，通过为每个数据点赋予一定的权重，使得我们的模型更加关注那些在当前预测点附近的样本。\n这里的”局部加权”，就好像是一把神奇的放大镜，它能够放大我们感兴趣的那些数据点，并且根据它们的特点，为我们提供一种个性化的预测模型。无论是在金融领域，医疗研究，还是天气预测，局部加权线性回归都能够以其独特的魅力，帮助我们更好地理解和解决问题。\n这就像是在一片茂密的丛林中，我们只专注于离我们最近的树木和植被，而忽略了远处的景象。局部加权线性回归带给我们的是一种局部敏感性，使我们能够更加准确地预测和理解数据的变化。\n局部加权线性回归（LWS）欠拟合与过拟合考虑一个让我们一起探索的有趣问题：如何从输入预测输出呢？这就是我们今天要聊的局部加权线性回归（LWR）算法啦！想象一下，我们置身于一个神奇的数据世界中，我们希望找到一种方法，能够让我们的模型更好地适应这些数据点。\n嘿，看看这张魔法般的图片吧！最左边的图展示了我们试图通过一条直线去拟合这些数据点的情况。可是，你有没有发现，这些点并不完全落在这条线上呢？是不是感觉有些不太对劲？没错，这就是我们所谓的欠拟合。这位可爱的小模型童鞋似乎没有完全抓住数据中的结构，留下了一些没被捕捉到的东西。\n\n\n于是，我们心生了一个奇妙的想法：如果我们再加上一个特征，试试拟合这样的模型，会发生什么呢？嗯嗯，看中间的图，你会发现拟合效果好像稍微好了一些。看起来添加更多的特征会让拟合效果变得更好，是不是有些开心呢？但是，小心别太过头哦！右边的图就展示了一个过拟合的例子，我们使用了一个5阶多项式去拟合这些数据。看起来，尽管拟合曲线完全通过了数据点，但它在对不同房屋面积预测房价方面的表现可能并不好。所以，记住了，过于贪心可不是好事哦！\n权重好啦，让我们稍微放慢脚步，先来简单介绍一下局部加权线性回归（LWR）算法吧！想象一下，当我们拥有足够多的训练数据时，特征的选择变得不那么重要了。这里，LWR算法就是我们的小助手，帮助我们更好地拟合数据。虽然我们只是稍微提一下，但是不要担心，在后面的作业中，你将有机会深入探索LWR算法的一些特性。\n在传统的线性回归算法中，要在查询点处进行预测（也就是评估），我们会按照以下步骤进行：\n\n通过最小化来拟合参数。\n将作为我们的预测结果输出。\n\n然而，在局部加权线性回归算法中，我们将迈出一小步，踏入了一个可爱而神奇的世界。请跟紧我，我们一起看看LWR算法的魔法步骤：\n\n通过最小化来拟合参数。\n将作为我们的预测结果输出。\n\n在这里，是非负权重值。直观地说，如果对于特定的，很大，那么在选择时，我们会努力使尽可能小。如果很小，那么在拟合中，的误差项将被忽略。\n那么，如何确定这些神奇的权重呢？一个非常常见的权重选择方式是：\n\n\n\n\n\n\n\n\n\n如果x是向量值的，这个公式可以推广为或者，其中或的选择适当。\n请注意，权重值取决于我们希望预测的特定点。而且，如果很小，那么会接近1；如果很大，那么就会很小。所以，我们可以说，对于与查询点相近的训练样本，我们赋予它们更高的“权重”，而离查询点更远的样本则具有较低的“权重”。真是一种魔法般的思想！\n还要注意的是，虽然权重公式在形式上类似于高斯分布的密度函数，但与高斯分布并没有直接的关联，特别是不是一个随机变量，无论它是否服从正态分布或其他分布。（这是一种可爱的小魔法，不是吗？）\n带宽参数控制着训练样本权重随其与查询点之间距离的衰减速度。你知道吗？这个就是我们所说的带宽参数，它也是你在后面任务中将要实验的内容之一。它决定了魔法的强弱程度！\n现在，我们已经见识了第一个非参数算法的例子，它就是局部加权线性回归。相比之下，之前我们接触的（无权重的）线性回归算法被称为参数学习算法，因为它具有一组固定的有限参数（），这些参数与数据进行拟合。一旦我们拟合了参数并将它们存储起来，我们就不再需要保留训练数据来进行未来的预测。\n但是，和LWR不同哦！为了使用局部加权线性回归进行预测，我们需要保留整个训练集。这就是所谓的非参数，因为为了表示假设，我们需要存储与训练集规模成线性增长的信息量。\n特点LWR算法的魔力之一在于它的灵活性和适应性。它不仅仅是一个固定的模型，而是根据数据的特点和查询点的需求，为每个预测问题个性化地构建模型。这就像我们有一位聪明的小精灵，他根据数据的不同部分，以及与查询点的距离，灵活地调整预测模型，以获得最佳的结果。\n嗯，你或许会问，为什么要引入这种灵活性呢？这是因为在现实世界中，我们经常面对各种各样的数据模式和问题。有时，数据可能在某个区域内呈现出线性关系，而在另一个区域则呈现出非线性关系。有时，我们对于某些区域的预测更加关注，希望能够更准确地捕捉到那些重要的点。这时，LWR算法就展现出了它的独特优势。\n让我们回到我们的探险之旅。在LWR算法中，带宽参数起着至关重要的作用。这个参数控制着样本权重随其与查询点之间距离的衰减速度。想象一下，如果我们选择一个较小的，那么只有离查询点非常近的训练样本才会受到较高的权重，而离查询点较远的样本则会受到较低的权重。这就好像我们的小精灵更注重那些距离查询点更近的样本，认为它们对于预测更加重要。\n另一方面，如果我们选择一个较大的，那么样本的权重衰减速度将变得较慢，离查询点较远的样本仍然会有较高的权重。这就好像我们的小精灵更加关注整体的数据趋势，不过仍然保留了远离查询点的样本的影响。\n嘿，还记得我们之前提到的权重选择公式吗？，这是一个非常常见的选择。但也请注意，这只是一个示例，实际上还有其他的权重选择方式，可以根据具体问题进行调整和探索。\n我知道你一定迫不及待地想要实践一下LWR算法了。在接下来的作业中，你将有机会亲自尝试不同的带宽参数，并观察它对预测结果的影响。这将帮助你更好地理解LWR算法的运作原理和特性。\nLWR算法步骤LWR算法的执行包括以下步骤：\n\n拟合参数θ：通过最小化加权误差来拟合参数。这里，是一个非负的权重值，用于调整每个训练样本在拟合过程中的重要性。\n预测：使用得到的参数对新的查询点进行预测。计算，将其作为我们的预测结果输出。\n\n在这里，我们将通过逐步展开这些步骤，深入了解每个步骤的细节和原理。\n拟合参数在LWR算法中，拟合参数的关键在于最小化加权误差。这里的权重决定了每个训练样本的重要性，进而影响参数的拟合过程。\n要拟合参数，我们需要选择合适的权重。在LWR中，一个常见的权重选择方式是使用高斯核函数，就是刚刚我们见到的：复习一下，在这个公式中，是第个训练样本的特征值，是查询点的特征值，是带宽参数。这个公式的作用是根据查询点与训练样本之间的距离，赋予每个训练样本一个权重值。距离越近的样本将具有较高的权重，对参数的拟合起到更大的影响；而距离较远的样本则具有较低的权重，对参数的拟合影响较小。\n这里，带宽参数起着关键的作用。它决定了权重随着距离的衰减速度。较小的会导致权重衰减较快，只有距离查询点较近的样本会对参数拟合产生较大的影响；而较大的会导致权重衰减较慢，距离查询点较远的样本仍然具有较高的权重。\n为了拟合参数，我们可以使用各种数值优化方法，如梯度下降或正规方程法。在优化过程中，我们使用加权误差作为目标函数，并根据权重对样本进行加权。\n预测一旦我们拟合了参数，我们就可以使用它来对新的查询点进行预测。预测的过程非常简单，我们只需计算，并将其作为我们的预测结果输出。\n这个预测过程可以看作是使用已经拟合好的参数对新的输入进行线性组合的过程。通过将参数与特征值进行线性组合，我们得到了我们对于新查询点的预测结果。\n通过拟合参数和预测过程，LWR算法为我们提供了一种灵活而强大的方式来适应不同的数据模式和预测需求。它允许我们个性化地构建模型，并根据查询点的特征和数据的分布情况进行个性化的预测。\n任务这个任务是我让GPT给出来的，因为毕竟在斯坦福原有的课程当中，这节课选修课，我也没找到作业在哪（其实是我懒）。。。TT\n任务1：调整带宽参数在这个作业中，你将尝试调整带宽参数，并观察其对LWR算法的影响。你可以选择一些不同的值，比如0.1、1、10，并进行如下实验：\n\n对于每个值，使用LWR算法进行参数拟合，并得到相应的参数。\n使用得到的参数对测试集中的样本进行预测，并计算预测结果的均方误差（Mean Squared Error）。\n观察不同值下的预测结果和均方误差之间的关系。\n\n通过这个作业，你将能够理解带宽参数对LWR算法的影响。较小的值会导致模型更关注查询点附近的训练样本，可能会出现过拟合的情况；而较大的值则会使模型更加关注整体的数据趋势，可能会出现欠拟合的情况。你可以通过观察均方误差来评估不同值下模型的性能。\n这个任务我写了个小程序，有python环境的可以尝试一下：\n\nClick to see more\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\n\ndef compute_weights(X_train, x, tau):\n    # 计算权重值\n    weights = np.exp(-(np.linalg.norm(X_train - x, axis=1) ** 2) / (2 * tau ** 2))\n    return weights\n\ndef fit_lwr(X_train, y_train, x, tau):\n    # 拟合参数θ\n    X = np.hstack((np.ones((X_train.shape[0], 1)), X_train))  # 添加常数项\n    weights = compute_weights(X_train, x, tau)\n    W = np.diag(weights)\n    theta = np.linalg.inv(X.T @ W @ X) @ X.T @ W @ y_train\n    return theta\n\ndef predict_lwr(X_train, y_train, X_test, tau):\n    predictions = []\n    for x in X_test:\n        theta = fit_lwr(X_train, y_train, x, tau)\n        x = np.hstack(([1], x))  # 添加常数项\n        y_pred = theta.T @ x\n        predictions.append(y_pred)\n    return np.array(predictions)\n\n# 生成示例数据集\nX, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n\n# 划分数据集\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 设置不同的带宽参数\ntau_values = [0.1, 1, 10]\n\n# 绘制数据集和拟合结果的图像\nplt.figure(figsize=(12, 8))\n\nfor i, tau in enumerate(tau_values):\n    plt.subplot(2, 2, i+1)\n\n    # 绘制训练数据集\n    plt.scatter(X_train, y_train, color='b', label='Training Data')\n\n    # 拟合参数θ\n    theta = fit_lwr(X_train, y_train, X_train, tau)\n    print(f\"带宽参数τ = {tau}，拟合得到的参数θ：{theta}\")\n\n    # 预测并计算均方误差\n    y_pred = predict_lwr(X_train, y_train, X_test, tau)\n    mse = np.mean((y_pred - y_test) ** 2)\n    print(f\"带宽参数τ = {tau}，测试集上的均方误差：{mse}\\n\")\n\n    # 绘制拟合曲线\n    x_plot = np.linspace(np.min(X_train), np.max(X_train), 100)\n    X_plot = np.hstack((np.ones((x_plot.shape[0], 1)), x_plot.reshape(-1, 1)))\n    y_plot = X_plot @ theta\n    plt.plot(x_plot, y_plot, label=f\"τ = {tau}\")\n\n    plt.xlabel('X')\n    plt.ylabel('y')\n    plt.legend()\n    plt.title(f'Local Weighted Linear Regression (τ = {tau})')\n\nplt.tight_layout()\nplt.show()\n\n\n这段代码首先使用make_regression函数生成一个示例数据集，（运用了种子来进行随机数据集，便于复现），然后使用train_test_split将数据集划分为训练集和测试集。\n然后，compute_weights函数用于计算权重值，fit_lwr函数用于拟合参数，predict_lwr函数用于进行预测。\n在主程序中，我们设置了不同的带宽参数值[0.1、1、10]，然后对每个参数值进行拟合和预测。最后，我们计算并输出每个参数值下测试集上的均方误差。\n使用了plt.subplot函数来创建一个2x2的子图布局，并在每个子图中绘制不同带宽参数下的拟合结果。每个子图显示了训练数据集的散点图和相应的拟合曲线。\n图像如下\n\n\n你可以根据实际情况修改代码，使用自己的数据集和问题进行实验。通过观察不同带宽参数下的拟合效果和预测误差，你将能够更好地理解带宽参数对LWR算法的影响。\n\n\n作业2：应用LWR算法解决实际问题在这个作业中，你将应用LWR算法解决一个实际的问题。你可以选择感兴趣的领域，如房价预测、销量预测等，并按照以下步骤进行：\n数据集可以用我们之前用过的房价数据集，我放到这里：\n\nClick to see more\n# 数据集\nareas = np.array([2104, 1600, 2400, 1416, 3000, 1985, 1534, 1427, 1380, 1494, 1940, 2000, 1890, 4478, 1268, 2300, 1760, 1450, 3100, 2250, 2132, 2596, 1850, 2680, 1956, 1604, 2020, 2730, 2008, 1537, 2500, 1560, 2120, 2200, 1638, 2540, 2200, 2070, 2005, 1900, 2380, 1320, 2190, 2340, 2678, 1966, 1570, 1852, 2454, 2205, 2450])\nbedrooms = np.array([3,3,3,2,4,4,3,3,3,3,4,3,3,5,3,4,3,3,4,4,4,3,4,4,3,3,4,4,3,3,4,4,4,3,3,4,3,4,3,3,4,2,4,3,4,4,3,3,4,4,4])\nprices = np.array([400, 330, 369, 232, 540, 320, 267, 199, 245, 347, 334, 383, 339, 699, 259, 410, 350, 315, 590, 410, 399, 459, 325, 480, 349, 285, 365, 525, 375, 295, 450, 280, 389, 425, 315, 475, 408, 382, 350, 380, 420, 230, 394, 416, 540, 385, 279, 360, 485, 405, 450])\n\n\n\n\n收集和准备数据集：选择一个合适的数据集，并对数据进行预处理，确保数据的质量和一致性。\n划分数据集：将数据集划分为训练集和测试集，用于参数拟合和模型评估。\n使用LWR算法进行参数拟合：根据训练集使用LWR算法拟合参数。\n模型评估：使用测试集进行模型评估，计算预测结果的均方误差或其他适当的评估指标。\n结果分析和改进：分析预测结果，并根据需要对模型进行改进和调整。\n\n通过完成这个作业，你将能够将LWR算法应用到实际问题中，并通过实践加深对算法的理解。你可以探索不同的数据集和问题领域，进一步挖掘LWR算法的潜力。\n","slug":"Locally-weighted-linear-regression-optional-reading","date":"2023-07-17T07:42:47.000Z","categories_index":"","tags_index":"Machine Learning,笔记","author_index":"General_K1ng"},{"id":"85691702e05d151e003d7396dcbea440","title":"概率解释*","content":"引言当涉及到机器学习算法时，有时我们不仅仅希望通过数学的角度来理解它们的原理，还希望探索它们的概率解释。在这个部分中，我们将探讨线性回归算法的概率解释。\n你有没有想过，为什么我们在回归问题中使用平方误差作为成本函数？为什么我们假设模型的预测值和真实值之间存在高斯分布的误差？通过概率解释，我们可以更深入地理解线性回归模型的工作原理，并从统计学的角度来看待它。\n当我们谈论概率解释时，让我们以一个简单易懂的例子来说明。假设你是一位面包师傅，你烘焙面包的时间和温度是你最关注的因素。你想要根据面包的温度来预测它的烘焙时间。\n现在，假设你已经收集了一些数据，包括了面包的温度和相应的烘焙时间。你想要建立一个模型，根据温度来预测烘焙时间。这就是一个典型的线性回归问题。\n现在，让我们用概率解释来理解这个问题。我们可以将线性回归模型看作是在给定面包温度的条件下，对烘焙时间的条件分布进行建模。换句话说，我们想要找到一个条件分布，它告诉我们在已知温度的情况下，烘焙时间可能的取值范围。\n通过概率解释，我们可以得到一个关键的洞察力：我们不仅仅是在寻找一个点估计，即给定温度预测单个烘焙时间，而是在寻找一个整个概率分布，它表示了在给定温度下烘焙时间的不确定性。\n这种概率解释对于面包师傅来说非常有用。它不仅告诉你在给定温度下的预测烘焙时间，还告诉你该预测的不确定性范围。这样，你就可以更加自信地做出决策，控制烘焙时间，确保面包在最佳状态下烘焙。\n所以，通过概率解释，线性回归模型不仅可以帮助你做出预测，还可以提供预测的不确定性估计，使你更加有信心地应对面包烘焙的挑战。这就是概率解释为我们带来的额外好处。\n概率解释在面对回归问题时，为什么线性回归，尤其是最小二乘成本函数 ，是一个合理的选择呢？让我们通过一组概率假设来解释这一点，根据这些假设，最小二乘回归可以被推导为一种非常自然的算法。\n我们假设目标变量和输入之间存在以下关系：其中  是一个误差项，用于捕捉未建模的影响（例如，我们没有在回归中包含与预测房价高度相关的某些特征）或者随机噪声。我们进一步假设  是独立同分布（IID）地遵循均值为零、方差为  的高斯分布（也称为正态分布）。我们可以表示这个假设为 “”，即  的概率密度函数为：\n\n\n\n\n\n\n\n\n\n在机器学习和数学中，exp 表示指数函数，即自然指数函数，记作 ，其中  是自然对数的底数（欧拉数，约等于2.71828）。指数函数是一个常用的数学函数，它的定义是将底数  提升到给定的指数值。\n在上述笔记中，exp 是将指数函数应用于括号内的表达式。例如，在计算高斯分布的概率密度函数时，指数函数被用于计算  这个指数部分。\n指数函数具有将非负实数映射到正实数的特性，它在概率密度函数和其他数学模型中经常被使用，例如高斯分布、指数分布等。\n因此，我们可以表示给定  和由参数  控制的  的分布为：这表示了  在给定  的条件下，根据参数  的分布。需要注意的是，我们不应将  视为条件概率  的一部分，因为  不是一个随机变量。我们还可以将  的分布写为 。\n在给定 （设计矩阵，包含所有 ）和  的情况下， 的整体分布是什么样的？数据的概率由  给出。这个量通常被视为 （以及可能的 ）的函数，对于固定的  值。当我们希望明确将其视为  的函数时，我们将其称为似然函数：根据对 （从而对给定的  和 ）的独立性假设，我们还可以将其写成如下形式：现在，考虑到这个将  和  关联的概率模型，我们应该以何种方式合理地选择参数  来获得最佳估计？最大似然原理指出，我们应该选择能够使数据的概率最大化的 。换句话说，我们应该选择能够最大化  的 。\n与最大化  等价的是最大化  的任何严格递增函数。特别地，如果我们转而最大化对数似然函数 ，推导会更加简单：：因此，最大化  得到与最小化相同的结果：我们将这个结果记为 ，也就是最初的最小二乘代价函数。\n总结一下，在数据的先验概率假设下，最小二乘回归对应于找到参数  的最大似然估计。因此，在这种假设下，最小二乘回归可以被认为是一种非常自然的方法，它只是在进行最大似然估计而已。（需要注意的是，概率假设并不是使得最小二乘成为完全合理和恰当的过程所必需的，还可能存在其他自然的假设可以用来证明它的合理性。）\n此外，根据我们之前的讨论，我们的最终  的选择并不依赖于  的值，实际上，即使  是未知的，我们也会得到相同的结果。当我们讨论指数族和广义线性模型时，我们将再次利用这一事实。\t\n举例说明假设你正在研究房屋价格与其尺寸之间的关系。你收集了一些房屋的尺寸和实际售价的数据，并希望使用机器学习来构建一个预测模型。在这种情况下，你可以使用最小二乘回归作为你的算法，并通过概率解释来理解它的合理性。\n根据概率解释，我们假设房屋价格与尺寸之间的关系可以通过以下方程表示：其中  是第  个房屋的实际售价， 是对应的尺寸特征， 是我们要学习的参数，而  则表示误差项。\n根据概率假设，我们假设误差项  是从均值为零、方差为  的高斯分布中独立同分布地抽样得到的。这意味着我们认为误差是随机的，并且服从正态分布。这个假设可以让我们使用概率密度函数来描述误差项的分布情况。\n现在，我们可以根据这个概率模型来定义给定  的条件下， 的分布：这表示给定  的情况下， 的分布是一个以  为均值、 为方差的高斯分布。\n我们的目标是找到使得观测到的数据的概率最大化的参数 。也就是说，我们希望选择参数 ，使得数据的整体概率  最大化。\n根据最大似然估计的原理，我们可以通过最大化似然函数  或对数似然函数  来获得最佳参数估计。在最小二乘回归中，我们常使用对数似然函数来简化推导。\n通过计算对数似然函数 ，我们可以将最大似然估计转化为最小化残差平方和的问题，即最小化代价函数 ：这刚好是最小二乘回归中使用的成本函数。\n因此，根据概率解释，最小化最小二乘成本函数  相当于在给定概率模型的前提下，寻找参数  的最大似然估计。这说明了最小二乘回归的合理性和自然性。\n补充当使用最小二乘法进行机器学习中的回归任务时，并不需要对概率解释的细节了如指掌。嗯，你没听错，概率解释并不是机器学习中的“铁板钉钉”。\n实际上，对于许多问题来说，最小二乘法就足够了，它能够给出很好的结果，而不需要我们费神去琢磨概率解释的种种细节。毕竟，最小二乘法是机器学习中非常常见且有效的方法。\n但是，不可否认的是，在某些情况下，了解概率解释和统计学原理是很有帮助的。特别是当你处理带有噪声的数据时，概率解释可以告诉你模型的不确定性和置信度。这样一来，你就能更好地理解和解释你的模型结果了。\n总而言之，了解最小二乘法是机器学习中的重点，而对概率解释的深入探究则是可选的。如果你只是想简单地应用最小二乘法来完成回归任务，那了解一些基本的原理和实现就足够了。当然，如果你对概率解释和统计学概念感兴趣，那么对于某些特定问题来说，深入研究概率解释会给你带来更深入的理解和分析能力。\n","slug":"Probabilistic-interpretation","date":"2023-07-17T06:02:56.000Z","categories_index":"","tags_index":"Machine Learning,笔记","author_index":"General_K1ng"},{"id":"8bd50a6b3cea7ecea2a8063e70b7409b","title":"正规方程","content":"引入在机器学习和线性回归中，我们经常需要通过训练数据来学习参数，以便建立一个能够准确预测目标变量的模型。前面我们已经介绍了梯度下降法，这是一种常用的优化算法，可以帮助我们找到最小化成本函数的参数值。\n除了梯度下降法，还有一种有趣而简洁的方法可以解决线性回归问题，它被称为正规方程（The Normal Equations）。正规方程提供了一种通过代数方法直接求解最优参数的方式，而不需要像梯度下降法那样迭代更新。\n让我们以一个生动的例子来理解正规方程。假设你是一名厨师，你想要制作一道美味的蛋糕。你知道蛋糕的味道取决于配料的种类和数量。你希望找到一个最佳的配料组合，使得蛋糕的口感和味道达到最佳。\n为了解决这个问题，你决定进行一系列实验。你准备了不同数量和种类的配料，并且每次制作蛋糕后，让一群品尝师评价蛋糕的口感。你记录下每个实验中使用的配料种类和数量，以及对应的评分。\n现在，你的目标是通过这些实验数据，找到一种最佳的配料组合，以获得最佳的蛋糕口感。你想要建立一个线性模型，通过配料的数量和种类预测口感评分。这个问题就可以转化为一个线性回归问题。\n正规方程提供了一种直接求解线性回归参数的方法。它的原理类似于代数方程的求解过程。通过对训练数据进行数学运算，我们可以得到一个公式，可以直接计算出最优的参数值。\n正规方程不需要像梯度下降法那样进行迭代更新，因此在某些情况下，它可能更加高效。然而，正规方程也有一些限制，例如当特征数量非常大时，计算复杂度会增加。\n在接下来的部分，我们将详细介绍正规方程的原理和应用。正规方程为我们提供了一种有趣而直接的方式来解决线性回归问题，让我们一起探索吧！\n正规方程正规方程是一种通过代数方法直接求解线性回归参数的方法，而不需要像梯度下降法那样进行迭代更新。它的原理是通过最小化成本函数，找到使得预测值与实际值之间差异最小的参数值。\n为了理解正规方程的原理，让我们再回到蛋糕制作的例子。你已经进行了一系列实验，记录了不同配料组合的口感评分。现在，你想要找到最佳的配料组合，使得蛋糕的口感评分最高。\n回忆一下线性回归模型的表示形式：。我们的目标是找到一组最优的参数，使得尽可能接近实际的口感评分。\n我们定义成本函数来衡量预测值与实际值之间的差异。对于线性回归问题，我们通常使用平方差误差（SSE）作为成本函数，即，其中是训练样本的数量。\n现在，我们的目标是找到最优的参数，使得成本函数最小化。而正规方程就提供了一种求解最优参数的解析解。具体来说，我们通过对关于参数的导数进行求解，并将其设置为零来最小化。\n在进行矩阵表示时，我们将训练样本的特征向量表示为矩阵，其中每一行代表一个样本的特征，每一列代表一个特征维度。类似地，我们将实际值表示为向量。那么，线性回归模型可以写成矩阵形式：。\n应用矩阵微积分的概念，我们可以求解成本函数关于参数的导数。这个导数称为梯度（gradient），用表示。当梯度为零时，我们得到正规方程的解。\n通过代数计算，我们可以得到正规方程的表达式：。这个表达式直接给出了最优参数的解析解。\n正规方程的优点在于它不需要进行迭代更新，可以直接得到最优参数的解析解。然而，它的计算复杂度取决于特征的数量，当特征数量非常大时，求解逆矩阵的计算可能变得耗时。\n在实际应用中，我们可以根据问题的特点选择使用梯度下降法还是正规方程。梯度下降法适用于大规模数据集和高维特征空间，而正规方程适用于小规模数据集和低维特征空间。\n矩阵导数矩阵导数是矩阵微积分中的重要概念，用于描述函数对矩阵变量的导数。在矩阵导数中，我们将函数从一个行列的矩阵映射到实数，定义为。为了求解矩阵导数，我们需要计算函数相对于矩阵的偏导数。矩阵导数本身也是一个行列的矩阵，其中元素表示函数对的偏导数。\n例如，假设是一个2行2列的矩阵，函数：定义为：在这个例子中，表示矩阵的元素。\n我们可以通过计算偏导数来得到矩阵导数的表达式。根据定义，我们计算对每个的偏导数，然后将它们组合成矩阵的形式。对于我们的例子，我们可以得到如下结果：这个结果展示了矩阵导数的计算方式。每个元素都是相应偏导数的结果。例如，元素是对的偏导数，元素是对的偏导数，以此类推。\n最小二乘法再探讨借助矩阵导数的工具，现在让我们通过闭式解来找到使最小化的的值。我们首先将用矩阵-向量表示法重新书写。\n给定一个训练集，定义设计矩阵为一个行列的矩阵（实际上是行列，如果我们包括截距项），其行包含训练示例的输入值：此外，让是一个维向量，包含来自训练集的所有目标值：现在，由于，我们可以很容易地验证：因此，利用向量的性质，我们有 ：最后，为了最小化，让我们找到它相对于的导数。因此，我们有：在第三步中，我们使用了的事实，在第五步中使用了和的事实，其中是对称矩阵。为了最小化，我们将其导数设为零，得到正规方程：因此，最小化的值可以通过以下方程的闭式解给出：\n\n\n\n\n\n\n\n\n\n请注意，在上述步骤中，我们隐含地假设是可逆矩阵。在计算逆矩阵之前，可以进行检查。如果线性无关的样本数量少于特征数量，或者特征不是线性无关的，则将不可逆。即使在这种情况下，也有可能通过额外的技术来“修正”这种情况，但为了简洁起见，我们在这里省略了这些内容。\n举例我们再回到最开始那个做烘焙的例子，假设你是一位厨师，想要研究面包的烘焙时间和温度之间的关系。你收集了一系列实验数据，记录下了烘焙时间和使用的温度。现在，你想要找到一个数学模型来预测未来的烘焙时间。这时，线性回归和最小二乘法就能派上用场了。\n现在，让我们使用矩阵导数的工具来重新表达成本函数。首先，我们定义设计矩阵，它是一个行列的矩阵，其中每一行包含一个实验样本的特征值（在我们的例子中就是温度）。我们还定义目标向量，它是一个维向量，包含对应每个实验样本的烘焙时间。\n我们收集了一些数据，记录了不同温度下烘焙面包所需的时间。现在我们要使用这些数据来训练一个线性回归模型，以便我们可以根据温度来预测烘焙时间。\n首先，让我们创建一个虚构的数据集（这是我用程序随机生成的）。假设我们有以下数据：\n\nClick to see more\n\n\n\n温度（摄氏度）\n烘焙时间（分钟）\n\n\n\n168.7\n41.4\n\n\n197.5\n52.2\n\n\n186.6\n45.0\n\n\n179.9\n43.7\n\n\n157.8\n42.8\n\n\n157.8\n32.0\n\n\n152.9\n31.9\n\n\n193.3\n45.8\n\n\n180.1\n41.0\n\n\n185.4\n48.7\n\n\n\n\n\n\n\n\n现在，我们将数据表示为输入特征矩阵和目标变量向量。是一个包含温度特征的矩阵，是对应的烘焙时间。\n接下来，我们将为矩阵添加截距项列。这样，矩阵的第一列将始终为1，以表示截距(intercept)。\n现在，我们可以使用正规方程来求解参数。正规方程的公式为：\n这个公式会给出使得模型最优拟合数据的参数值。\n控制台会输出：\nIntercept: -19.32\nSlope: 0.35\n\n\n\n\n\n为了应用这个公式，我们需要使用Python进行计算。我们可以使用NumPy库来进行矩阵运算。让我们来看看如何在Python中计算正规方程的闭式解：\n\nClick to see more\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)  # 设置随机种子，以便结果可复现\n\n# 创建输入特征 X（温度）和目标变量 y（烘焙时间）\nX = np.random.uniform(150, 200, 10).reshape(-1, 1)  # 温度范围在150到200之间\ny = 10 + 0.2 * X + np.random.normal(0, 5, 10).reshape(-1, 1)  # 烘焙时间=10 + 0.2*温度 + 噪声\n\n# 添加截距项列（全为1）到 X 矩阵中\nX = np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)\n\n# 计算参数 theta\ntheta = np.linalg.inv(X.T @ X) @ X.T @ y\n\nintercept = theta[0][0]\nslope = theta[1][0]\nprint(f\"Intercept: {intercept:.2f}\")\nprint(f\"Slope: {slope:.2f}\")\n\n\n# 绘制数据点\nplt.scatter(X[:, 1], y, label=\"Data\")\n\n# 绘制拟合的线性回归模型\nx_line = np.linspace(150, 200, 100)\ny_line = intercept + slope * x_line\nplt.plot(x_line, y_line, color=\"red\", label=\"Linear Regression\")\n\n# 添加标签和图例\nplt.xlabel(\"Temperature\")\nplt.ylabel(\"Baking Time\")\nplt.legend()\n\n# 显示图形\nplt.show()\n\n\n\n\n运行这段代码，我们会得到参数的值。在这个例子中，我们会得到两个参数：截距项参数和温度参数。这些参数表示烘焙时间与温度之间的线性关系。\n一旦我们求解出参数，我们就可以使用它来进行预测。给定一个新的温度值，我们可以通过计算来预测对应的烘焙时间。\n这节的内容会比较难以理解，希望可以反复阅读，如有疑问欢迎提出，说实话，我都有些没看懂。\n","slug":"The-normal-equations","date":"2023-07-17T04:09:05.000Z","categories_index":"","tags_index":"Machine Learning,笔记","author_index":"General_K1ng"},{"id":"eee27f691084ae51bee755f5fe41f548","title":"LMS算法","content":"欢迎来到新的一部分！现在我们将介绍一种非常有趣的算法，它被称为最小均方（Least Mean Squares，LMS）算法。这是一种用于优化线性回归模型的算法，它可以帮助我们找到最佳的参数组合，使得我们的预测结果与实际观测值之间的差异最小化。\nLMS算法实际上是一个非常聪明的算法，它的灵感来自于我们人类在学习过程中的一种思维方式。想象一下，当你在学习骑自行车或者学习弹吉他时，你并不会一次就掌握所有技巧。相反，你会不断地试验、调整和改进，直到你的动作越来越接近完美。\nLMS算法的原理也是类似的。它通过逐步调整模型的参数来最小化成本函数，就像我们逐步调整我们的动作来提高技能一样。在每一步中，LMS算法会计算出当前参数设置下的成本函数值，并根据这个值来调整参数，以便使下一次迭代的预测结果更接近实际观测值。这个过程就像是在不断地微调模型，让它的预测能够更准确地拟合实际数据。\n一个有趣的比喻是，想象你是一名音乐家，正在调音吉他。你会先弹奏一根弦，然后通过调整琴弦的张力来使音高趋近于理想的音高。LMS算法的工作方式类似于这个过程，它会在每一步中微调模型的参数，使得预测结果逐渐接近实际观测值，就像音高逐渐趋近理想音高一样。\nLMS算法是一种非常强大和常用的优化算法，特别适用于解决线性回归问题。它不仅可以用于预测骑行时间，还可以应用于各种其他领域，如金融、医疗和天气预测等。通过不断地微调参数，LMS算法帮助我们找到最佳的模型参数，使我们的预测结果更加准确和可靠。\nLMS算法我们继续探讨LMS算法！让我们首先回顾一下我们的目标：选择合适的参数来最小化成本函数。为了实现这一目标，我们需要一个搜索算法，该算法从一个”初始猜测”开始选择，然后通过迭代改变以使逐渐变小，直到我们收敛到使最小化的值。\n\n\n\n\n\n\n\n\n\n我们使用符号“a := b”来表示一种操作（在计算机程序中），该操作将变量a的值设置为等于变量b的值。换句话说，这个操作会用b的值覆盖a的值。相反，当我们在断言一个事实时，即a的值等于b的值，我们会写成“a = b”。\n那么，我们如何在每次迭代中更新参数呢？这就是LMS算法的精髓所在。它使用一种称为梯度下降的方法，以最陡的下降方向更新参数。具体而言，在每次迭代中，我们将参数更新为，其中是学习率。\n为了更好地理解LMS算法的更新规则，让我们以一个简单的例子来说明。假设我们只有一个训练样本，其中是我们的输入特征，是对应的目标值。我们的目标是根据输入预测出目标值。我们将使用线性模型来进行预测。\n这是一个非常自然的算法，它重复地朝着最陡的下降方向迈出一步。为了实现这个算法，我们需要计算出右侧的偏导数项。让我们首先计算出在只有一个训练样本的情况下的结果，这样我们就可以忽略的定义中的求和符号。为了更新参数和，我们需要计算成本函数对于每个参数的偏导数。通过计算，我们得到偏导数的表达式为：。这表明参数的更新量与误差项成比例，以及输入特征。根据这个结果，我们可以得到LMS算法的更新规则：这个规则被称为LMS更新规则（LMS代表“最小均方差”），也被称为Widrow-Hoff学习规则。这个规则具有几个看起来自然而直观的特性。例如，更新的幅度与误差项成比例；因此，例如，如果我们遇到一个训练样本，我们的预测几乎与的实际值相匹配，那么我们发现几乎不需要改变参数；相反，如果我们的预测与有较大的误差（即相距较远），那么参数将会有较大的变化。\n梯度下降法当我们使用机器学习算法解决问题时，经常需要最小化一个函数。梯度下降法（Gradient Descent）是一种常用的优化算法，用于找到函数的最小值。\n让我们通过一个生动的例子来解释梯度下降法。假设你是一位登山爱好者，目标是从山顶下到山脚的最短路径。你置身于山顶，但是你没有任何线索告诉你应该往哪个方向走。你面前一片云雾茫茫，你看不到山脚。然而，你手上有一个高度计可以告诉你当前的海拔高度。\n你的目标是找到一条最快的下山路径。你知道山的地形图呈现出一种斜率或坡度。你也知道下山的最陡峭方向就是当前位置的负梯度方向。\n梯度下降法的思想类似于登山者的行动。你观察当前位置的海拔高度，并朝着最陡峭的下坡方向迈出一步。然后，你再次观察新位置的海拔高度，继续朝着最陡峭的下坡方向迈出一步。你不断重复这个过程，逐步接近山脚。\n在数学中，我们使用类似的思想来最小化函数。假设我们有一个函数，我们希望找到它的最小值。梯度下降法通过迭代地计算函数的梯度，沿着梯度的反方向更新参数，以使函数的值逐渐减小。\n函数的梯度是一个向量，指示函数在给定点上最陡峭的上升方向。我们的目标是朝着最陡峭的下降方向前进，因此我们朝着梯度的反方向更新参数。\n\n\n\n\n\n\nTIP\n这个过程可以表示为以下步骤：\n\n初始化参数：选择一个初始的参数值作为起点。\n计算梯度：计算函数在当前参数值处的梯度。梯度告诉我们函数在该点上升的方向和速度。\n更新参数：根据梯度的方向和一个称为学习率的调整参数，更新参数值。\n重复步骤2和步骤3，直到达到停止条件。停止条件可以是达到最大迭代次数、参数变化很小或函数值达到某个阈值。\n\n\n\n通过迭代更新参数，梯度下降法能够找到函数的局部最小值或全局最小值，这取决于函数的性质和初始参数的选择。\n梯度下降法在机器学习中扮演重要角色，它是许多算法的基础，例如线性回归、逻辑回归和神经网络。它允许我们通过最小化成本函数来调整模型的参数，使模型更好地拟合训练数据。\n批量梯度下降我们已经推导出了适用于单个训练样本的LMS更新规则。但是，对于包含多个训练样本的训练集，我们可以通过将坐标更新组合成向量形式来简化更新规则：\n​\t\t\t\t重复直到收敛 {}\n通过将坐标的更新组合成向量θ的更新，我们可以以更简洁的方式重新编写更新式（1.1）：这种形式的更新规则被称为批量梯度下降，因为它在每次迭代中考虑整个训练集。需要注意的是，对于线性回归的优化问题，由于成本函数是一个凸二次函数，不存在局部最小值，只有一个全局最小值。因此，梯度下降算法总是会收敛到全局最小值（前提是学习率不要设置得太大）。\n\n\n当然python的代码如下，你可以自己尝试\n\nClick to see more\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 定义二次函数\ndef quadratic_function(x, y):\n    return x**2 + y**2\n\n# 定义二次函数的偏导数\ndef gradient(x, y):\n    return np.array([2*x, 2*y])\n\n# 定义梯度下降函数\ndef gradient_descent(gradient, initial_point, learning_rate, num_iterations):\n    path = [initial_point]\n    point = initial_point\n\n    for _ in range(num_iterations):\n        grad = gradient(*point)\n        point = point - learning_rate * grad\n        path.append(point)\n\n    return np.array(path)\n\n# 定义绘制等高线图的函数\ndef plot_contour(func):\n    x = np.linspace(-5, 5, 100)\n    y = np.linspace(-5, 5, 100)\n    X, Y = np.meshgrid(x, y)\n    Z = func(X, Y)\n\n    plt.figure(figsize=(8, 6))\n    plt.contour(X, Y, Z, levels=20)\n    plt.colorbar()\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.title('Contour Plot')\n    plt.grid(True)\n\n# 设置初始点、学习率和迭代次数\ninitial_point = np.array([3.0, 4.0])\nlearning_rate = 0.1\nnum_iterations = 20\n\n# 运行梯度下降算法\npath = gradient_descent(gradient, initial_point, learning_rate, num_iterations)\n\n# 绘制等高线图和路径\nplot_contour(quadratic_function)\nplt.plot(path[:, 0], path[:, 1], '-ro')\nplt.show()\n\n\n\n首先，图像展示了一个二维平面，其中轴和轴代表二次函数的输入变量的取值范围。二次函数由公式 给出，其中等高线表示函数值相等的点。等高线的形状呈现出圆形，因为函数是关于和的平方和的形式。\n其次，等高线的颜色表示函数值的大小。颜色条(colorbar)位于图像右侧，它显示了颜色与函数值的对应关系。颜色越深表示函数值越小，而颜色越浅表示函数值越大。在这个示例中，我们选择了20个等高线水平线，因此你可以看到等高线从内部圆开始，逐渐向外部圆扩展。\n接下来，红色的路径表示梯度下降算法的路径。我们使用初始点 (3.0, 4.0)作为起始点，并选择学习率为0.1，执行了20次迭代。梯度下降算法根据当前点的梯度信息来更新下一个点的位置，直到达到指定的迭代次数。红色路径显示了从初始点开始，沿着梯度下降方向逐步更新点的位置的过程。你可以看到路径开始在较陡峭的地方，然后逐渐向梯度变小的区域移动，最终趋近于函数的最小值(0, 0)。\n面积与房价我们继续研究梯度下降算法的不同变体！让我们先来看看批量梯度下降算法在拟合房屋价格预测模型时得到的结果。根据我们之前的数据集，通过运行批量梯度下降，我们得到了参数值和，它们可以用于构建线性模型来预测房屋价格，其中表示房屋的居住面积。如果我们绘制作为（面积）的函数，并结合训练数据，我们会得到上面的图表。这个模型给出了一个大致符合数据趋势的直线。\n\n\n当然，代码如下\n\nClick to see more\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 数据集\nareas = np.array([2104, 1600, 2400, 1416, 3000, 1985, 1534, 1427, 1380, 1494, 1940, 2000, 1890, 4478, 1268, 2300, 1760, 1450, 3100, 2250, 2132, 2596, 1850, 2680, 1956, 1604, 2020, 2730, 2008, 1537, 2500, 1560, 2120, 2200, 1638, 2540, 2200, 2070, 2005, 1900, 2380, 1320, 2190, 2340, 2678, 1966, 1570, 1852, 2454, 2205, 2450])\nprices = np.array([400, 330, 369, 232, 540, 320, 267, 199, 245, 347, 334, 383, 339, 699, 259, 410, 350, 315, 590, 410, 399, 459, 325, 480, 349, 285, 365, 525, 375, 295, 450, 280, 389, 425, 315, 475, 408, 382, 350, 380, 420, 230, 394, 416, 540, 385, 279, 360, 485, 405, 450])\n\n# 数据归一化（特征缩放）\nareas_normalized = (areas - np.mean(areas)) / np.std(areas)\nprices_normalized = (prices - np.mean(prices)) / np.std(prices)\n\n# 添加偏置项\nX = np.column_stack((np.ones(len(areas_normalized)), areas_normalized))\n\n# 初始化参数\ntheta = np.zeros(2)\nalpha = 0.01\niterations = 1500\n\n# 定义代价函数\ndef compute_cost(X, y, theta):\n    m = len(y)\n    h = np.dot(X, theta)\n    J = (1 / (2 * m)) * np.sum((h - y) ** 2)\n    return J\n\n# 批量梯度下降\ndef gradient_descent(X, y, theta, alpha, iterations):\n    m = len(y)\n    J_history = []\n    for _ in range(iterations):\n        h = np.dot(X, theta)\n        theta = theta - (alpha / m) * np.dot(X.T, h - y)\n        cost = compute_cost(X, y, theta)\n        J_history.append(cost)\n    return theta, J_history\n\n# 运行批量梯度下降算法\ntheta, J_history = gradient_descent(X, prices_normalized, theta, alpha, iterations)\n\n# 绘制拟合曲线\nx_values = np.linspace(-2, 2, 100)\ny_values = theta[0] + theta[1] * x_values\n\n\n# 绘制数据点和拟合曲线\nplt.scatter(areas_normalized, prices_normalized, label='Training Data')\nplt.plot(x_values, y_values, color='red', label='Linear Regression')\nplt.xlabel('Normalized Area')\nplt.ylabel('Normalized Price')\nplt.title('House Prices vs. Area (Linear Regression)')\nplt.legend()\nplt.show()\n\n\n\n\n继续考虑卧室数量接下来，如果我们考虑卧室数量作为输入特征之一，我们可以使用批量梯度下降来拟合模型并得到参数值，，。通过将卧室数量纳入考虑，我们可以构建一个更复杂的模型来预测房屋价格。\n\n\n代码如下\n\nClick to see more\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# 数据集\nareas = np.array([2104, 1600, 2400, 1416, 3000, 1985, 1534, 1427, 1380, 1494, 1940, 2000, 1890, 4478, 1268, 2300, 1760, 1450, 3100, 2250, 2132, 2596, 1850, 2680, 1956, 1604, 2020, 2730, 2008, 1537, 2500, 1560, 2120, 2200, 1638, 2540, 2200, 2070, 2005, 1900, 2380, 1320, 2190, 2340, 2678, 1966, 1570, 1852, 2454, 2205, 2450])\nbedrooms = np.array([3,3,3,2,4,4,3,3,3,3,4,3,3,5,3,4,3,3,4,4,4,3,4,4,3,3,4,4,3,3,4,4,4,3,3,4,3,4,3,3,4,2,4,3,4,4,3,3,4,4,4])\nprices = np.array([400, 330, 369, 232, 540, 320, 267, 199, 245, 347, 334, 383, 339, 699, 259, 410, 350, 315, 590, 410, 399, 459, 325, 480, 349, 285, 365, 525, 375, 295, 450, 280, 389, 425, 315, 475, 408, 382, 350, 380, 420, 230, 394, 416, 540, 385, 279, 360, 485, 405, 450])\n\n# 特征缩放（归一化）\nareas_normalized = (areas - np.mean(areas)) / np.std(areas)\nbedrooms_normalized = (bedrooms - np.mean(bedrooms)) / np.std(bedrooms)\nprices_normalized = (prices - np.mean(prices)) / np.std(prices)\n\n# 构建设计矩阵\nX = np.column_stack((np.ones(len(areas_normalized)), areas_normalized, bedrooms_normalized))\n\n# 初始化参数\ntheta = np.zeros(3)\nalpha = 0.01\niterations = 1500\n\n# 定义代价函数\ndef compute_cost(X, y, theta):\n    m = len(y)\n    h = np.dot(X, theta)\n    J = (1 / (2 * m)) * np.sum((h - y) ** 2)\n    return J\n\n# 批量梯度下降\ndef gradient_descent(X, y, theta, alpha, iterations):\n    m = len(y)\n    J_history = []\n    for _ in range(iterations):\n        h = np.dot(X, theta)\n        theta = theta - (alpha / m) * np.dot(X.T, h - y)\n        cost = compute_cost(X, y, theta)\n        J_history.append(cost)\n    return theta, J_history\n\n# 运行批量梯度下降算法\ntheta, J_history = gradient_descent(X, prices_normalized, theta, alpha, iterations)\n\n# 输出最终回归表达式\ntheta0 = theta[0]\ntheta1 = theta[1]\ntheta2 = theta[2]\nprint(f\"最终回归表达式: hθ(x) = {theta0:.2f} + {theta1:.2f}x1 + {theta2:.2f}x2\")\n\n# 绘制拟合曲面\nx1_values = np.linspace(-2, 2, 100)\nx2_values = np.linspace(-2, 2, 100)\nx1, x2 = np.meshgrid(x1_values, x2_values)\ny_values = theta0 + theta1 * x1 + theta2 * x2\n\n# 绘制数据点和拟合曲面\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(areas_normalized, bedrooms_normalized, prices_normalized, c='b', marker='o')\nax.plot_surface(x1, x2, y_values, color='r', alpha=0.5)\nax.set_xlabel('Normalized Area')\nax.set_ylabel('Normalized Bedrooms')\nax.set_zlabel('Normalized Price')\nax.set_title('House Prices vs. Area and Bedrooms (Linear Regression)')\nplt.show()\n\n\n\n\n最终控制台会输出\n最终回归表达式: hθ(x) = 0.00 + 0.93x1 + 0.04x2\n\n\n\n你可以看到，通过添加更多的特征，我们可以得到更准确的房屋价格预测模型。这说明特征选择对于机器学习模型的性能至关重要。\n随机梯度下降除了批量梯度下降，还有一种非常有效的替代方法，它被称为随机梯度下降。这种方法的算法如下：\nLoop{    for  to ,{\n​\t\t\t\t\t\t​\t\t}\n}\n通过将坐标的更新组合成向量θ的更新，我们可以以更简洁的方式重新编写更新式:在这个算法中，我们遍历整个训练集，并且在每次遇到一个训练样本时，只使用该样本的误差梯度来更新参数。这个算法被称为随机梯度下降或增量梯度下降。与批量梯度下降不同的是，随机梯度下降可以立即开始取得进展，并且在每个样本上都继续进行更新。这使得随机梯度下降比批量梯度下降更快地将参数接近最小值。然而，需要注意的是，随机梯度下降可能无法收敛到真正的最小值，参数会在最小值周围波动，但是在实践中，这些接近最小值的参数值通常是对真实最小值的合理近似。因此，尤其是在训练集很大的情况下，随机梯度下降比批量梯度下降更受欢迎。\n通过这些不同的梯度下降算法，我们可以有效地拟合参数，从而得到准确的预测模型。在接下来的部分，我将继续更新我在机器学习部分自学的笔记，希望各位可以一起交流！\n","slug":"LMS","date":"2023-07-16T09:18:07.000Z","categories_index":"","tags_index":"Machine Learning,笔记","author_index":"General_K1ng"},{"id":"b6c077dbe8f34883367bdebb8559e973","title":"探索机器学习的魅力：从斯坦福大学CS229课程开始","content":"机器学习是当今科技领域的热门话题，而斯坦福大学的CS229课程则是深入学习机器学习的绝佳门户。这篇文章将带您踏上机器学习的征程，通过探索CS229课程中的第一个主题——监督学习，揭开这个令人着迷的领域的神秘面纱。无论您是初学者还是有一定经验的机器学习从业者，本文将带您以生动活泼且专业的方式了解监督学习的基本原理、应用领域以及最新的研究动态。\n（当然我也是小白，这只是我在学习过程当中的笔记 &gt;_&lt;）\n监督学习：预测房价的例子让我们从几个监督学习问题的例子入手。假设我们有一个数据集，其中包含了50栋房屋的居住面积和价格。我们可以将这些数据制成表格如下：\n\nClick to see more\n\n\n\n居住面积（feet^2）\n价格（1000$s）\n\n\n\n2104\n400\n\n\n1600\n330\n\n\n2400\n369\n\n\n1416\n232\n\n\n3000\n540\n\n\n1985\n320\n\n\n1534\n267\n\n\n1427\n199\n\n\n1380\n245\n\n\n1494\n347\n\n\n1940\n334\n\n\n2000\n383\n\n\n1890\n339\n\n\n4478\n699\n\n\n1268\n259\n\n\n2300\n410\n\n\n1760\n350\n\n\n1450\n315\n\n\n3100\n590\n\n\n2250\n410\n\n\n2132\n399\n\n\n2596\n459\n\n\n1850\n325\n\n\n2680\n480\n\n\n1956\n349\n\n\n1604\n285\n\n\n2020\n365\n\n\n2730\n525\n\n\n2008\n375\n\n\n1537\n295\n\n\n2500\n450\n\n\n1560\n280\n\n\n2120\n389\n\n\n2200\n425\n\n\n1638\n315\n\n\n2540\n475\n\n\n2200\n408\n\n\n2070\n382\n\n\n2005\n350\n\n\n1900\n380\n\n\n2380\n420\n\n\n1320\n230\n\n\n2190\n394\n\n\n2340\n416\n\n\n2678\n540\n\n\n1966\n385\n\n\n1570\n279\n\n\n1852\n360\n\n\n2454\n485\n\n\n2205\n405\n\n\n2450\n450\n\n\n\n\n我们可以用图表来展示这些数据：\n\n\n有了这样的数据，我们可以提出一个问题：基于波特兰其他房屋的居住面积，如何预测它们的价格呢？\n为了在接下来的讨论中使用统一的符号，我们将使用表示“输入”变量（在这个例子中是生活区域的大小），也称为输入特征；表示我们试图预测的“输出”或目标变量（价格）。对于一对，我们称其为训练示例（training example）。我们将学习的数据集，由n个训练示例的列表；构成，被称为训练集（training set）。请注意，上标“(i)”仅用于表示训练集的索引，与求幂无关。我们还将使用表示输入值的空间，表示输出值的空间。在这个例子中，。\n为了更正式地描述监督学习问题，我们的目标是给定一个训练集，学习一个函数：，使得成为y的“良好”预测器。从图表中可以看出，这个过程如下所示：\n\n\n当我们试图预测的目标变量是连续的，例如在房屋价格的例子中，我们将这种学习问题称为回归问题。回归问题的目标是建立一个模型，能够对连续的目标变量进行预测。通过分析各种特征和输入变量之间的关系，我们可以推断出目标变量的数值。在回归问题中，我们通常尝试拟合一条曲线或平面，以最好地表示数据的趋势和模式。\n相比之下，当目标变量只能取少量离散值时（比如，根据居住面积预测一个住宅是房子还是公寓），我们将这种学习问题称为分类问题。分类问题的目标是根据输入变量的特征将样本分配到预定义的离散类别中。在分类问题中，我们建立一个分类器，该分类器根据输入变量的特征预测目标变量的类别。为了将不同类别的样本区分开来，分类问题通常涉及使用统计技术或机器学习算法构建决策边界。\n线性回归让我们使我们的住房示例更加丰富，加入一个稍微复杂的数据集，我们还知道每栋房子的卧室数量。\n在这个数据集中，除了居住面积外，我们还有每个房子的卧室数量。我们可以将数据表示为以下表格：\n\nClick to see more\n\n\n\n居住面积（feet^2）\n卧室数量\n价格（1000$s）\n\n\n\n2104\n3\n400\n\n\n1600\n3\n330\n\n\n2400\n3\n369\n\n\n1416\n2\n232\n\n\n3000\n4\n540\n\n\n1985\n4\n320\n\n\n1534\n3\n267\n\n\n1427\n3\n199\n\n\n1380\n3\n245\n\n\n1494\n3\n347\n\n\n1940\n4\n334\n\n\n2000\n3\n383\n\n\n1890\n3\n339\n\n\n4478\n5\n699\n\n\n1268\n3\n259\n\n\n2300\n4\n410\n\n\n1760\n3\n350\n\n\n1450\n3\n315\n\n\n3100\n4\n590\n\n\n2250\n4\n410\n\n\n2132\n4\n399\n\n\n2596\n3\n459\n\n\n1850\n4\n325\n\n\n2680\n4\n480\n\n\n1956\n3\n349\n\n\n1604\n3\n285\n\n\n2020\n4\n365\n\n\n2730\n4\n525\n\n\n2008\n3\n375\n\n\n1537\n3\n295\n\n\n2500\n4\n450\n\n\n1560\n4\n280\n\n\n2120\n4\n389\n\n\n2200\n3\n425\n\n\n1638\n3\n315\n\n\n2540\n4\n475\n\n\n2200\n3\n408\n\n\n2070\n4\n382\n\n\n2005\n3\n350\n\n\n1900\n3\n380\n\n\n2380\n4\n420\n\n\n1320\n2\n230\n\n\n2190\n4\n394\n\n\n2340\n3\n416\n\n\n2678\n4\n540\n\n\n1966\n4\n385\n\n\n1570\n3\n279\n\n\n1852\n3\n360\n\n\n2454\n4\n485\n\n\n2205\n4\n405\n\n\n2450\n4\n450\n\n\n\n\n在这里，我们将表示为二维向量，包括居住面积和卧室数量。例如，表示训练集中第个房子的居住面积，表示卧室数量。（在设计学习问题时，我们可以自行选择包括哪些特征。如果我们收集住房数据，还可以考虑包括其他特征，如壁炉数量、卫生间数量等。稍后我们将详细讨论特征选择，但现在我们将特征视为给定的。）\n为了进行监督学习，我们需要决定如何在计算机中表示函数/假设。作为初始选择，我们假设我们决定将近似为的线性函数：在这个表达式中，是参数（也被称为权重），用于参数化从到的线性函数空间。当没有混淆的风险时，我们将在中省略θ的下标，并将其简化为。为了简化表示法，我们还引入一个约定，将设置为1（这是截距项），这样我们可以表示为：在上面的表达式中，我们将和都视为向量，其中是输入变量的数量（不包括）。现在，给定一个训练集，我们如何选择或学习参数？一个合理的方法似乎是使得尽可能接近，至少对于我们拥有的训练样本来说是如此。为了形式化这个问题，我们定义了一个函数，用于衡量每个值对应的与相应的之间的接近程度。我们定义了成本函数：让我们逐步解释成本函数的每个部分：\n\n 代表我们的模型对于输入样本  的预测值。\n 是对应于输入样本  的实际观测值。\n 表示我们的模型预测值与实际观测值之间的差异，即误差。\n 将误差进行平方，这是为了消除误差的正负号，并将大误差的影响放大，以更好地衡量它们对总体误差的贡献。\n 对所有训练样本的误差平方进行求和，得到总体误差的度量。\n 为了计算方便，我们对总体误差进行了归一化，除以2。这不会影响最终优化的结果，因为我们的目标是最小化成本函数，而不是具体的数值。\n\n因此，成本函数  衡量了模型预测值与实际观测值之间的差异的平方和的一半。我们的目标是通过调整参数  的值，使得成本函数的值最小化，从而使模型的预测尽可能接近实际观测值。\n如果听不懂，没关系，我们来举一个非常简单的例子来理解成本函数到底是什么玩意。当我们建立一个模型时，我们希望它能够根据输入数据预测出正确的结果。然而，在训练模型时，我们的预测可能与实际结果有一些差距。成本函数的作用就是衡量这些预测差距的大小。\n假设你是一名学生，每天都要骑自行车去上学。你决定根据骑行时间来预测你到达学校所需的时间。你记录了过去一周的骑行时间和实际到达学校的时间，如下所示：\n\n\n\n骑行时间（分钟）\n到达时间（分钟）\n\n\n\n20\n25\n\n\n25\n30\n\n\n30\n35\n\n\n35\n40\n\n\n40\n45\n\n\n现在，你想建立一个模型，根据骑行时间预测到达时间。你选择线性函数来表示模型，即假设到达时间与骑行时间之间存在一种线性关系。\n假设我们的模型为 ，其中  表示到达时间的预测值， 表示骑行时间。我们的目标是找到最佳的参数  和 ，使得模型的预测结果尽可能接近实际观测值。\n为了衡量模型的预测与实际观测值之间的差距，我们使用成本函数。在这个例子中，我们使用均方误差（Mean Squared Error，MSE）作为成本函数。MSE 的计算方式是将每个预测值与对应的实际观测值之间的差距平方，并取所有差距平方的平均值。\n现在，我们来计算一下成本函数的值。假设我们选择了一组参数  和 。我们可以将这些参数代入模型，并计算出每个骑行时间对应的预测值。\n\n\n\n骑行时间（分钟）\n到达时间（分钟）\n预测到达时间（分钟）\n差距（预测-实际）\n差距平方\n\n\n\n20\n25\n30\n-5\n25\n\n\n25\n30\n35\n-5\n25\n\n\n30\n35\n40\n-5\n25\n\n\n35\n40\n45\n-5\n25\n\n\n40\n45\n50\n-5\n25\n\n\n现在，我们将差距平方的平均值作为成本函数的值。在这种情况下，成本函数的计算如下：我们的目标是通过调整参数  和  的值，使得成本函数的值最小化。这意味着我们希望找到最佳的参数组合，使得模型的预测结果与实际观测值之间的差距最小化。\n希望这个例子能够更加清晰地解释成本函数的概念。成本函数用于衡量模型预测与实际观测之间的差距，并帮助我们找到最佳的参数组合。\n如果你之前接触过线性回归，你可能会注意到这个熟悉的最小二乘成本函数，它导致了普通最小二乘回归模型。无论你之前是否见过它，我们将继续讨论，并最终展示它是一个更广泛的算法家族中的特例。同时，这个成本函数的意义是衡量我们的预测与实际数据之间的差距。较小的成本值表示我们的预测较接近真实数据，而较大的成本值表示预测与真实数据之间的差距较大。\n如何有任何疑问或者建议欢迎在评论区评论&gt; &lt;!!!\n","slug":"初识机器学习","date":"2023-07-16T07:02:18.000Z","categories_index":"","tags_index":"Machine Learning,笔记","author_index":"General_K1ng"},{"id":"d99fcab655887d4444838841a030a1e7","title":"正项级数","content":"这是一个非常重要的课题，我们将开始学习关于正级数，请专心听讲。\n正项级数的定义正项级数是一种无穷级数，其项均为正实数。它的形式如下：其中为级数的第个项。\np级数p级数是指形如的级数，其中是一个正实数。该级数以分母的指数来命名。\np级数具有以下性质：\n\n如果，则p级数收敛。\n如果，则p级数发散。\n\n\n\n这个结果的证明基于积分测试。为了理解为什么这是正确的，我们可以考虑函数。这个函数在区间上连续、正值且递减，因此我们可以应用积分测试来得到级数的结果：对积分进行计算，我们得到：$$\\int_{1}^{\\infty} \\frac{1}{x^p}dx  \\left{\\right.$$因此，p级数收敛当且仅当，当时发散。\n对于，p级数的和可以用黎曼ζ函数（Riemann zeta function）来表示，它的定义为：黎曼ζ函数具有许多有趣的性质，并与数论和复分析等其他数学领域有着密切的联系。\n敛散性检验有几个用于确定正项级数收敛或发散的收敛性测试。以下是其中几个常用的测试：\n1. 比较判别法比较判别法是一种通过将待定级数与已知收敛性的另一个级数进行比较来确定级数的收敛性或发散性的方法。比较法的规则如下：\n假设  和  是具有正项的级数，并且对所有 ，满足 。\n\n如果  收敛，则  也收敛。\n如果  发散，则  也发散。\n\n换句话说，如果级数  的项始终小于或等于级数  的项，并且  收敛，那么  必定收敛。相反地，如果  发散，那么  也一定发散。\n比较测试经常用于将给定的级数与 p-级数进行比较，因为 p-级数的收敛性是众所周知的。具体而言，如果我们有一个形如  的级数，以及另一个级数 ，其中的项始终小于或等于 ，那么我们可以使用比较测试来确定  的收敛性。\n\n\n\n\n\n\n\n\n\n\n\n我们常用的一些参考无限级数有：\n\n几何级数\n调和级数\np-级数\n\n2. 极限比较判别法极限比较判别法是用于确定级数的收敛性或发散性的另一种方法。与比较法类似，它涉及将给定的级数与已知收敛性的另一个级数进行比较。然而，极限比较测试在选择要进行比较的级数方面更加灵活。\n假设  和  是具有正项的级数。令 ，其中  是一个有限的正数或者是 。\n\n如果 ，则  和  要么都收敛，要么都发散。\n如果  并且  收敛，则  也收敛。\n如果  并且  发散，则  也发散。\n\n极限比较测试在选择要进行比较的级数方面更加灵活，因为我们只需要项的比值收敛到一个有限的正数。这意味着我们通常可以找到一个更易处理的级数来进行比较，相较于比较测试的情况而言。\n3. 比值判别法比值判别法是一种用于判断级数的收敛性或发散性的测试方法。比值法规定如下：\n假设  是一个具有正项的级数，令 （这个极限可能存在也可能不存在）。\n\n如果 ，则  绝对收敛。\n如果  或 ，则  发散。\n如果  或极限不存在，则比值测试无法确定收敛性或发散性，我们需要使用其他测试方法。\n\n从直观上讲，比值测试将级数的项与具有公比  的几何级数的项进行比较。如果 ，那么级数的项的衰减速度比一个收敛的几何级数的项更快，因此该级数收敛。如果 ，那么级数的项的增长速度比一个发散的几何级数的项更快，因此该级数发散。如果 ，那么级数的项的衰减速度与一个收敛的几何级数的项相同，因此测试是不确定的。\n4. 根值判别法根值判别法是一种用于判断级数的收敛性或发散性的测试方法。根值判别法规定如下：\n假设  是一个具有正项的级数，令 （这个极限可能存在也可能不存在）。\n\n如果 ，则  绝对收敛。\n如果  或 ，则  发散。\n如果  或极限不存在，则根值测试无法确定收敛性或发散性，我们需要使用其他测试方法。\n\n从直观上讲，根值测试将级数的项与一个收敛的几何级数的项进行比较，该几何级数的公比为 。如果 ，那么级数的项的衰减速度比一个收敛的几何级数的项更快，因此该级数收敛。如果 ，那么级数的项的增长速度比一个发散的几何级数的项更快，因此该级数发散。如果 ，那么级数的项的衰减速度与一个收敛的几何级数的项相同，因此测试是不确定的。\n这章节的内容非常重要，因为我们随后提到的许多概念和扩展都是基于这一章的结论，所以一定要仔细阅读。\n","slug":"正项级数","date":"2023-07-15T09:07:26.000Z","categories_index":"","tags_index":"笔记,Math","author_index":"General_K1ng"},{"id":"8c5051666bb20a88e04fe467e55f2664","title":"无穷级数的性质","content":"欢迎来到无穷级数的奇妙世界！在这一章中，我们将探索无穷级数的性质，包括收敛、发散以及我们可以对级数进行的代数运算。理解这些性质对于数学和科学的许多领域都是至关重要的，它使我们能够做出准确的预测，解决重要的问题，并发展新的计算方法。所以，让我们一起深入探索无穷级数的惊人性质吧。\n几个重要的无穷级数除了探索无穷级数的性质，我们还将介绍和研究一些在数学中最重要的级数。其中包括几何级数，在微积分中有许多重要的应用，以及调和级数，它是一个经典的发散级数的例子。我们还将研究其他重要的级数，如交错级数和泰勒级数，在数学和科学的许多领域都有广泛的应用。所以，准备好一起探索无穷级数的性质，以及数学中一些最重要的级数吧！\n几何级数几何级数是一种特殊类型的无穷级数，其中每一项都是前一项的常数倍（说白了就是等比数列）。几何级数的一般形式为其中  是第一项， 是公比。几何级数在数学中很重要，在科学和工程中也有许多应用。\n推导通项公式为了推导出几何级数的求和公式，我们从考虑级数的部分和开始。设  为级数的前  项和，那么我们可以将方程的两边都乘以  得到将第二个方程从第一个方程中减去，我们得到这可以简化为如果 ，我们可以将两边都除以  得到这个公式给出了几何级数的前  项和。\n要求解无穷几何级数的和，我们取  趋向于无穷的极限：如果 ，那么当  趋向于无穷时， 趋向于零，所以极限简化为这就是当  时无穷几何级数的和的公式。\n几何级数的敛散性几何级数的收敛性取决于公比  的值。我们可以将几何级数分为三类：\n\n如果 ，那么级数绝对收敛。这意味着级数收敛且和是有限的。\n如果 ，那么级数可能收敛，也可能发散。在这种情况下，我们需要观察级数的项的行为来确定收敛性或发散性。\n如果 ，那么级数发散。这意味着级数的和是无穷的。\n\n例如，考虑级数\n这是一个公比为 ， 的几何级数。由于 ，该级数绝对收敛，和为\n\n\n\n\n\n\n\n\n\n这个图像生动地展示了为什么这个几何级数的和是2。当然，为了方便起见，我们让级数的第一项从  开始。每次将图像分成两半并取剩余部分的一半，即四分之一，依此类推，我们发现图像的总面积仍然是1，直到无穷项。\n几何级数的应用几何级数在数学、科学和工程中有许多应用。例如，它们可以用来模拟指数增长或衰减，如人口增长或放射性物质的衰变。它们还可以用于计算某些类型的积分和近似函数。\n结论几何级数是微积分中的一个基本概念，在各个领域中都有许多应用。理解几何级数的收敛和发散对于使用闭合解找到级数的和非常重要。\n调和级数调和级数是数学中一个众所周知的级数，它在许多不同的背景下自然出现，包括微积分、数论和物理学。特别地，它是以下形式的级数：\n调和级数之所以有趣，是因为它是一个发散的级数，也就是说它没有有限的和。这可以通过检查级数的部分和来看出，随着添加更多的项，部分和会无限增长。\n敛散性的证明为了证明调和级数的发散性，我们可以使用积分测试。积分测试表明，如果函数  对于所有  是正的、递减的和连续的，并且对于所有 ，有 ，那么级数  和不定积分  要么都收敛，要么都发散。\n对于调和级数，我们可以选择 ，它满足积分测试的条件。不定积分  可以计算为：由于该积分发散，调和级数也必定发散。\n\n\n可以看到，每个矩形的面积都是 ，所以前  个矩形的总面积是 。随着  的增加，矩形的面积逐渐接近 ，因此阶梯状的图形逐渐趋近于斜率为  的曲线。最终，当  趋向于无穷时，矩形的面积趋向于 ，阶梯状的图形趋向于曲线 。\n这种可视化可以帮助我们更好地理解级数的行为以及它与自然对数的关系。\n当然，如果你无法理解这个图像以及以上所说的证明过程，没关系，你只需要记住调和级数是发散的。\n调和级数的应用调和级数的发散性在数学和科学中有许多重要的应用，例如：\n\n调和级数在数论中被用来研究质数的分布。级数的发散意味着质数是无穷多的，这是数论中的一个基本结果。\n调和级数的发散性在物理学中也有重要的应用，特别是在电场的研究中。点电荷在电场中的电势能与点电荷与电场中所有其他电荷之间距离的倒数之和成正比。这个和等价于调和级数，它的发散性意味着点电荷的电势能是无限大的。\n\n结论总之，调和级数是数学和科学中重要而有趣的级数。它是一个发散的级数，也就是说它没有有限的和。我们可以使用积分测试来证明级数的发散性，而级数的发散性在数论和物理学中有重要的应用。\n无穷级数的一些性质\n如果给定的无穷级数  收敛，那么任何形式为  的级数，其中  是常数，也将收敛。这个性质可以通过序列极限的定义得出。\n\n\n\n\n\n\n\n\n\n\n\n我们可以看到  收敛，并且  也收敛，它们的收敛性与  相同。\n因此，这个定理可以用来证明  收敛，因为它是通过将  乘以常数 0.5 而得到的。\n\n为了证明这个性质，我们可以设  是级数  的部分和序列， 是级数  的部分和序列。那么我们有：和将第一个等式乘以 ，我们得到：现在，设  是序列  的极限，即 。由于级数  收敛，我们知道极限  是有限的。因此，根据极限的代数性质，我们有：类似地，序列  的极限为：因此，级数  也收敛，其和为 。\n综上所述，无穷级数的线性性质表明，如果给定的无穷级数收敛，那么通过将原级数的项乘以一个常数得到的任何级数也将收敛，其和将是该常数与原级数和的乘积。这个性质可以通过序列极限的定义和极限的代数性质得到。\n\n\n\n如果  和  收敛，那么  也收敛。\n\n\n\n\n\n\n\n\n\n\n\n\n\n我们可以看到  和  都收敛，而  也收敛，它们的收敛性与  和  相同。\n因此，这个定理可以用来证明  收敛，因为它是  和  的和。\n\n要证明这个结果，我们可以使用以下步骤：\n\n令 。那么  是由  和  对应的项相加得到的级数。\n\n由于  和  都收敛，它们的部分和序列  和  也收敛。即， 和 。\n\n我们想要证明  收敛。为了做到这一点，我们需要证明  的部分和序列  收敛。也就是说，我们需要证明  存在。\n\n我们可以将  表示为  和  的形式：\n\n根据极限的性质，我们有：\n\n因此，我们已经证明了  的部分和序列  收敛，因此级数  收敛。\n\n由于  被定义为 ，所以这个结果对于  和  两种情况都成立。也就是说，如果  和  收敛，那么  和  也收敛。\n\n\n\n\n\n对于仍然在任意添加括号后保持收敛的无穷级数\n\n​\t\t如果您有Python环境，我强烈建议您运行我提供的”Verifying_Property_3” Python文件，您可以看到在不同括号下的图像的差异。\n\n要了解这个结论为什么成立，考虑一个收敛于极限的无穷级数。也就是说，偏和数列，其中，当趋向于无穷时收敛于。\n现在，假设我们以任意方式给级数的项添加括号，也就是说，我们用括号将某些项分组，但不改变项的顺序。例如，我们可以写成：或者或者任何其他方式的分组。\n让我们用表示新的偏和数列，其中是前个分组的和。例如，在上述第一种分组中，我们有，，，依此类推。\n现在，考虑级数中的任意两个相邻的分组。我们将第一个分组中的项称为，将第二个分组中的项称为。那么这两个分组的和为：根据加法的结合律，我们可以重新排列这个和为：也就是说，我们可以以任何希望的方式将这些项分组，得到的和仍然相同。因此，新的分组的偏和数列与原始的偏和数列相同。换句话说，在收敛级数的项上添加括号不会改变级数的极限。\n因此，我们已经证明了对于收敛的无穷级数，在其项上添加任何括号后，级数仍然收敛，且极限不变。\n\n\n​\t\t需要注意的是，这个性质只适用于收敛的级数。对于发散的级数，重新排列项可能会导致不同的收敛性质。\n\n通过删除、添加或更改有限项，级数的收敛性不会改变，但和可能会改变。\n\n\n要正式证明这个性质，让我们考虑一个无穷级数，其中是级数的第个项。我们想要证明，如果我们通过添加、删除或更改任意有限数量的项来修改这个级数，级数的收敛性或发散性不会改变。\n首先，让我们考虑添加或删除有限数量的项的情况。设为原级数的原和，为修改后级数的新和。我们可以将表示为两个级数的和：第一个级数是原级数删除或添加有限数量的项后得到的，第二个级数是由被删除或添加的项组成的有限级数。形式上，我们可以写成：这里，是正整数，是非负整数，是修改后级数的第个项。\n由于原级数收敛于，我们有：现在，让我们考虑修改后的级数。修改后级数的第一部分收敛于与原级数相同的极限，因为它们之间只有有限数量的项不同。第二部分是一个有限级数，因此它收敛于一个有限和。因此，修改后的级数也收敛于和。\n因此，我们已经证明，如果我们通过添加或删除有限数量的项来修改一个无穷级数，级数的收敛性或发散性不会改变。\n接下来，让我们考虑更改有限数量的项的情况。假设我们通过将第个项更改为来修改级数，其中。设和分别为原和和修改后的和。那么，我们可以写成：由于和之间的差是一个有限数，级数的收敛性或发散性不会改变。然而，级数的实际和是不同的。\n总而言之，”通过删除、添加或更改有限项，级数的收敛性不会改变，但和可能会改变”是无穷级数理论中的一个基本结果。它告诉我们，我们可以通过添加、删除或更改有限数量的项来修改一个无穷级数，而不影响其收敛性或发散性。然而，级数的实际和可能会有所不同。\n\n\n\n级数收敛的必要条件是。换句话说，如果是一个收敛的级数，那么。\n\n\n要证明这个结果，假设是一个收敛的级数。根据定义，这意味着偏和序列收敛到某个有限极限。\n我们可以将级数的第个项表示为两个相邻偏和的差：将两边取极限，当时，我们得到：这里我们利用了序列收敛于的事实，因此和。\n因此，我们已经证明了如果是一个收敛的级数，那么。\n值得注意的是，这个结果的逆命题不一定成立。也就是说，仅仅因为，并不意味着是收敛的。例如，调和级数是发散的，尽管。因此，条件只是收敛的必要条件，而不是充分条件。\n\n\n当然，我们要求你不必记住或完全理解这些性质的推导过程，这些只是为了帮助你理解。在考试中，你只需要记住加粗的文字，这应该不难，对吗？\n","slug":"无穷级数的性质","date":"2023-07-15T07:46:56.000Z","categories_index":"","tags_index":"笔记,Math","author_index":"General_K1ng"},{"id":"fca5d0f1b5b938fde80803f8dc301aa3","title":"我的博客之旅：学习、分享与成长","content":"\n\n\n\n\n\n\n\n\n欢迎来到我的博客！我是金洪来，目前就读于西交利物浦大学，专业是信息与计算科学（ICS）。在我充满好奇心和激情的探索中，我决定搭建这个博客，与大家分享我的学习经历、见解和成果。对我来说，这是一次意义非凡的旅程，我希望能够与你们一起成长、互相学习和建立联系。\n自我介绍我是一个对新兴技术充满热情的学生，同时也热爱广泛阅读。在我信息与计算科学的学习中，我不仅学习了编程语言和算法，还探索了许多有趣的领域，如人工智能、数据科学和网络安全。我迷恋于技术的力量和它所带来的无限可能。通过博客，我希望能够与大家分享我的学习经验、项目经历以及对技术和生活的思考。\n搭建博客的动机我为什么突然决定搭建博客呢？首先，学习新技术时，我发现将所学知识记录下来是一种非常有效的方法，可以帮助我更好地理解和巩固所学内容。通过博客，我可以分享这些知识，并与志同道合的人们交流和互动，从中收获更多的见解和观点。其次，博客可以成为一个平台，让我与专业人士和技术大佬们建立联系。我希望能够从他们的经验中获得启发和指导，进一步提升自己的技术能力和职业发展。最重要的是，我相信博客是一个分享和学习的场所，我希望能够通过博客与读者们一起成长，共同进步。\n目标受众我的博客欢迎所有学生、志同道合的朋友、技术大佬和技术小白们。无论你是正在学习编程的初学者，还是想深入了解某个领域的专业人士，我都希望我的博客能够为你提供有价值的信息和灵感。在我的博客中，你将找到关于技术教程、项目经验、学习心得，以及我对生活和工作的见解和体验分享。我希望能够为你提供有趣且实用的内容，无论你身在何处、经历如何，我都希望我的博客能够成为你学习和成长的伙伴。\n博客内容计划在我的博客中，你将看到各种内容，涵盖了技术教程、项目经验、学习笔记以及我对生活和工作的见解和体验。我计划分享一些简单易懂的技术教程，帮助初学者快速入门。通过清晰的代码示例和详细的解释，我希望能够让你轻松理解复杂的概念和技术。同时，我也会分享一些我在项目中遇到的挑战和解决方法，以及学习过程中的心得体会。我相信通过分享这些经验，我们可以相互帮助和共同成长。此外，我会不定期地分享一些生活感悟和工作经验，希望能够给你带来一些启发和思考。\n学习和成长通过搭建博客，我期望自己能够不断学习和成长。通过与读者的互动和交流，我相信我可以提升自己的学习能力和沟通技巧。我希望能够给你提供有价值的内容和支持，帮助你解决问题、开拓思路。同时，我也希望能够通过博客启发更多的人，鼓励他们追求自己的梦想，勇敢地探索未知的领域。在这个博客的旅程中，我将不断挑战自我，拓宽自己的知识边界，并将这些经验和成长与大家分享。\n结语感谢你花时间阅读我的博客介绍。我希望你能够加入我的博客之旅，与我一起探索技术的奇妙世界，共同成长和学习。如果你对我的博客感兴趣或有任何问题、建议或想法，请随时与我联系。我期待与你在博客中互动，并希望我的博客能够对你有所帮助。谢谢！\n","slug":"我的第一篇博客","date":"2023-07-14T09:16:53.000Z","categories_index":"","tags_index":"随笔","author_index":"General_K1ng"}]