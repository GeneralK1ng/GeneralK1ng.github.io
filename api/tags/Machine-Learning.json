{"name":"Machine Learning","slug":"Machine-Learning","count":7,"postlist":[{"title":"LMS算法","uid":"eee27f691084ae51bee755f5fe41f548","slug":"LMS","date":"2023-07-16T09:18:07.000Z","updated":"2023-07-17T05:44:45.397Z","comments":true,"path":"api/articles/LMS.json","keywords":null,"cover":"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/jianyue.png","text":"欢迎来到新的一部分！现在我们将介绍一种非常有趣的算法，它被称为最小均方（Least Mean Squares，LMS）算法。这是一种用于优化线性回归模型的算法，它可以帮助我们找到最佳的参数组合，使得我们的预测结果与实际观测值之间的差异最小化。 LMS算法实际上是一个非常聪明的算法...","link":"","photos":[],"count_time":{"symbolsCount":"9.3k","symbolsTime":"8 mins."},"categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","count":7,"path":"api/tags/Machine-Learning.json"},{"name":"笔记","slug":"笔记","count":9,"path":"api/tags/笔记.json"}],"author":{"name":"General_K1ng","slug":"blog-author","avatar":"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/avatar.png","link":"/","description":"一名正在努力学习计算机的菜鸟","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/svg/BILIBILI.svg","link":"https://space.bilibili.com/32927332"},"csdn":{"icon":"/svg/csdn.svg","link":"https://blog.csdn.net/qq_34849354"},"github":{"icon":"/svg/GitHub.svg","link":"https://github.com/GeneralK1ng"},"QQ":{"icon":"/svg/QQ.svg","link":"tencent://AddContact/?fromId=45&fromSubId=1&subcmd=all&uin=2645370205"}}}}},{"title":"分类与逻辑回归","uid":"4c5f4ebe8f68ff24ce30098465671f7c","slug":"Classification-and-logistic-regression","date":"2023-07-18T09:41:28.000Z","updated":"2023-07-18T11:40:45.100Z","comments":true,"path":"api/articles/Classification-and-logistic-regression.json","keywords":null,"cover":"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/jianyue.png","text":"在机器学习的广袤领域中，分类问题犹如一片神秘的森林，吸引着众多探险家的目光。我们可以将自己想象成一位勇敢的森林导游，带领着各种生物来到分类问题的奇妙世界。 什么是分类问题？在这片森林中，我们将聚焦于探讨分类问题。这与我们之前遇到的回归问题有些相似，但又有所不同。在分类问题中，我们...","link":"","photos":[],"count_time":{"symbolsCount":"4.2k","symbolsTime":"4 mins."},"categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","count":7,"path":"api/tags/Machine-Learning.json"},{"name":"笔记","slug":"笔记","count":9,"path":"api/tags/笔记.json"}],"author":{"name":"General_K1ng","slug":"blog-author","avatar":"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/avatar.png","link":"/","description":"一名正在努力学习计算机的菜鸟","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/svg/BILIBILI.svg","link":"https://space.bilibili.com/32927332"},"csdn":{"icon":"/svg/csdn.svg","link":"https://blog.csdn.net/qq_34849354"},"github":{"icon":"/svg/GitHub.svg","link":"https://github.com/GeneralK1ng"},"QQ":{"icon":"/svg/QQ.svg","link":"tencent://AddContact/?fromId=45&fromSubId=1&subcmd=all&uin=2645370205"}}}},"feature":true},{"title":"局部加权线性回归*","uid":"465c62620dad1684532695600a6cd19f","slug":"Locally-weighted-linear-regression-optional-reading","date":"2023-07-17T07:42:47.000Z","updated":"2023-07-18T11:38:04.024Z","comments":true,"path":"api/articles/Locally-weighted-linear-regression-optional-reading.json","keywords":null,"cover":"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/jianyue.png","text":"引言回顾最小二乘法的概率解释，我们曾深入研究过如何通过最小化误差的平方和，寻找最佳的模型参数。这个方法的确非常强大，但有时候我们需要更加灵活和精确的工具来解决特定的问题。 于是，引入局部加权线性回归（Locally Weighted Linear Regression）。这个方法...","link":"","photos":[],"count_time":{"symbolsCount":"7.2k","symbolsTime":"7 mins."},"categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","count":7,"path":"api/tags/Machine-Learning.json"},{"name":"笔记","slug":"笔记","count":9,"path":"api/tags/笔记.json"}],"author":{"name":"General_K1ng","slug":"blog-author","avatar":"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/avatar.png","link":"/","description":"一名正在努力学习计算机的菜鸟","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/svg/BILIBILI.svg","link":"https://space.bilibili.com/32927332"},"csdn":{"icon":"/svg/csdn.svg","link":"https://blog.csdn.net/qq_34849354"},"github":{"icon":"/svg/GitHub.svg","link":"https://github.com/GeneralK1ng"},"QQ":{"icon":"/svg/QQ.svg","link":"tencent://AddContact/?fromId=45&fromSubId=1&subcmd=all&uin=2645370205"}}}}},{"title":"概率解释*","uid":"85691702e05d151e003d7396dcbea440","slug":"Probabilistic-interpretation","date":"2023-07-17T06:02:56.000Z","updated":"2023-07-17T07:40:04.082Z","comments":true,"path":"api/articles/Probabilistic-interpretation.json","keywords":null,"cover":"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/jianyue.png","text":"引言当涉及到机器学习算法时，有时我们不仅仅希望通过数学的角度来理解它们的原理，还希望探索它们的概率解释。在这个部分中，我们将探讨线性回归算法的概率解释。 你有没有想过，为什么我们在回归问题中使用平方误差作为成本函数？为什么我们假设模型的预测值和真实值之间存在高斯分布的误差？通过概...","link":"","photos":[],"count_time":{"symbolsCount":"2.9k","symbolsTime":"3 mins."},"categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","count":7,"path":"api/tags/Machine-Learning.json"},{"name":"笔记","slug":"笔记","count":9,"path":"api/tags/笔记.json"}],"author":{"name":"General_K1ng","slug":"blog-author","avatar":"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/avatar.png","link":"/","description":"一名正在努力学习计算机的菜鸟","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/svg/BILIBILI.svg","link":"https://space.bilibili.com/32927332"},"csdn":{"icon":"/svg/csdn.svg","link":"https://blog.csdn.net/qq_34849354"},"github":{"icon":"/svg/GitHub.svg","link":"https://github.com/GeneralK1ng"},"QQ":{"icon":"/svg/QQ.svg","link":"tencent://AddContact/?fromId=45&fromSubId=1&subcmd=all&uin=2645370205"}}}}},{"title":"正规方程","uid":"8bd50a6b3cea7ecea2a8063e70b7409b","slug":"The-normal-equations","date":"2023-07-17T04:09:05.000Z","updated":"2023-07-17T05:34:06.496Z","comments":true,"path":"api/articles/The-normal-equations.json","keywords":null,"cover":"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/jianyue.png","text":"引入在机器学习和线性回归中，我们经常需要通过训练数据来学习参数，以便建立一个能够准确预测目标变量的模型。前面我们已经介绍了梯度下降法，这是一种常用的优化算法，可以帮助我们找到最小化成本函数的参数值。 除了梯度下降法，还有一种有趣而简洁的方法可以解决线性回归问题，它被称为正规方程（...","link":"","photos":[],"count_time":{"symbolsCount":"3.9k","symbolsTime":"4 mins."},"categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","count":7,"path":"api/tags/Machine-Learning.json"},{"name":"笔记","slug":"笔记","count":9,"path":"api/tags/笔记.json"}],"author":{"name":"General_K1ng","slug":"blog-author","avatar":"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/avatar.png","link":"/","description":"一名正在努力学习计算机的菜鸟","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/svg/BILIBILI.svg","link":"https://space.bilibili.com/32927332"},"csdn":{"icon":"/svg/csdn.svg","link":"https://blog.csdn.net/qq_34849354"},"github":{"icon":"/svg/GitHub.svg","link":"https://github.com/GeneralK1ng"},"QQ":{"icon":"/svg/QQ.svg","link":"tencent://AddContact/?fromId=45&fromSubId=1&subcmd=all&uin=2645370205"}}}}},{"title":"探索机器学习的魅力：从斯坦福大学CS229课程开始","uid":"b6c077dbe8f34883367bdebb8559e973","slug":"初识机器学习","date":"2023-07-16T07:02:18.000Z","updated":"2023-07-16T10:50:13.225Z","comments":true,"path":"api/articles/初识机器学习.json","keywords":null,"cover":"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/jianyue.png","text":"机器学习是当今科技领域的热门话题，而斯坦福大学的CS229课程则是深入学习机器学习的绝佳门户。这篇文章将带您踏上机器学习的征程，通过探索CS229课程中的第一个主题——监督学习，揭开这个令人着迷的领域的神秘面纱。无论您是初学者还是有一定经验的机器学习从业者，本文将带您以生动活泼且...","link":"","photos":[],"count_time":{"symbolsCount":"4.3k","symbolsTime":"4 mins."},"categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","count":7,"path":"api/tags/Machine-Learning.json"},{"name":"笔记","slug":"笔记","count":9,"path":"api/tags/笔记.json"}],"author":{"name":"General_K1ng","slug":"blog-author","avatar":"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/avatar.png","link":"/","description":"一名正在努力学习计算机的菜鸟","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/svg/BILIBILI.svg","link":"https://space.bilibili.com/32927332"},"csdn":{"icon":"/svg/csdn.svg","link":"https://blog.csdn.net/qq_34849354"},"github":{"icon":"/svg/GitHub.svg","link":"https://github.com/GeneralK1ng"},"QQ":{"icon":"/svg/QQ.svg","link":"tencent://AddContact/?fromId=45&fromSubId=1&subcmd=all&uin=2645370205"}}}}},{"title":"（实战）鸢尾花数据集的二分类","uid":"6ad60e40b1cfbe85f1c534ea3d1910e1","slug":"Secondary-classification-of-Iris","date":"2023-07-19T10:14:24.000Z","updated":"2023-07-19T11:33:27.102Z","comments":true,"path":"api/articles/Secondary-classification-of-Iris.json","keywords":null,"cover":"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/dataAnalysis.jpg","text":"所以说第一行打不了字是吧，莫名其妙。（不用管这一行，刚刚发现我的编辑器第一行莫名其妙打不了字，所以你看到的这是第二行，很烦） 昨天我学习了逻辑回归，今天就要实战一下啦！因为光看纸上的知识总感觉有点枯燥，咱们动手试试，把学到的知识化为力量吧！今天我们要玩的游戏是逻辑回归，而游戏场地...","link":"","photos":[],"count_time":{"symbolsCount":"11k","symbolsTime":"10 mins."},"categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","count":7,"path":"api/tags/Machine-Learning.json"},{"name":"笔记","slug":"笔记","count":9,"path":"api/tags/笔记.json"}],"author":{"name":"General_K1ng","slug":"blog-author","avatar":"https://cdn.jsdelivr.net/gh/GeneralK1ng/My_Blog_IMG@main/img/avatar.png","link":"/","description":"一名正在努力学习计算机的菜鸟","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/svg/BILIBILI.svg","link":"https://space.bilibili.com/32927332"},"csdn":{"icon":"/svg/csdn.svg","link":"https://blog.csdn.net/qq_34849354"},"github":{"icon":"/svg/GitHub.svg","link":"https://github.com/GeneralK1ng"},"QQ":{"icon":"/svg/QQ.svg","link":"tencent://AddContact/?fromId=45&fromSubId=1&subcmd=all&uin=2645370205"}}}},"feature":true}]}